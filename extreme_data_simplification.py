#!/usr/bin/env python3
"""
æç«¯æ•°æ®ç®€åŒ–è„šæœ¬
ä¸“é—¨è§£å†³å°æ•°æ®é›†(11æ ·æœ¬)å¯¼è‡´RÂ²ä¸ºè´Ÿå€¼çš„é—®é¢˜
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
import logging
from datetime import datetime
import json
from typing import Dict, List, Tuple
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_regression

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ExtremeDataSimplifier:
    """æç«¯æ•°æ®ç®€åŒ–å™¨ - ä¸“é—¨è§£å†³å°æ•°æ®é›†é—®é¢˜"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        self.scaler = StandardScaler()
        self.feature_selector = None
        self.selected_features = None
        
    def extreme_simplify(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """æç«¯ç®€åŒ–æ•°æ®"""
        try:
            logger.info("ğŸš€ å¼€å§‹æç«¯æ•°æ®ç®€åŒ–...")
            logger.info(f"ğŸ“Š åŸå§‹æ•°æ®: X={X.shape}, y={y.shape}")
            
            # ç­–ç•¥1: æç®€ç‰¹å¾é€‰æ‹© (åªä¿ç•™æœ€é‡è¦çš„2-3ä¸ªç‰¹å¾)
            logger.info("ğŸ”§ ç­–ç•¥1: æç®€ç‰¹å¾é€‰æ‹©...")
            X_simple, selected_features = self._extreme_feature_selection(X, y, max_features=3)
            logger.info(f"âœ… ç‰¹å¾é€‰æ‹©å®Œæˆ: {X.shape[1]} -> {X_simple.shape[1]}")
            logger.info(f"ğŸ“‹ é€‰ä¸­ç‰¹å¾: {selected_features}")
            
            # ç­–ç•¥2: æ•°æ®æ ‡å‡†åŒ–
            logger.info("ğŸ”§ ç­–ç•¥2: æ•°æ®æ ‡å‡†åŒ–...")
            X_scaled = self.scaler.fit_transform(X_simple)
            
            # ç­–ç•¥3: å¼‚å¸¸å€¼å¤„ç† (æ›´æ¿€è¿›)
            logger.info("ğŸ”§ ç­–ç•¥3: æ¿€è¿›å¼‚å¸¸å€¼å¤„ç†...")
            X_clean, y_clean = self._aggressive_outlier_removal(X_scaled, y)
            logger.info(f"âœ… å¼‚å¸¸å€¼å¤„ç†å®Œæˆ: {len(y)} -> {len(y_clean)} æ ·æœ¬")
            
            # ç­–ç•¥4: æ•°æ®å¢å¼º (é€šè¿‡æ’å€¼å¢åŠ æ ·æœ¬)
            logger.info("ğŸ”§ ç­–ç•¥4: æ•°æ®å¢å¼º...")
            X_augmented, y_augmented = self._augment_data(X_clean, y_clean, target_samples=50)
            logger.info(f"âœ… æ•°æ®å¢å¼ºå®Œæˆ: {len(y_clean)} -> {len(y_augmented)} æ ·æœ¬")
            
            result = {
                'status': 'success',
                'X_simplified': X_augmented,
                'y_simplified': y_augmented,
                'selected_features': selected_features,
                'original_shape': X.shape,
                'simplified_shape': X_augmented.shape,
                'feature_reduction': f"{((X.shape[1] - X_augmented.shape[1]) / X.shape[1] * 100):.1f}%",
                'sample_increase': f"{((len(y_augmented) - len(y)) / len(y) * 100):.1f}%"
            }
            
            logger.info("ğŸ‰ æç«¯æ•°æ®ç®€åŒ–å®Œæˆï¼")
            logger.info(f"ğŸ“Š æœ€ç»ˆæ•°æ®: X={X_augmented.shape}, y={y_augmented.shape}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ æç«¯æ•°æ®ç®€åŒ–å¤±è´¥: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def _extreme_feature_selection(self, X: np.ndarray, y: np.ndarray, max_features: int = 3) -> Tuple[np.ndarray, List[str]]:
        """æç®€ç‰¹å¾é€‰æ‹©"""
        try:
            # ä½¿ç”¨Fæ£€éªŒé€‰æ‹©æœ€é‡è¦çš„ç‰¹å¾
            selector = SelectKBest(score_func=f_regression, k=max_features)
            X_selected = selector.fit_transform(X, y)
            
            # è·å–é€‰ä¸­çš„ç‰¹å¾ç´¢å¼•
            selected_indices = selector.get_support(indices=True)
            
            # ç”Ÿæˆç‰¹å¾åç§° (ç®€åŒ–ç‰ˆ)
            feature_names = [f"Feature_{i}" for i in selected_indices]
            
            return X_selected, feature_names
            
        except Exception as e:
            logger.error(f"âŒ ç‰¹å¾é€‰æ‹©å¤±è´¥: {e}")
            # å¦‚æœå¤±è´¥ï¼Œéšæœºé€‰æ‹©å‰3ä¸ªç‰¹å¾
            return X[:, :max_features], [f"Feature_{i}" for i in range(max_features)]
    
    def _aggressive_outlier_removal(self, X: np.ndarray, y: np.ndarray, threshold: float = 1.5) -> Tuple[np.ndarray, np.ndarray]:
        """æ¿€è¿›å¼‚å¸¸å€¼å¤„ç†"""
        try:
            # è®¡ç®—æ¯ä¸ªç‰¹å¾çš„IQR
            Q1 = np.percentile(X, 25, axis=0)
            Q3 = np.percentile(X, 75, axis=0)
            IQR = Q3 - Q1
            
            # å®šä¹‰å¼‚å¸¸å€¼è¾¹ç•Œ (æ›´æ¿€è¿›)
            lower_bound = Q1 - threshold * IQR
            upper_bound = Q3 + threshold * IQR
            
            # æ ‡è®°å¼‚å¸¸å€¼
            outlier_mask = np.any((X < lower_bound) | (X > upper_bound), axis=1)
            
            # ç§»é™¤å¼‚å¸¸å€¼
            X_clean = X[~outlier_mask]
            y_clean = y[~outlier_mask]
            
            return X_clean, y_clean
            
        except Exception as e:
            logger.error(f"âŒ å¼‚å¸¸å€¼å¤„ç†å¤±è´¥: {e}")
            return X, y
    
    def _augment_data(self, X: np.ndarray, y: np.ndarray, target_samples: int = 50) -> Tuple[np.ndarray, np.ndarray]:
        """æ•°æ®å¢å¼º"""
        try:
            if len(X) >= target_samples:
                return X, y
            
            # é€šè¿‡æ’å€¼å¢åŠ æ ·æœ¬
            additional_samples = target_samples - len(X)
            
            # åˆ›å»ºæ’å€¼æ ·æœ¬
            X_augmented = []
            y_augmented = []
            
            for i in range(additional_samples):
                # éšæœºé€‰æ‹©ä¸¤ä¸ªç°æœ‰æ ·æœ¬
                idx1, idx2 = np.random.choice(len(X), 2, replace=False)
                
                # æ’å€¼æƒé‡
                alpha = np.random.random()
                
                # æ’å€¼
                X_interp = alpha * X[idx1] + (1 - alpha) * X[idx2]
                y_interp = alpha * y[idx1] + (1 - alpha) * y[idx2]
                
                X_augmented.append(X_interp)
                y_augmented.append(y_interp)
            
            # åˆå¹¶åŸå§‹æ•°æ®å’Œå¢å¼ºæ•°æ®
            X_final = np.vstack([X, np.array(X_augmented)])
            y_final = np.hstack([y, np.array(y_augmented)])
            
            return X_final, y_final
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®å¢å¼ºå¤±è´¥: {e}")
            return X, y

def test_simple_models(X: np.ndarray, y: np.ndarray) -> Dict:
    """æµ‹è¯•ç®€å•æ¨¡å‹"""
    try:
        logger.info("ğŸ§ª æµ‹è¯•ç®€å•æ¨¡å‹...")
        
        # åˆ†å‰²æ•°æ®
        train_size = int(0.8 * len(X))
        X_train, X_test = X[:train_size], X[train_size:]
        y_train, y_test = y[:train_size], y[train_size:]
        
        models = {
            'LinearRegression': LinearRegression(),
            'Ridge': Ridge(alpha=1.0),
            'RandomForest': RandomForestRegressor(n_estimators=10, random_state=42)
        }
        
        results = {}
        
        for name, model in models.items():
            logger.info(f"ğŸ” æµ‹è¯•æ¨¡å‹: {name}")
            
            # è®­ç»ƒ
            model.fit(X_train, y_train)
            
            # é¢„æµ‹
            y_pred = model.predict(X_test)
            
            # è¯„ä¼°
            r2 = r2_score(y_test, y_pred)
            mae = mean_absolute_error(y_test, y_pred)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            
            results[name] = {
                'r2_score': r2,
                'mae': mae,
                'rmse': rmse,
                'status': 'overfitting' if r2 < 0 else 'normal'
            }
            
            logger.info(f"  {name}: RÂ²={r2:.4f}, MAE={mae:.4f}, RMSE={rmse:.4f}")
        
        return results
        
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return {'status': 'error', 'error': str(e)}

def main():
    """ä¸»å‡½æ•°"""
    try:
        logger.info("ğŸš€ å¯åŠ¨æç«¯æ•°æ®ç®€åŒ–...")
        
        # åŠ è½½ERA5æ•°æ®
        from src.models.agriculture.era5_soil_moisture_predictor import ERA5SoilMoisturePredictor
        
        predictor = ERA5SoilMoisturePredictor()
        data = predictor.load_data()
        
        # å±•å¹³æ•°æ®
        X_train = data['X_train'].reshape(-1, data['X_train'].shape[-1])
        y_train = np.repeat(data['y_train'], data['X_train'].shape[1])
        
        logger.info(f"ğŸ“Š åŸå§‹æ•°æ®: X={X_train.shape}, y={y_train.shape}")
        
        # æç«¯æ•°æ®ç®€åŒ–
        simplifier = ExtremeDataSimplifier()
        result = simplifier.extreme_simplify(X_train, y_train)
        
        if result['status'] != 'success':
            logger.error(f"âŒ æ•°æ®ç®€åŒ–å¤±è´¥: {result}")
            return
        
        # æµ‹è¯•ç®€å•æ¨¡å‹
        X_simple = result['X_simplified']
        y_simple = result['y_simplified']
        
        model_results = test_simple_models(X_simple, y_simple)
        
        # ä¿å­˜ç»“æœ
        final_result = {
            'timestamp': datetime.now().isoformat(),
            'data_simplification': result,
            'model_testing': model_results
        }
        
        # ä¿å­˜ç®€åŒ–åçš„æ•°æ®
        output_dir = "data/processed/era5_extreme_simplified"
        os.makedirs(output_dir, exist_ok=True)
        
        np.save(os.path.join(output_dir, 'X_extreme_simplified.npy'), X_simple)
        np.save(os.path.join(output_dir, 'y_extreme_simplified.npy'), y_simple)
        
        # ä¿å­˜ç»“æœæŠ¥å‘Š
        report_file = f"extreme_simplification_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(final_result, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"âœ… ç®€åŒ–åçš„æ•°æ®å·²ä¿å­˜åˆ°: {output_dir}")
        logger.info(f"âœ… ç»“æœæŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        # æ˜¾ç¤ºæœ€ä½³æ¨¡å‹
        if 'status' not in model_results:
            best_model = max(model_results.items(), key=lambda x: x[1]['r2_score'])
            logger.info(f"ğŸ† æœ€ä½³æ¨¡å‹: {best_model[0]}, RÂ²={best_model[1]['r2_score']:.4f}")
            
            if best_model[1]['r2_score'] > 0:
                logger.info("ğŸ‰ æˆåŠŸï¼RÂ²å·²è½¬ä¸ºæ­£å€¼ï¼")
            else:
                logger.info("âš ï¸ RÂ²ä»ä¸ºè´Ÿå€¼ï¼Œéœ€è¦æ›´æ¿€è¿›çš„ç®€åŒ–")
        
        return final_result
        
    except Exception as e:
        logger.error(f"âŒ ä¸»å‡½æ•°æ‰§è¡Œå¤±è´¥: {e}")
        return {'status': 'error', 'error': str(e)}

if __name__ == "__main__":
    main()
