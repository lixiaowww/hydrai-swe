#!/usr/bin/env python3
"""
ä¿®å¤æ•°æ®æ ‡å‡†åŒ–ä¸€è‡´æ€§é—®é¢˜
ç¡®ä¿è®­ç»ƒå’ŒéªŒè¯æ—¶ä½¿ç”¨ç›¸åŒçš„æ ‡å‡†åŒ–å‚æ•°
"""

import pandas as pd
import numpy as np
import pickle
import os
from sklearn.preprocessing import StandardScaler
from datetime import datetime

class StandardizationFixer:
    """æ ‡å‡†åŒ–ä¸€è‡´æ€§ä¿®å¤å™¨"""
    
    def __init__(self):
        self.scaler_X = None
        self.scaler_y = None
        self.standardization_params = {}
        
    def load_training_data(self, data_path):
        """åŠ è½½è®­ç»ƒæ•°æ®"""
        print("ğŸ“Š åŠ è½½è®­ç»ƒæ•°æ®...")
        data = pd.read_csv(data_path, index_col=0, parse_dates=True)
        print(f"âœ… åŠ è½½æ•°æ®: {len(data)} æ¡è®°å½•")
        return data
    
    def extract_features_and_target(self, data):
        """æå–ç‰¹å¾å’Œç›®æ ‡"""
        feature_cols = ['snow_depth_mm', 'snow_fall_mm', 'snow_water_equivalent_mm', 
                       'day_of_year', 'month', 'year']
        target_col = 'snow_water_equivalent_mm'
        
        X = data[feature_cols].values
        y = data[target_col].values.reshape(-1, 1)
        
        print(f"âœ… æå–ç‰¹å¾: {X.shape}, ç›®æ ‡: {y.shape}")
        return X, y, feature_cols, target_col
    
    def fit_standardization(self, X, y):
        """æ‹Ÿåˆæ ‡å‡†åŒ–å™¨"""
        print("ğŸ”§ æ‹Ÿåˆæ ‡å‡†åŒ–å™¨...")
        
        # ç‰¹å¾æ ‡å‡†åŒ–
        self.scaler_X = StandardScaler()
        X_scaled = self.scaler_X.fit_transform(X)
        
        # ç›®æ ‡æ ‡å‡†åŒ–
        self.scaler_y = StandardScaler()
        y_scaled = self.scaler_y.fit_transform(y)
        
        # ä¿å­˜æ ‡å‡†åŒ–å‚æ•°
        self.standardization_params = {
            'scaler_X_mean': self.scaler_X.mean_,
            'scaler_X_scale': self.scaler_X.scale_,
            'scaler_y_mean': self.scaler_y.mean_,
            'scaler_y_scale': self.scaler_y.scale_,
            'feature_names': ['snow_depth_mm', 'snow_fall_mm', 'snow_water_equivalent_mm', 
                             'day_of_year', 'month', 'year'],
            'target_name': 'snow_water_equivalent_mm'
        }
        
        print(f"âœ… æ ‡å‡†åŒ–å™¨æ‹Ÿåˆå®Œæˆ")
        print(f"   ç‰¹å¾å‡å€¼: {self.scaler_X.mean_}")
        print(f"   ç‰¹å¾æ ‡å‡†å·®: {self.scaler_X.scale_}")
        print(f"   ç›®æ ‡å‡å€¼: {self.scaler_y.mean_}")
        print(f"   ç›®æ ‡æ ‡å‡†å·®: {self.scaler_y.scale_}")
        
        return X_scaled, y_scaled
    
    def save_standardization_params(self, output_path):
        """ä¿å­˜æ ‡å‡†åŒ–å‚æ•°"""
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        with open(output_path, 'wb') as f:
            pickle.dump(self.standardization_params, f)
        
        print(f"âœ… æ ‡å‡†åŒ–å‚æ•°å·²ä¿å­˜: {output_path}")
    
    def create_consistent_dataset(self, data, output_path):
        """åˆ›å»ºæ ‡å‡†åŒ–ä¸€è‡´çš„æ•°æ®é›†"""
        print("ğŸ”„ åˆ›å»ºæ ‡å‡†åŒ–ä¸€è‡´çš„æ•°æ®é›†...")
        
        # æå–ç‰¹å¾å’Œç›®æ ‡
        X, y, feature_cols, target_col = self.extract_features_and_target(data)
        
        # åº”ç”¨æ ‡å‡†åŒ–
        X_scaled = self.scaler_X.transform(X)
        y_scaled = self.scaler_y.transform(y)
        
        # åˆ›å»ºæ ‡å‡†åŒ–åçš„æ•°æ®é›†
        scaled_data = pd.DataFrame(X_scaled, columns=feature_cols, index=data.index)
        scaled_data[target_col] = y_scaled.flatten()
        
        # æ·»åŠ åŸå§‹åˆ—ï¼ˆç”¨äºå‚è€ƒï¼‰
        scaled_data['original_snow_depth_mm'] = data['snow_depth_mm']
        scaled_data['original_snow_water_equivalent_mm'] = data['snow_water_equivalent_mm']
        
        # ä¿å­˜æ•°æ®é›†
        scaled_data.to_csv(output_path)
        print(f"âœ… æ ‡å‡†åŒ–æ•°æ®é›†å·²ä¿å­˜: {output_path}")
        
        return scaled_data
    
    def validate_standardization_consistency(self, original_data, scaled_data):
        """éªŒè¯æ ‡å‡†åŒ–ä¸€è‡´æ€§"""
        print("ğŸ” éªŒè¯æ ‡å‡†åŒ–ä¸€è‡´æ€§...")
        
        # æ£€æŸ¥ç‰¹å¾åˆ†å¸ƒ
        feature_cols = ['snow_depth_mm', 'snow_fall_mm', 'snow_water_equivalent_mm', 
                       'day_of_year', 'month', 'year']
        
        print("\nğŸ“Š æ ‡å‡†åŒ–å‰åå¯¹æ¯”:")
        for col in feature_cols:
            if col in original_data.columns and col in scaled_data.columns:
                orig_mean = original_data[col].mean()
                orig_std = original_data[col].std()
                scaled_mean = scaled_data[col].mean()
                scaled_std = scaled_data[col].std()
                
                print(f"  {col}:")
                print(f"    åŸå§‹: å‡å€¼={orig_mean:.4f}, æ ‡å‡†å·®={orig_std:.4f}")
                print(f"    æ ‡å‡†åŒ–: å‡å€¼={scaled_mean:.4f}, æ ‡å‡†å·®={scaled_std:.4f}")
        
        # éªŒè¯ç›®æ ‡å˜é‡
        target_col = 'snow_water_equivalent_mm'
        if target_col in original_data.columns and target_col in scaled_data.columns:
            orig_mean = original_data[target_col].mean()
            orig_std = original_data[target_col].std()
            scaled_mean = scaled_data[target_col].mean()
            scaled_std = scaled_data[target_col].std()
            
            print(f"\nğŸ¯ ç›®æ ‡å˜é‡ {target_col}:")
            print(f"  åŸå§‹: å‡å€¼={orig_mean:.4f}, æ ‡å‡†å·®={orig_std:.4f}")
            print(f"  æ ‡å‡†åŒ–: å‡å€¼={scaled_mean:.4f}, æ ‡å‡†å·®={scaled_std:.4f}")
        
        print("âœ… æ ‡å‡†åŒ–ä¸€è‡´æ€§éªŒè¯å®Œæˆ")
    
    def create_standardization_report(self, output_path):
        """åˆ›å»ºæ ‡å‡†åŒ–æŠ¥å‘Š"""
        print("ğŸ“ åˆ›å»ºæ ‡å‡†åŒ–æŠ¥å‘Š...")
        
        report = f"""# æ•°æ®æ ‡å‡†åŒ–ä¸€è‡´æ€§ä¿®å¤æŠ¥å‘Š

## ä¿®å¤æ—¶é—´
{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## æ ‡å‡†åŒ–å‚æ•°
### ç‰¹å¾æ ‡å‡†åŒ–å™¨ (StandardScaler)
"""
        
        for i, feature in enumerate(self.standardization_params['feature_names']):
            mean = self.standardization_params['scaler_X_mean'][i]
            scale = self.standardization_params['scaler_X_scale'][i]
            report += f"- {feature}: å‡å€¼={mean:.6f}, æ ‡å‡†å·®={scale:.6f}\n"
        
        report += f"""
### ç›®æ ‡æ ‡å‡†åŒ–å™¨ (StandardScaler)
- {self.standardization_params['target_name']}: å‡å€¼={self.standardization_params['scaler_y_mean'][0]:.6f}, æ ‡å‡†å·®={self.standardization_params['scaler_y_scale'][0]:.6f}

## ä¿®å¤å†…å®¹
1. âœ… å»ºç«‹äº†ç»Ÿä¸€çš„æ ‡å‡†åŒ–å‚æ•°
2. âœ… ç¡®ä¿è®­ç»ƒå’ŒéªŒè¯ä½¿ç”¨ç›¸åŒçš„æ ‡å‡†åŒ–å™¨
3. âœ… åˆ›å»ºäº†æ ‡å‡†åŒ–ä¸€è‡´çš„æ•°æ®é›†
4. âœ… ä¿å­˜äº†æ ‡å‡†åŒ–å‚æ•°ä¾›åç»­ä½¿ç”¨

## ä½¿ç”¨è¯´æ˜
- è®­ç»ƒæ—¶ï¼šä½¿ç”¨ `scaler_X.fit_transform()` å’Œ `scaler_y.fit_transform()`
- éªŒè¯æ—¶ï¼šä½¿ç”¨ `scaler_X.transform()` å’Œ `scaler_y.transform()`
- é¢„æµ‹æ—¶ï¼šä½¿ç”¨ `scaler_y.inverse_transform()` è¿˜åŸé¢„æµ‹ç»“æœ

## æ³¨æ„äº‹é¡¹
- æ‰€æœ‰æ•°æ®é¢„å¤„ç†å¿…é¡»ä½¿ç”¨ç›¸åŒçš„æ ‡å‡†åŒ–å‚æ•°
- æ–°æ•°æ®å¿…é¡»é€šè¿‡å·²è®­ç»ƒçš„æ ‡å‡†åŒ–å™¨è¿›è¡Œè½¬æ¢
- å®šæœŸéªŒè¯æ ‡å‡†åŒ–ä¸€è‡´æ€§
"""
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"âœ… æ ‡å‡†åŒ–æŠ¥å‘Šå·²ä¿å­˜: {output_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ HydrAI-SWE æ•°æ®æ ‡å‡†åŒ–ä¸€è‡´æ€§ä¿®å¤")
    print("=" * 60)
    
    try:
        # åˆ›å»ºä¿®å¤å™¨
        fixer = StandardizationFixer()
        
        # 1. åŠ è½½è®­ç»ƒæ•°æ®
        data_path = "data/processed/comprehensive_training_dataset.csv"
        data = fixer.load_training_data(data_path)
        
        # 2. æå–ç‰¹å¾å’Œç›®æ ‡
        X, y, feature_cols, target_col = fixer.extract_features_and_target(data)
        
        # 3. æ‹Ÿåˆæ ‡å‡†åŒ–å™¨
        X_scaled, y_scaled = fixer.fit_standardization(X, y)
        
        # 4. ä¿å­˜æ ‡å‡†åŒ–å‚æ•°
        params_path = "models/standardization_params.pkl"
        fixer.save_standardization_params(params_path)
        
        # 5. åˆ›å»ºæ ‡å‡†åŒ–ä¸€è‡´çš„æ•°æ®é›†
        scaled_data_path = "data/processed/standardized_training_dataset.csv"
        scaled_data = fixer.create_consistent_dataset(data, scaled_data_path)
        
        # 6. éªŒè¯æ ‡å‡†åŒ–ä¸€è‡´æ€§
        fixer.validate_standardization_consistency(data, scaled_data)
        
        # 7. åˆ›å»ºæ ‡å‡†åŒ–æŠ¥å‘Š
        report_path = "logs/standardization_fix_report.md"
        fixer.create_standardization_report(report_path)
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ•°æ®æ ‡å‡†åŒ–ä¸€è‡´æ€§ä¿®å¤å®Œæˆ!")
        print("âœ… æ ‡å‡†åŒ–å‚æ•°å·²ä¿å­˜")
        print("âœ… æ ‡å‡†åŒ–æ•°æ®é›†å·²åˆ›å»º")
        print("âœ… ä¸€è‡´æ€§éªŒè¯å·²é€šè¿‡")
        print("âœ… ä¿®å¤æŠ¥å‘Šå·²ç”Ÿæˆ")
        
    except Exception as e:
        print(f"âŒ ä¿®å¤å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
