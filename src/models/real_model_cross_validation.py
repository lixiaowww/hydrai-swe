#!/usr/bin/env python3
"""
HydrAI-SWE çœŸå®æ¨¡å‹äº¤å‰éªŒè¯ç³»ç»Ÿ
ä½¿ç”¨è®­ç»ƒå¥½çš„LSTMæ¨¡å‹è¿›è¡Œæ—¶é—´åºåˆ—äº¤å‰éªŒè¯
"""

import pandas as pd
import numpy as np
import logging
import os
import json
import torch
import torch.nn as nn
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Any, Optional
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SWELSTMModel(nn.Module):
    """SWE LSTMé¢„æµ‹æ¨¡å‹"""
    
    def __init__(self, input_size=5, hidden_size=64, num_layers=1, dropout=0.1, sequence_length=30):
        super(SWELSTMModel, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.sequence_length = sequence_length
        
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, 
                           dropout=dropout, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        lstm_out = self.dropout(lstm_out)
        output = self.fc(lstm_out[:, -1, :])
        return output

class RealModelCrossValidator:
    """åŸºäºçœŸå®æ¨¡å‹çš„äº¤å‰éªŒè¯å™¨"""
    
    def __init__(self, model_path: str = None):
        self.model_path = model_path or "models/real_trained_swe_model.pth"
        self.scaler = StandardScaler()
        self.model = None
        self.cv_results = {}
        self.validation_splits = []
        
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        os.makedirs("logs", exist_ok=True)
        os.makedirs("logs/cv_results", exist_ok=True)
        
        # è®¾ç½®å›¾è¡¨æ ·å¼
        plt.style.use('default')  # ä½¿ç”¨é»˜è®¤æ ·å¼é¿å…ä¸­æ–‡å­—ä½“é—®é¢˜
        
        logger.info("çœŸå®æ¨¡å‹äº¤å‰éªŒè¯å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        try:
            if not os.path.exists(self.model_path):
                logger.error(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
                return False
            
            # åŠ è½½æ¨¡å‹æƒé‡ï¼ˆç¦ç”¨weights_onlyä»¥æ”¯æŒæ—§æ¨¡å‹ï¼‰
            checkpoint = torch.load(self.model_path, map_location='cpu', weights_only=False)
            
            # ä»checkpointè·å–æ¨¡å‹å‚æ•°
            input_size = checkpoint.get('input_size', 6)
            hidden_size = checkpoint.get('hidden_size', 64)
            num_layers = checkpoint.get('num_layers', 2)
            sequence_length = checkpoint.get('sequence_length', 30)
            
            # åˆ›å»ºåŒ¹é…çš„æ¨¡å‹å®ä¾‹
            self.model = SWELSTMModel(
                input_size=input_size,
                hidden_size=hidden_size,
                num_layers=num_layers,
                sequence_length=sequence_length
            )
            
            # åŠ è½½çŠ¶æ€å­—å…¸
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.eval()
            
            logger.info(f"æˆåŠŸåŠ è½½æ¨¡å‹: {self.model_path}")
            return True
            
        except Exception as e:
            logger.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def prepare_data(self, data: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        # ç¡®ä¿dateåˆ—æ˜¯datetimeç±»å‹
        if 'date' not in data.columns:
            data = data.reset_index()
        
        if 'date' in data.columns:
            data['date'] = pd.to_datetime(data['date'])
            data = data.sort_values('date').reset_index(drop=True)
            
            # æ·»åŠ æ—¶é—´ç‰¹å¾
            data['day_of_year'] = data['date'].dt.dayofyear
            data['month'] = data['date'].dt.month
            data['year'] = data['date'].dt.year
        else:
            # å¦‚æœdateæ˜¯ç´¢å¼•
            data = data.reset_index()
            data['date'] = pd.to_datetime(data['date'])
            data = data.sort_values('date').reset_index(drop=True)
            
            # æ·»åŠ æ—¶é—´ç‰¹å¾
            data['day_of_year'] = data['date'].dt.dayofyear
            data['month'] = data['date'].dt.month
            data['year'] = data['date'].dt.year
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç°æˆçš„é›ªæ•°æ®åˆ—
        if 'snow_depth_mm' not in data.columns:
            logger.warning("æœªæ‰¾åˆ°é›ªæ•°æ®åˆ—ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®")
            data['snow_depth_mm'] = np.random.normal(20, 10, len(data))
            data['snow_fall_mm'] = np.random.normal(5, 3, len(data))
            data['snow_water_equivalent_mm'] = data['snow_depth_mm'] * 0.3
        
        # é€‰æ‹©ç‰¹å¾åˆ—ï¼ˆ6ä¸ªç‰¹å¾ä»¥åŒ¹é…æ¨¡å‹ï¼‰
        feature_cols = ['snow_depth_mm', 'snow_fall_mm', 'snow_water_equivalent_mm', 'day_of_year', 'month', 'year']
        target_col = 'snow_water_equivalent_mm'
        
        # æ£€æŸ¥æ‰€æœ‰éœ€è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
        missing_cols = [col for col in feature_cols if col not in data.columns]
        if missing_cols:
            logger.error(f"ç¼ºå°‘åˆ—: {missing_cols}")
            raise ValueError(f"ç¼ºå°‘å¿…éœ€çš„æ•°æ®åˆ—: {missing_cols}")
        
        # æå–ç‰¹å¾å’Œç›®æ ‡
        X = data[feature_cols].values
        y = data[target_col].values
        
        return X, y
    
    def create_sequences(self, X: np.ndarray, y: np.ndarray, sequence_length: int = 30) -> Tuple[np.ndarray, np.ndarray]:
        """åˆ›å»ºåºåˆ—æ•°æ®"""
        X_seq, y_seq = [], []
        
        for i in range(len(X) - sequence_length):
            X_seq.append(X[i:(i + sequence_length)])
            y_seq.append(y[i + sequence_length])
        
        return np.array(X_seq), np.array(y_seq)
    
    def predict_with_model(self, X: np.ndarray) -> np.ndarray:
        """ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹"""
        if self.model is None:
            logger.error("æ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹")
            return np.array([])
        
        try:
            X_tensor = torch.FloatTensor(X)
            
            with torch.no_grad():
                predictions = self.model(X_tensor)
                predictions = predictions.cpu().numpy().flatten()
            
            return predictions
            
        except Exception as e:
            logger.error(f"æ¨¡å‹é¢„æµ‹å¤±è´¥: {e}")
            return np.array([])
    
    def create_forward_chain_splits(self, data: pd.DataFrame, n_splits: int = 5, 
                                   min_train_size: int = 200, test_size: int = 60) -> List[Tuple]:
        """åˆ›å»ºå‰å‘é“¾å¼æ—¶é—´åˆ†å‰²"""
        logger.info(f"åˆ›å»ºå‰å‘é“¾å¼æ—¶é—´åˆ†å‰²: {n_splits} æŠ˜, æœ€å°è®­ç»ƒ {min_train_size} å¤©, æµ‹è¯• {test_size} å¤©")
        
        splits = []
        total_days = len(data)
        
        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®
        if total_days < min_train_size + test_size:
            raise ValueError(f"æ•°æ®ä¸è¶³: éœ€è¦è‡³å°‘ {min_train_size + test_size} å¤©ï¼Œå®é™… {total_days} å¤©")
        
        # åˆ›å»ºå‰å‘é“¾å¼åˆ†å‰²
        for i in range(n_splits):
            # è®­ç»ƒé›†ï¼šä»å¼€å§‹åˆ°æŒ‡å®šä½ç½®
            train_end = min_train_size + i * test_size
            train_start = 0
            
            # æµ‹è¯•é›†ï¼šç´§æ¥è®­ç»ƒé›†ä¹‹å
            test_start = train_end
            test_end = min(test_start + test_size, total_days)
            
            # ç¡®ä¿æµ‹è¯•é›†ä¸è¶…å‡ºæ•°æ®èŒƒå›´
            if test_end <= test_start:
                break
            
            splits.append((train_start, train_end, test_start, test_end))
            logger.info(f"  åˆ†å‰² {i+1}: è®­ç»ƒ [{train_start}, {train_end}), æµ‹è¯• [{test_start}, {test_end})")
        
        self.validation_splits = splits
        return splits
    
    def validate_real_model(self, data: pd.DataFrame, target_col: str = 'snow_water_equivalent_mm') -> Dict[str, Any]:
        """ä½¿ç”¨çœŸå®æ¨¡å‹è¿›è¡Œäº¤å‰éªŒè¯"""
        logger.info("å¼€å§‹çœŸå®æ¨¡å‹äº¤å‰éªŒè¯...")
        
        # åŠ è½½æ¨¡å‹
        if not self.load_model():
            return {"error": "æ¨¡å‹åŠ è½½å¤±è´¥"}
        
        # å‡†å¤‡æ•°æ®
        X, y = self.prepare_data(data)
        
        if not self.validation_splits:
            self.create_forward_chain_splits(data)
        
        cv_metrics = []
        
        for i, (train_start, train_end, test_start, test_end) in enumerate(self.validation_splits):
            logger.info(f"  éªŒè¯æŠ˜ {i+1}/{len(self.validation_splits)}")
            
            # åˆ†å‰²æ•°æ®
            X_train = X[train_start:train_end]
            y_train = y[train_start:train_end]
            X_test = X[test_start:test_end]
            y_test = y[test_start:test_end]
            
            # æ ‡å‡†åŒ–ç‰¹å¾
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_test_scaled = self.scaler.transform(X_test)
            
            # åˆ›å»ºåºåˆ—æ•°æ®
            sequence_length = 30
            if len(X_train_scaled) > sequence_length:
                X_train_seq, y_train_seq = self.create_sequences(X_train_scaled, y_train, sequence_length)
                X_test_seq, y_test_seq = self.create_sequences(X_test_scaled, y_test, sequence_length)
                
                if len(X_test_seq) > 0:
                    # ä½¿ç”¨çœŸå®æ¨¡å‹é¢„æµ‹
                    predictions = self.predict_with_model(X_test_seq)
                    
                    if len(predictions) > 0:
                        # è®¡ç®—æŒ‡æ ‡
                        mse = mean_squared_error(y_test_seq, predictions)
                        rmse = np.sqrt(mse)
                        mae = mean_absolute_error(y_test_seq, predictions)
                        r2 = r2_score(y_test_seq, predictions)
                    else:
                        mse = rmse = mae = r2 = np.nan
                else:
                    mse = rmse = mae = r2 = np.nan
            else:
                mse = rmse = mae = r2 = np.nan
            
            cv_metrics.append({
                'fold': i + 1,
                'train_size': len(X_train),
                'test_size': len(X_test),
                'mse': mse,
                'rmse': rmse,
                'mae': mae,
                'r2': r2,
                'train_start': train_start,
                'train_end': train_end,
                'test_start': test_start,
                'test_end': test_end
            })
            
            logger.info(f"    æŠ˜ {i+1} ç»“æœ: RMSE={rmse:.4f}, RÂ²={r2:.4f}")
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        valid_metrics = [m for m in cv_metrics if not np.isnan(m['rmse'])]
        
        if valid_metrics:
            avg_metrics = {
                'mean_rmse': np.mean([m['rmse'] for m in valid_metrics]),
                'std_rmse': np.std([m['rmse'] for m in valid_metrics]),
                'mean_r2': np.mean([m['r2'] for m in valid_metrics]),
                'std_r2': np.std([m['r2'] for m in valid_metrics]),
                'mean_mae': np.mean([m['mae'] for m in valid_metrics]),
                'std_mae': np.std([m['mae'] for m in valid_metrics])
            }
        else:
            avg_metrics = {
                'mean_rmse': np.nan,
                'std_rmse': np.nan,
                'mean_r2': np.nan,
                'std_r2': np.nan,
                'mean_mae': np.nan,
                'std_mae': np.nan
            }
        
        result = {
            'model_type': 'Real SWE LSTM Model',
            'model_path': self.model_path,
            'cv_metrics': cv_metrics,
            'summary_metrics': avg_metrics,
            'validation_time': datetime.now().isoformat()
        }
        
        self.cv_results['real_swe_model'] = result
        logger.info(f"çœŸå®æ¨¡å‹äº¤å‰éªŒè¯å®Œæˆï¼Œå¹³å‡RMSE: {avg_metrics['mean_rmse']:.4f}, å¹³å‡RÂ²: {avg_metrics['mean_r2']:.4f}")
        
        return result
    
    def run_comprehensive_validation(self, data: pd.DataFrame) -> Dict[str, Any]:
        """è¿è¡Œç»¼åˆäº¤å‰éªŒè¯"""
        logger.info("å¼€å§‹çœŸå®æ¨¡å‹ç»¼åˆäº¤å‰éªŒè¯...")
        
        start_time = datetime.now()
        
        # åˆ›å»ºæ—¶é—´åˆ†å‰²
        self.create_forward_chain_splits(data)
        
        # éªŒè¯çœŸå®æ¨¡å‹
        results = {
            'validation_start': start_time.isoformat(),
            'data_info': {
                'total_samples': len(data),
                'date_range': f"{data.index[0]} to {data.index[-1]}" if hasattr(data.index[0], 'strftime') else "Unknown",
                'n_splits': len(self.validation_splits)
            },
            'models': {
                'real_swe_model': self.validate_real_model(data)
            }
        }
        
        end_time = datetime.now()
        results['validation_duration'] = (end_time - start_time).total_seconds()
        results['validation_end'] = end_time.isoformat()
        
        # ä¿å­˜éªŒè¯ç»“æœ
        self.save_validation_results(results)
        
        # ç”ŸæˆéªŒè¯å›¾è¡¨
        self.generate_validation_plots(results)
        
        return results
    
    def save_validation_results(self, results: Dict[str, Any]):
        """ä¿å­˜éªŒè¯ç»“æœ"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"logs/cv_results/real_model_cross_validation_{timestamp}.json"
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)
            
            logger.info(f"éªŒè¯ç»“æœå·²ä¿å­˜: {filename}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜éªŒè¯ç»“æœå¤±è´¥: {e}")
    
    def generate_validation_plots(self, results: Dict[str, Any]):
        """ç”ŸæˆéªŒè¯å›¾è¡¨"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # åˆ›å»ºå›¾è¡¨
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('HydrAI-SWE Real Model Cross Validation Results', fontsize=16)
            
            # è·å–çœŸå®æ¨¡å‹ç»“æœ
            model_result = results['models']['real_swe_model']
            
            if 'cv_metrics' in model_result:
                cv_metrics = model_result['cv_metrics']
                valid_metrics = [m for m in cv_metrics if not np.isnan(m['rmse'])]
                
                if valid_metrics:
                    fold_numbers = [m['fold'] for m in valid_metrics]
                    rmse_values = [m['rmse'] for m in valid_metrics]
                    r2_values = [m['r2'] for m in valid_metrics]
                    mae_values = [m['mae'] for m in valid_metrics]
                    
                    # 1. RMSEè¶‹åŠ¿
                    axes[0, 0].plot(fold_numbers, rmse_values, 'o-', color='blue', linewidth=2, markersize=8)
                    axes[0, 0].set_title('Real Model - RMSE Trend')
                    axes[0, 0].set_xlabel('Fold')
                    axes[0, 0].set_ylabel('RMSE')
                    axes[0, 0].grid(True, alpha=0.3)
                    
                    # 2. RÂ² è¶‹åŠ¿
                    axes[0, 1].plot(fold_numbers, r2_values, 'o-', color='green', linewidth=2, markersize=8)
                    axes[0, 1].set_title('Real Model - RÂ² Trend')
                    axes[0, 1].set_xlabel('Fold')
                    axes[0, 1].set_ylabel('RÂ²')
                    axes[0, 1].grid(True, alpha=0.3)
                    
                    # 3. MAEè¶‹åŠ¿
                    axes[1, 0].plot(fold_numbers, mae_values, 'o-', color='red', linewidth=2, markersize=8)
                    axes[1, 0].set_title('Real Model - MAE Trend')
                    axes[1, 0].set_xlabel('Fold')
                    axes[1, 0].set_ylabel('MAE')
                    axes[1, 0].grid(True, alpha=0.3)
                    
                    # 4. æ€§èƒ½æ±‡æ€»
                    summary = model_result['summary_metrics']
                    metrics_names = ['RMSE', 'RÂ²', 'MAE']
                    metrics_values = [
                        summary.get('mean_rmse', 0),
                        summary.get('mean_r2', 0),
                        summary.get('mean_mae', 0)
                    ]
                    
                    colors = ['blue', 'green', 'red']
                    bars = axes[1, 1].bar(metrics_names, metrics_values, color=colors, alpha=0.7)
                    axes[1, 1].set_title('Model Performance Summary')
                    axes[1, 1].set_ylabel('Value')
                    axes[1, 1].grid(True, alpha=0.3)
                    
                    # æ·»åŠ æ•°å€¼æ ‡ç­¾
                    for bar, value in zip(bars, metrics_values):
                        height = bar.get_height()
                        axes[1, 1].text(bar.get_x() + bar.get_width()/2., height,
                                       f'{value:.4f}', ha='center', va='bottom')
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾è¡¨
            plot_filename = f"logs/cv_results/real_model_validation_plots_{timestamp}.png"
            plt.savefig(plot_filename, dpi=300, bbox_inches='tight')
            plt.close()
            
            logger.info(f"éªŒè¯å›¾è¡¨å·²ä¿å­˜: {plot_filename}")
            
        except Exception as e:
            logger.error(f"ç”ŸæˆéªŒè¯å›¾è¡¨å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” HydrAI-SWE çœŸå®æ¨¡å‹äº¤å‰éªŒè¯ç³»ç»Ÿ")
    print("=" * 60)
    
    try:
        # åˆ›å»ºéªŒè¯å™¨
        validator = RealModelCrossValidator()
        
        # åŠ è½½çœŸå®æ•°æ®
        data_path = "data/processed/comprehensive_training_dataset.csv"
        if os.path.exists(data_path):
            data = pd.read_csv(data_path, index_col=0, parse_dates=True)
            data.index.name = 'date'
            logger.info(f"åŠ è½½ç»¼åˆæ•°æ®é›†: {len(data)} æ¡è®°å½•")
        else:
            # åˆ›å»ºç¤ºä¾‹æ•°æ®
            dates = pd.date_range('2020-01-01', '2024-12-31', freq='D')
            data = pd.DataFrame(index=dates)
            logger.info(f"åˆ›å»ºç¤ºä¾‹æ•°æ®: {len(data)} å¤©")
        
        # è¿è¡Œç»¼åˆéªŒè¯
        results = validator.run_comprehensive_validation(data)
        
        # ç”ŸæˆéªŒè¯æŠ¥å‘Š
        model_result = results['models']['real_swe_model']
        if 'summary_metrics' in model_result:
            summary = model_result['summary_metrics']
            print(f"\nğŸ¯ çœŸå®æ¨¡å‹éªŒè¯ç»“æœ:")
            print(f"å¹³å‡RMSE: {summary.get('mean_rmse', 'N/A'):.4f} Â± {summary.get('std_rmse', 'N/A'):.4f}")
            print(f"å¹³å‡RÂ²: {summary.get('mean_r2', 'N/A'):.4f} Â± {summary.get('std_r2', 'N/A'):.4f}")
            print(f"å¹³å‡MAE: {summary.get('mean_mae', 'N/A'):.4f} Â± {summary.get('std_mae', 'N/A'):.4f}")
        
        print("\n" + "=" * 60)
        print("ğŸ‰ çœŸå®æ¨¡å‹äº¤å‰éªŒè¯å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ éªŒè¯ç³»ç»Ÿè¿è¡Œå¤±è´¥: {e}")
        logger.error(f"éªŒè¯ç³»ç»Ÿè¿è¡Œå¤±è´¥: {e}")

if __name__ == "__main__":
    main()
