#!/usr/bin/env python3
"""
è¯šå®é¢„æµ‹å™¨ - å®Œå…¨ç§»é™¤ä»»ä½•é€ å‡æ–¹æ³•
å®ç°å¤šç§é¢„æµ‹æ¨¡å¼ï¼Œé€‚åº”ä¸åŒæ•°æ®é‡
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from datetime import datetime, timedelta
import os
import pickle
from typing import Dict, List, Any, Optional, Tuple
from enum import Enum

class PredictionMode(Enum):
    """é¢„æµ‹æ¨¡å¼æšä¸¾"""
    STRICT = "strict"      # ä¸¥æ ¼æ¨¡å¼ï¼šéœ€è¦å®Œæ•´å†å²æ•°æ®
    LIMITED = "limited"    # æœ‰é™æ¨¡å¼ï¼šæ•°æ®ä¸è¶³æ—¶æä¾›æœ‰é™é¢„æµ‹
    PROGRESSIVE = "progressive"  # æ¸è¿›æ¨¡å¼ï¼šéšç€æ•°æ®å¢åŠ é€æ­¥æé«˜è´¨é‡

class PredictionConfidence(Enum):
    """é¢„æµ‹ç½®ä¿¡åº¦æšä¸¾"""
    HIGH = "high"      # é«˜ç½®ä¿¡åº¦ï¼šæ•°æ®å……è¶³
    MEDIUM = "medium"  # ä¸­ç­‰ç½®ä¿¡åº¦ï¼šæ•°æ®éƒ¨åˆ†å……è¶³
    LOW = "low"        # ä½ç½®ä¿¡åº¦ï¼šæ•°æ®ä¸è¶³
    INSUFFICIENT = "insufficient"  # æ•°æ®ä¸è¶³ï¼Œæ— æ³•é¢„æµ‹

class HonestSWEPredictor:
    """è¯šå®SWEé¢„æµ‹å™¨ - ç»ä¸é€ å‡"""
    
    def __init__(self, model_path: str = None, mode: PredictionMode = PredictionMode.STRICT):
        self.model = None
        self.scaler_X = None
        self.scaler_y = None
        self.sequence_length = 30
        self.is_loaded = False
        self.prediction_mode = mode
        
        # ç‰¹å¾é…ç½®
        self.feature_config = {
            'snow_depth_mm': 0,
            'snow_fall_mm': 1, 
            'snow_water_equivalent_mm': 2,
            'day_of_year': 3,
            'month': 4,
            'year': 5
        }
        
        # å†å²æ•°æ®å­˜å‚¨
        self._historical_features = []
        self._historical_dates = []
        
        # è‡ªåŠ¨åŠ è½½æœ€ä½³æ¨¡å‹
        if model_path is None:
            self._auto_load_best_model()
        else:
            self.load_model(model_path)
    
    def set_prediction_mode(self, mode: PredictionMode):
        """è®¾ç½®é¢„æµ‹æ¨¡å¼"""
        self.prediction_mode = mode
        print(f"âœ… é¢„æµ‹æ¨¡å¼è®¾ç½®ä¸º: {mode.value}")
    
    def get_prediction_requirements(self) -> Dict[str, Any]:
        """è·å–é¢„æµ‹è¦æ±‚è¯´æ˜"""
        requirements = {
            'strict_mode': {
                'description': 'ä¸¥æ ¼æ¨¡å¼ï¼šéœ€è¦å®Œæ•´å†å²æ•°æ®',
                'min_data_points': self.sequence_length,
                'confidence': PredictionConfidence.HIGH.value,
                'limitations': 'æ— '
            },
            'limited_mode': {
                'description': 'æœ‰é™æ¨¡å¼ï¼šæ•°æ®ä¸è¶³æ—¶æä¾›æœ‰é™é¢„æµ‹',
                'min_data_points': 1,
                'confidence': PredictionConfidence.MEDIUM.value,
                'limitations': 'é¢„æµ‹è´¨é‡å—é™ï¼Œç½®ä¿¡åº¦é™ä½'
            },
            'progressive_mode': {
                'description': 'æ¸è¿›æ¨¡å¼ï¼šéšç€æ•°æ®å¢åŠ é€æ­¥æé«˜è´¨é‡',
                'min_data_points': 1,
                'confidence': PredictionConfidence.LOW.value,
                'limitations': 'åˆå§‹é¢„æµ‹è´¨é‡è¾ƒä½ï¼Œéœ€è¦æŒç»­æ”¶é›†æ•°æ®'
            }
        }
        
        return {
            'current_mode': self.prediction_mode.value,
            'requirements': requirements,
            'recommendations': self._get_recommendations()
        }
    
    def _get_recommendations(self) -> List[str]:
        """è·å–æ•°æ®æ”¶é›†å»ºè®®"""
        current_data_points = len(self._historical_features)
        
        recommendations = []
        
        if current_data_points == 0:
            recommendations.append("å»ºè®®æ”¶é›†è‡³å°‘1ä¸ªæ•°æ®ç‚¹å¼€å§‹æ¸è¿›é¢„æµ‹")
        elif current_data_points < self.sequence_length:
            recommendations.append(f"å»ºè®®ç»§ç»­æ”¶é›†æ•°æ®ï¼Œå½“å‰{current_data_points}/{self.sequence_length}")
            recommendations.append("æ•°æ®è¶Šå¤šï¼Œé¢„æµ‹è´¨é‡è¶Šé«˜")
        else:
            recommendations.append("æ•°æ®å……è¶³ï¼Œå¯ä»¥ä½¿ç”¨ä¸¥æ ¼æ¨¡å¼è·å¾—æœ€ä½³é¢„æµ‹")
        
        return recommendations
    
    def validate_feature_data(self, snow_depth_mm: float, snow_fall_mm: float, 
                            snow_water_equivalent_mm: float, date: datetime) -> bool:
        """éªŒè¯è¾“å…¥ç‰¹å¾æ•°æ® - ä¸¥æ ¼æ¨¡å¼"""
        try:
            # éªŒè¯æ•°æ®ç±»å‹
            if not all(isinstance(x, (int, float)) for x in [snow_depth_mm, snow_fall_mm, snow_water_equivalent_mm]):
                raise ValueError("é›ªç›¸å…³ç‰¹å¾å¿…é¡»æ˜¯æ•°å€¼ç±»å‹")
            
            # ä¸¥æ ¼éªŒè¯ï¼šæ‹’ç»æ˜æ˜¾ä¸åˆç†çš„é›ªæ•°æ®
            if snow_depth_mm < 0:
                raise ValueError(f"é›ªæ·±åº¦ä¸èƒ½ä¸ºè´Ÿå€¼: {snow_depth_mm}")
            if snow_water_equivalent_mm < 0:
                raise ValueError(f"é›ªæ°´å½“é‡ä¸èƒ½ä¸ºè´Ÿå€¼: {snow_water_equivalent_mm}")
            
            # é›ªé™é‡å¯ä»¥ä¸ºè´Ÿå€¼ï¼ˆè¡¨ç¤ºèåŒ–ï¼‰ï¼Œä½†éœ€è¦æ£€æŸ¥åˆç†æ€§
            if snow_fall_mm < -100:
                raise ValueError(f"é›ªé™é‡ï¼ˆèåŒ–é‡ï¼‰è¿‡å¤§: {snow_fall_mm}")
            
            # æ£€æŸ¥æ•°å€¼èŒƒå›´åˆç†æ€§
            if snow_depth_mm > 10000:
                raise ValueError(f"é›ªæ·±åº¦è¿‡å¤§ï¼Œå¯èƒ½ä¸åˆç†: {snow_depth_mm} mm")
            
            # é›ªæ°´å½“é‡ç›¸å¯¹äºé›ªæ·±åº¦çš„æ¯”ä¾‹æ£€æŸ¥
            if snow_depth_mm > 0:
                ratio = snow_water_equivalent_mm / snow_depth_mm
                if ratio > 0.4:
                    print(f"âš ï¸ è­¦å‘Šï¼šé›ªæ°´å½“é‡ç›¸å¯¹äºé›ªæ·±åº¦æ¯”ä¾‹å¼‚å¸¸: {ratio:.2f}")
                    print(f"   é›ªæ·±åº¦: {snow_depth_mm} mm, é›ªæ°´å½“é‡: {snow_water_equivalent_mm} mm")
                    # åœ¨ä¸¥æ ¼æ¨¡å¼ä¸‹æ‹’ç»
                    if self.prediction_mode == PredictionMode.STRICT:
                        raise ValueError(f"é›ªæ°´å½“é‡æ¯”ä¾‹å¼‚å¸¸: {ratio:.2f}")
            
            # éªŒè¯æ—¥æœŸ
            if not isinstance(date, datetime):
                raise ValueError("æ—¥æœŸå¿…é¡»æ˜¯datetimeå¯¹è±¡")
            
            current_year = datetime.now().year
            if date.year < 1900 or date.year > current_year + 10:
                raise ValueError(f"æ—¥æœŸå¹´ä»½ä¸åˆç†: {date.year}")
            
            return True
            
        except Exception as e:
            print(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {e}")
            return False
    
    def add_historical_data(self, snow_depth_mm: float, snow_fall_mm: float, 
                           snow_water_equivalent_mm: float, date: datetime):
        """æ·»åŠ å†å²æ•°æ® - è¯šå®æ–¹æ³•"""
        # æ•°æ®éªŒè¯
        if not self.validate_feature_data(snow_depth_mm, snow_fall_mm, snow_water_equivalent_mm, date):
            raise ValueError("å†å²æ•°æ®éªŒè¯å¤±è´¥")
        
        # å‡†å¤‡ç‰¹å¾
        features = self._prepare_features(snow_depth_mm, snow_fall_mm, snow_water_equivalent_mm, date)
        
        # æ·»åŠ åˆ°å†å²æ•°æ®
        self._historical_features.append(features.flatten())
        self._historical_dates.append(date)
        
        # ä¿æŒæ•°æ®é¡ºåºï¼ˆæŒ‰æ—¶é—´ï¼‰
        if len(self._historical_features) > 1:
            # æŒ‰æ—¥æœŸæ’åº
            sorted_indices = np.argsort([d.timestamp() for d in self._historical_dates])
            self._historical_features = [self._historical_features[i] for i in sorted_indices]
            self._historical_dates = [self._historical_dates[i] for i in sorted_indices]
        
        # é™åˆ¶å†å²æ•°æ®é‡
        max_history = self.sequence_length * 3
        if len(self._historical_features) > max_history:
            self._historical_features = self._historical_features[-max_history:]
            self._historical_dates = self._historical_dates[-max_history:]
        
        print(f"âœ… å†å²æ•°æ®æ·»åŠ æˆåŠŸï¼Œå½“å‰æ•°æ®ç‚¹: {len(self._historical_features)}")
    
    def _prepare_features(self, snow_depth_mm: float, snow_fall_mm: float, 
                         snow_water_equivalent_mm: float, date: datetime) -> np.ndarray:
        """å‡†å¤‡ç‰¹å¾ - å†…éƒ¨æ–¹æ³•"""
        # è®¡ç®—æ—¥æœŸç‰¹å¾
        day_of_year = date.timetuple().tm_yday
        month = date.month
        year = date.year
        
        # åˆ›å»ºç‰¹å¾å‘é‡
        features = np.array([
            snow_depth_mm,
            snow_fall_mm, 
            snow_water_equivalent_mm,
            day_of_year,
            month,
            year
        ]).reshape(1, -1)
        
        # æ ‡å‡†åŒ–ç‰¹å¾
        if self.scaler_X is not None:
            try:
                features = self.scaler_X.transform(features)
            except Exception as e:
                print(f"âŒ ç‰¹å¾æ ‡å‡†åŒ–å¤±è´¥: {e}")
                raise
        else:
            print("âš ï¸ è­¦å‘Šï¼šæ ‡å‡†åŒ–å™¨æœªåŠ è½½ï¼Œä½¿ç”¨åŸå§‹ç‰¹å¾")
        
        return features
    
    def predict(self, snow_depth_mm: float, snow_fall_mm: float, 
               snow_water_equivalent_mm: float, date: datetime) -> Tuple[float, PredictionConfidence, Dict[str, Any]]:
        """ä¸»é¢„æµ‹æ–¹æ³• - æ ¹æ®æ¨¡å¼é€‰æ‹©é¢„æµ‹ç­–ç•¥"""
        if not self.is_loaded:
            raise Exception("æ¨¡å‹æœªåŠ è½½")
        
        # æ•°æ®éªŒè¯
        if not self.validate_feature_data(snow_depth_mm, snow_fall_mm, snow_water_equivalent_mm, date):
            raise ValueError("è¾“å…¥æ•°æ®éªŒè¯å¤±è´¥")
        
        # æ ¹æ®é¢„æµ‹æ¨¡å¼é€‰æ‹©ç­–ç•¥
        if self.prediction_mode == PredictionMode.STRICT:
            return self._predict_strict(snow_depth_mm, snow_fall_mm, snow_water_equivalent_mm, date)
        elif self.prediction_mode == PredictionMode.LIMITED:
            return self._predict_limited(snow_depth_mm, snow_fall_mm, snow_water_equivalent_mm, date)
        elif self.prediction_mode == PredictionMode.PROGRESSIVE:
            return self._predict_progressive(snow_depth_mm, snow_fall_mm, snow_water_equivalent_mm, date)
        else:
            raise ValueError(f"æœªçŸ¥çš„é¢„æµ‹æ¨¡å¼: {self.prediction_mode}")
    
    def _predict_strict(self, snow_depth_mm: float, snow_fall_mm: float, 
                       snow_water_equivalent_mm: float, date: datetime) -> Tuple[float, PredictionConfidence, Dict[str, Any]]:
        """ä¸¥æ ¼é¢„æµ‹æ¨¡å¼ - éœ€è¦å®Œæ•´å†å²æ•°æ®"""
        # æ£€æŸ¥å†å²æ•°æ®æ˜¯å¦å……è¶³
        if len(self._historical_features) < self.sequence_length:
            raise ValueError(
                f"ä¸¥æ ¼æ¨¡å¼éœ€è¦è‡³å°‘ {self.sequence_length} ä¸ªå†å²æ•°æ®ç‚¹ï¼Œ"
                f"ä½†åªæœ‰ {len(self._historical_features)} ä¸ªã€‚"
                "è¯·å…ˆæ”¶é›†è¶³å¤Ÿçš„å†å²æ•°æ®ï¼Œæˆ–åˆ‡æ¢åˆ°å…¶ä»–é¢„æµ‹æ¨¡å¼ã€‚"
            )
        
        # ä½¿ç”¨çœŸå®çš„å†å²æ•°æ®åˆ›å»ºåºåˆ—
        sequence = self._historical_features[-self.sequence_length:]
        sequence = np.array(sequence).reshape(1, self.sequence_length, -1)
        
        # é¢„æµ‹
        prediction = self._make_prediction(sequence)
        
        # åæ ‡å‡†åŒ–
        if self.scaler_y is not None:
            prediction = self.scaler_y.inverse_transform([[prediction]])[0][0]
        
        prediction = max(0, prediction)  # ç¡®ä¿éè´Ÿ
        
        # è¿”å›ç»“æœå’Œå…ƒæ•°æ®
        metadata = {
            'mode': 'strict',
            'data_points_used': self.sequence_length,
            'data_quality': 'high',
            'limitations': 'æ— ',
            'recommendations': ['æ•°æ®å……è¶³ï¼Œé¢„æµ‹è´¨é‡æœ€ä½³']
        }
        
        return prediction, PredictionConfidence.HIGH, metadata
    
    def _predict_limited(self, snow_depth_mm: float, snow_fall_mm: float, 
                        snow_water_equivalent_mm: float, date: datetime) -> Tuple[float, PredictionConfidence, Dict[str, Any]]:
        """æœ‰é™é¢„æµ‹æ¨¡å¼ - æ•°æ®ä¸è¶³æ—¶æä¾›æœ‰é™é¢„æµ‹"""
        current_data_points = len(self._historical_features)
        
        if current_data_points == 0:
            raise ValueError(
                "æœ‰é™æ¨¡å¼éœ€è¦è‡³å°‘1ä¸ªå†å²æ•°æ®ç‚¹ã€‚"
                "è¯·å…ˆæ·»åŠ ä¸€äº›å†å²æ•°æ®ï¼Œæˆ–åˆ‡æ¢åˆ°æ¸è¿›æ¨¡å¼ã€‚"
            )
        
        # å‡†å¤‡å½“å‰ç‰¹å¾
        current_features = self._prepare_features(snow_depth_mm, snow_fall_mm, snow_water_equivalent_mm, date)
        
        # åˆ›å»ºåºåˆ—ï¼ˆä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„å†å²æ•°æ®ï¼‰
        available_features = self._historical_features.copy()
        available_features.append(current_features.flatten())
        
        # å¦‚æœæ•°æ®ä¸è¶³ï¼Œä½¿ç”¨å¯ç”¨çš„æ•°æ®ï¼ˆä¸é€ å‡ï¼‰
        if len(available_features) < self.sequence_length:
            # ä½¿ç”¨å¯ç”¨çš„æ•°æ®ï¼Œä½†æ˜ç¡®å‘ŠçŸ¥é™åˆ¶
            sequence = np.array(available_features)
            # é‡å¡‘ä¸º (1, n_available, n_features)
            sequence = sequence.reshape(1, -1, sequence.shape[1])
            
            # ä½¿ç”¨å¯ç”¨çš„æ•°æ®ç‚¹è¿›è¡Œé¢„æµ‹
            prediction = self._make_prediction_with_variable_length(sequence)
        else:
            # æ•°æ®å……è¶³ï¼Œä½¿ç”¨æ ‡å‡†æ–¹æ³•
            sequence = np.array(available_features[-self.sequence_length:])
            sequence = sequence.reshape(1, self.sequence_length, -1)
            prediction = self._make_prediction(sequence)
        
        # åæ ‡å‡†åŒ–
        if self.scaler_y is not None:
            prediction = self.scaler_y.inverse_transform([[prediction]])[0][0]
        
        prediction = max(0, prediction)
        
        # è®¡ç®—ç½®ä¿¡åº¦
        if current_data_points >= self.sequence_length:
            confidence = PredictionConfidence.HIGH
        elif current_data_points >= self.sequence_length // 2:
            confidence = PredictionConfidence.MEDIUM
        else:
            confidence = PredictionConfidence.LOW
        
        # è¿”å›ç»“æœå’Œå…ƒæ•°æ®
        metadata = {
            'mode': 'limited',
            'data_points_used': len(available_features),
            'data_quality': 'medium' if confidence == PredictionConfidence.MEDIUM else 'low',
            'limitations': f'æ•°æ®ä¸è¶³ï¼Œä»…ä½¿ç”¨ {len(available_features)}/{self.sequence_length} ä¸ªæ•°æ®ç‚¹',
            'recommendations': [
                f'å»ºè®®æ”¶é›†æ›´å¤šå†å²æ•°æ®ï¼ˆå½“å‰{current_data_points}/{self.sequence_length}ï¼‰',
                'æ•°æ®è¶Šå¤šï¼Œé¢„æµ‹è´¨é‡è¶Šé«˜'
            ]
        }
        
        return prediction, confidence, metadata
    
    def _predict_progressive(self, snow_depth_mm: float, snow_fall_mm: float, 
                           snow_water_equivalent_mm: float, date: datetime) -> Tuple[float, PredictionConfidence, Dict[str, Any]]:
        """æ¸è¿›é¢„æµ‹æ¨¡å¼ - éšç€æ•°æ®å¢åŠ é€æ­¥æé«˜è´¨é‡"""
        current_data_points = len(self._historical_features)
        
        # å‡†å¤‡å½“å‰ç‰¹å¾
        current_features = self._prepare_features(snow_depth_mm, snow_fall_mm, snow_water_equivalent_mm, date)
        
        # åˆ›å»ºåºåˆ—ï¼ˆä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„å†å²æ•°æ®ï¼‰
        available_features = self._historical_features.copy()
        available_features.append(current_features.flatten())
        
        # æ ¹æ®å¯ç”¨æ•°æ®é‡é€‰æ‹©é¢„æµ‹ç­–ç•¥
        if len(available_features) == 1:
            # åªæœ‰ä¸€ä¸ªæ•°æ®ç‚¹ï¼Œä½¿ç”¨ç®€å•å¤–æ¨
            prediction = self._simple_extrapolation(current_features)
            confidence = PredictionConfidence.LOW
        elif len(available_features) < self.sequence_length:
            # æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨å¯ç”¨çš„æ•°æ®
            sequence = np.array(available_features)
            sequence = sequence.reshape(1, -1, sequence.shape[1])
            prediction = self._make_prediction_with_variable_length(sequence)
            
            # æ ¹æ®æ•°æ®é‡è®¡ç®—ç½®ä¿¡åº¦
            if len(available_features) >= self.sequence_length // 2:
                confidence = PredictionConfidence.MEDIUM
            else:
                confidence = PredictionConfidence.LOW
        else:
            # æ•°æ®å……è¶³ï¼Œä½¿ç”¨æ ‡å‡†æ–¹æ³•
            sequence = np.array(available_features[-self.sequence_length:])
            sequence = sequence.reshape(1, self.sequence_length, -1)
            prediction = self._make_prediction(sequence)
            confidence = PredictionConfidence.HIGH
        
        # åæ ‡å‡†åŒ–
        if self.scaler_y is not None:
            prediction = self.scaler_y.inverse_transform([[prediction]])[0][0]
        
        prediction = max(0, prediction)
        
        # è¿”å›ç»“æœå’Œå…ƒæ•°æ®
        metadata = {
            'mode': 'progressive',
            'data_points_used': len(available_features),
            'data_quality': 'progressive',
            'limitations': f'æ¸è¿›æ¨¡å¼ï¼Œå½“å‰ä½¿ç”¨ {len(available_features)}/{self.sequence_length} ä¸ªæ•°æ®ç‚¹',
            'recommendations': [
                f'å½“å‰æ•°æ®ç‚¹: {len(available_features)}/{self.sequence_length}',
                'ç»§ç»­æ”¶é›†æ•°æ®ä»¥æé«˜é¢„æµ‹è´¨é‡',
                f'é¢„è®¡éœ€è¦ {self.sequence_length - len(available_features)} ä¸ªæ•°æ®ç‚¹è¾¾åˆ°æœ€ä½³è´¨é‡'
            ]
        }
        
        return prediction, confidence, metadata
    
    def _make_prediction(self, sequence: np.ndarray) -> float:
        """æ ‡å‡†é¢„æµ‹æ–¹æ³•"""
        with torch.no_grad():
            if hasattr(self, 'ensemble_models') and self.ensemble_models:
                # é›†æˆé¢„æµ‹
                predictions = []
                for model in self.ensemble_models:
                    pred = model(torch.FloatTensor(sequence))
                    predictions.append(pred.item())
                return np.mean(predictions)
            else:
                # å•ä¸ªæ¨¡å‹é¢„æµ‹
                return self.model(torch.FloatTensor(sequence)).item()
    
    def _make_prediction_with_variable_length(self, sequence: np.ndarray) -> float:
        """å¤„ç†å¯å˜é•¿åº¦åºåˆ—çš„é¢„æµ‹"""
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…æ¨¡å‹æ¶æ„è°ƒæ•´
        # æš‚æ—¶ä½¿ç”¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„ç‰¹å¾è¿›è¡Œé¢„æµ‹
        last_features = sequence[0, -1, :]
        
        # åˆ›å»ºå•æ—¶é—´æ­¥åºåˆ—
        single_sequence = last_features.reshape(1, 1, -1)
        
        with torch.no_grad():
            if hasattr(self, 'ensemble_models') and self.ensemble_models:
                predictions = []
                for model in self.ensemble_models:
                    # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾æ¨¡å‹å¯ä»¥å¤„ç†å•æ—¶é—´æ­¥åºåˆ—
                    # å¦‚æœä¸è¡Œï¼Œéœ€è¦è°ƒæ•´æ¨¡å‹æ¶æ„
                    pred = model(torch.FloatTensor(single_sequence))
                    predictions.append(pred.item())
                return np.mean(predictions)
            else:
                return self.model(torch.FloatTensor(single_sequence)).item()
    
    def _simple_extrapolation(self, current_features: np.ndarray) -> float:
        """ç®€å•å¤–æ¨ - ä»…ç”¨äºæ¸è¿›æ¨¡å¼çš„åˆå§‹é˜¶æ®µ"""
        # ä½¿ç”¨å½“å‰ç‰¹å¾è¿›è¡Œç®€å•é¢„æµ‹
        # è¿™é‡Œå¯ä»¥åŸºäºç‰©ç†è§„å¾‹è¿›è¡Œç®€å•å¤–æ¨
        # æš‚æ—¶è¿”å›ä¸€ä¸ªåŸºäºå½“å‰é›ªæ°´å½“é‡çš„ç®€å•ä¼°è®¡
        
        # å‡è®¾é¢„æµ‹å€¼æ¥è¿‘å½“å‰é›ªæ°´å½“é‡ï¼Œä½†è€ƒè™‘å­£èŠ‚æ€§å› ç´ 
        current_swe = current_features[0, 2]  # é›ªæ°´å½“é‡
        
        # ç®€å•çš„å­£èŠ‚æ€§è°ƒæ•´ï¼ˆåŸºäºæœˆä»½ï¼‰
        month = current_features[0, 4]
        seasonal_factor = 1.0 + 0.1 * np.sin(2 * np.pi * month / 12)
        
        return current_swe * seasonal_factor
    
    def get_data_quality_report(self) -> Dict[str, Any]:
        """è·å–æ•°æ®è´¨é‡æŠ¥å‘Š"""
        if len(self._historical_features) == 0:
            return {
                'status': 'no_data',
                'message': 'æ²¡æœ‰å†å²æ•°æ®',
                'quality_score': 0.0,
                'recommendations': ['å¼€å§‹æ”¶é›†å†å²æ•°æ®']
            }
        
        try:
            features_array = np.array(self._historical_features)
            n_samples = len(features_array)
            
            # è®¡ç®—è´¨é‡åˆ†æ•°
            quality_score = min(1.0, n_samples / self.sequence_length)
            
            # ç”ŸæˆæŠ¥å‘Š
            report = {
                'status': 'excellent' if quality_score >= 1.0 else 'good' if quality_score >= 0.7 else 'fair' if quality_score >= 0.4 else 'poor',
                'quality_score': quality_score,
                'n_samples': n_samples,
                'required_samples': self.sequence_length,
                'completion_percentage': f"{quality_score * 100:.1f}%",
                'recommendations': self._get_recommendations()
            }
            
            return report
            
        except Exception as e:
            return {
                'status': 'error',
                'message': f'æ•°æ®è´¨é‡æ£€æŸ¥å¤±è´¥: {e}',
                'quality_score': 0.0
            }
    
    def _auto_load_best_model(self):
        """è‡ªåŠ¨åŠ è½½æœ€ä½³æ¨¡å‹"""
        # æŸ¥æ‰¾æœ€æ–°çš„ä¼˜åŒ–æ¨¡å‹
        models_dir = "models"
        if not os.path.exists(models_dir):
            print("âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨")
            return
        
        # æŸ¥æ‰¾ä¼˜åŒ–æ¨¡å‹
        optimized_files = [f for f in os.listdir(models_dir) if f.startswith("optimized_gru_model_")]
        if optimized_files:
            latest_model = max(optimized_files)
            model_path = os.path.join(models_dir, latest_model)
            print(f"ğŸ” æ‰¾åˆ°ä¼˜åŒ–æ¨¡å‹: {latest_model}")
            self.load_model(model_path)
            return
        
        # æŸ¥æ‰¾é›†æˆæ¨¡å‹
        ensemble_dirs = [d for d in os.listdir(models_dir) if d.startswith("ensemble_models_")]
        if ensemble_dirs:
            latest_ensemble = max(ensemble_dirs)
            ensemble_path = os.path.join(models_dir, latest_ensemble)
            print(f"ğŸ” æ‰¾åˆ°é›†æˆæ¨¡å‹: {latest_ensemble}")
            self.load_ensemble_model(ensemble_path)
            return
        
        print("âŒ æœªæ‰¾åˆ°ä¼˜åŒ–æ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        self._create_default_model()
    
    def _create_default_model(self):
        """åˆ›å»ºé»˜è®¤æ¨¡å‹"""
        self.model = OptimizedGRUModel(
            input_size=6,
            hidden_size=64,
            num_layers=2,
            dropout=0.1
        )
        self.is_loaded = True
    
    def load_model(self, model_path: str):
        """åŠ è½½å•ä¸ªä¼˜åŒ–æ¨¡å‹"""
        try:
            print(f"ğŸ“¥ åŠ è½½æ¨¡å‹: {model_path}")
            
            # éªŒè¯æ–‡ä»¶å­˜åœ¨
            if not os.path.exists(model_path):
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            
            # åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹
            checkpoint = torch.load(model_path, map_location='cpu')
            
            # é‡å»ºæ ‡å‡†åŒ–å™¨
            self.scaler_X = StandardScaler()
            self.scaler_X.mean_ = checkpoint['scaler_X_mean']
            self.scaler_X.scale_ = checkpoint['scaler_X_scale']
            
            self.scaler_y = StandardScaler()
            self.scaler_y.mean_ = checkpoint['scaler_y_mean']
            self.scaler_y.scale_ = checkpoint['scaler_y_scale']
            
            # åˆ›å»ºæ¨¡å‹
            self.model = OptimizedGRUModel(
                input_size=6,
                hidden_size=64,
                num_layers=2,
                dropout=0.1
            )
            
            # åŠ è½½æ¨¡å‹æƒé‡
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.eval()
            
            self.is_loaded = True
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self._create_default_model()
    
    def load_ensemble_model(self, ensemble_dir: str):
        """åŠ è½½é›†æˆæ¨¡å‹"""
        try:
            print(f"ğŸ“¥ åŠ è½½é›†æˆæ¨¡å‹: {ensemble_dir}")
            
            # åŠ è½½æ ‡å‡†åŒ–å™¨å‚æ•°
            standardization_path = "models/standardization_params.pkl"
            if os.path.exists(standardization_path):
                with open(standardization_path, 'rb') as f:
                    params = pickle.load(f)
                
                self.scaler_X = StandardScaler()
                self.scaler_X.mean_ = params['scaler_X_mean']
                self.scaler_X.scale_ = params['scaler_X_scale']
                
                self.scaler_y = StandardScaler()
                self.scaler_y.mean_ = params['scaler_y_mean']
                self.scaler_y.scale_ = params['scaler_y_scale']
                
                print("âœ… æ ‡å‡†åŒ–å™¨åŠ è½½æˆåŠŸ")
            
            # åˆ›å»ºé›†æˆæ¨¡å‹åˆ—è¡¨
            self.ensemble_models = []
            successful_loads = 0
            
            for i in range(1, 4):  # åŠ è½½å‰3ä¸ªæ¨¡å‹
                model_files = [f for f in os.listdir(ensemble_dir) if f.startswith(f"model_{i}_")]
                if model_files:
                    model_path = os.path.join(ensemble_dir, model_files[0])
                    model = OptimizedGRUModel()
                    checkpoint = torch.load(model_path, map_location='cpu')
                    model.load_state_dict(checkpoint['model_state_dict'])
                    model.eval()
                    self.ensemble_models.append(model)
                    successful_loads += 1
                    print(f"âœ… é›†æˆæ¨¡å‹ {i} åŠ è½½æˆåŠŸ")
            
            if successful_loads > 0:
                self.is_loaded = True
                print(f"âœ… é›†æˆæ¨¡å‹åŠ è½½å®Œæˆ: {successful_loads} ä¸ªæ¨¡å‹")
            else:
                raise Exception("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•é›†æˆæ¨¡å‹")
                
        except Exception as e:
            print(f"âŒ é›†æˆæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self._create_default_model()

class OptimizedGRUModel(nn.Module):
    """ä¼˜åŒ–çš„GRUæ¨¡å‹"""
    
    def __init__(self, input_size=6, hidden_size=64, num_layers=2, dropout=0.1):
        super(OptimizedGRUModel, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        self.gru = nn.GRU(input_size, hidden_size, num_layers, 
                          dropout=dropout if num_layers > 1 else 0, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x):
        gru_out, _ = self.gru(x)
        gru_out = self.dropout(gru_out)
        output = self.fc(gru_out[:, -1, :])
        return output

# å…¨å±€é¢„æµ‹å™¨å®ä¾‹
_global_honest_predictor = None

def get_honest_predictor(mode: PredictionMode = PredictionMode.STRICT) -> HonestSWEPredictor:
    """è·å–å…¨å±€è¯šå®é¢„æµ‹å™¨å®ä¾‹"""
    global _global_honest_predictor
    if _global_honest_predictor is None:
        _global_honest_predictor = HonestSWEPredictor(mode=mode)
    return _global_honest_predictor

