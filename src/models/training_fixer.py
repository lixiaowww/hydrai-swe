#!/usr/bin/env python3
"""
æ¨¡å‹è®­ç»ƒä¿®å¤å™¨
ç²¾å‡†ä¿®å¤RÂ²ä¸ºè´Ÿå€¼é—®é¢˜ï¼Œå›å½’æ ¸å¿ƒç›®æ ‡
"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
from typing import Dict, List, Optional, Tuple
import logging
from datetime import datetime
import os

# å¯¼å…¥é˜²è¿‡æ‹Ÿåˆæ ¸å¿ƒç³»ç»Ÿ
from .anti_overfitting_core import AntiOverfittingCore
from ..data.data_quality_detector import DataQualityDetector

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class TrainingFixer:
    """æ¨¡å‹è®­ç»ƒä¿®å¤å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–è®­ç»ƒä¿®å¤å™¨"""
        self.anti_overfitting = AntiOverfittingCore()
        self.data_quality = DataQualityDetector()
        self.fix_history = []
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs('models/fixed', exist_ok=True)
        
        logger.info("âœ… æ¨¡å‹è®­ç»ƒä¿®å¤å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def diagnose_and_fix(self, model: nn.Module, X_train: np.ndarray, y_train: np.ndarray,
                        X_val: np.ndarray, y_val: np.ndarray, 
                        train_losses: List[float], val_losses: List[float]) -> Dict:
        """è¯Šæ–­å¹¶ä¿®å¤è®­ç»ƒé—®é¢˜"""
        try:
            logger.info("ğŸ” å¼€å§‹è¯Šæ–­è®­ç»ƒé—®é¢˜...")
            
            diagnosis_result = {
                'timestamp': datetime.now().isoformat(),
                'data_quality': {},
                'overfitting_analysis': {},
                'fixes_applied': [],
                'final_status': 'unknown'
            }
            
            # æ­¥éª¤1: æ•°æ®è´¨é‡è¯Šæ–­
            logger.info("ğŸ“Š æ­¥éª¤1: æ•°æ®è´¨é‡è¯Šæ–­...")
            data_quality_result = self.data_quality.detect_data_issues(X_train, y_train)
            diagnosis_result['data_quality'] = data_quality_result
            
            if data_quality_result['status'] == 'success':
                quality_score = data_quality_result['quality_score']
                logger.info(f"æ•°æ®è´¨é‡å¾—åˆ†: {quality_score:.3f}")
                
                if quality_score < 0.5:
                    logger.warning("âš ï¸ æ•°æ®è´¨é‡è¾ƒå·®ï¼Œéœ€è¦å…ˆè§£å†³æ•°æ®é—®é¢˜")
                    diagnosis_result['final_status'] = 'data_quality_issue'
                    return diagnosis_result
            
            # æ­¥éª¤2: è¿‡æ‹Ÿåˆè¯Šæ–­
            logger.info("ğŸ” æ­¥éª¤2: è¿‡æ‹Ÿåˆè¯Šæ–­...")
            overfitting_result = self.anti_overfitting.detect_overfitting(train_losses, val_losses)
            diagnosis_result['overfitting_analysis'] = overfitting_result
            
            if overfitting_result['status'] == 'success' and overfitting_result['overfitting']:
                logger.warning("âš ï¸ æ£€æµ‹åˆ°è¿‡æ‹Ÿåˆï¼Œå¼€å§‹ä¿®å¤...")
                
                # åº”ç”¨è¿‡æ‹Ÿåˆä¿®å¤
                fix_result = self.anti_overfitting.fix_overfitting(model, X_train, y_train, X_val, y_val)
                diagnosis_result['fixes_applied'].append({
                    'type': 'overfitting_fix',
                    'result': fix_result
                })
                
                if fix_result['status'] == 'success':
                    logger.info("âœ… è¿‡æ‹Ÿåˆä¿®å¤å®Œæˆ")
                    diagnosis_result['final_status'] = 'overfitting_fixed'
                else:
                    logger.error("âŒ è¿‡æ‹Ÿåˆä¿®å¤å¤±è´¥")
                    diagnosis_result['final_status'] = 'fix_failed'
            else:
                logger.info("âœ… æœªæ£€æµ‹åˆ°è¿‡æ‹Ÿåˆ")
                diagnosis_result['final_status'] = 'no_overfitting'
            
            # æ­¥éª¤3: æ¨¡å‹æ€§èƒ½ä¿®å¤
            if diagnosis_result['final_status'] in ['overfitting_fixed', 'no_overfitting']:
                logger.info("ğŸ”§ æ­¥éª¤3: æ¨¡å‹æ€§èƒ½ä¿®å¤...")
                performance_fix = self._fix_model_performance(model, X_train, y_train, X_val, y_val)
                diagnosis_result['fixes_applied'].append({
                    'type': 'performance_fix',
                    'result': performance_fix
                })
            
            # ä¿å­˜è¯Šæ–­ç»“æœ
            self.fix_history.append(diagnosis_result)
            try:
                self._save_diagnosis_result(diagnosis_result)
            except Exception as e:
                logger.warning(f"ä¿å­˜è¯Šæ–­ç»“æœå¤±è´¥: {e}")
            
            logger.info(f"âœ… è¯Šæ–­å’Œä¿®å¤å®Œæˆï¼Œæœ€ç»ˆçŠ¶æ€: {diagnosis_result['final_status']}")
            
            return diagnosis_result
            
        except Exception as e:
            logger.error(f"âŒ è¯Šæ–­å’Œä¿®å¤å¤±è´¥: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def _fix_model_performance(self, model: nn.Module, X_train: np.ndarray, y_train: np.ndarray,
                              X_val: np.ndarray, y_val: np.ndarray) -> Dict:
        """ä¿®å¤æ¨¡å‹æ€§èƒ½é—®é¢˜"""
        try:
            logger.info("ğŸ”§ å¼€å§‹ä¿®å¤æ¨¡å‹æ€§èƒ½...")
            
            # æ£€æŸ¥æ•°æ®è§„æ¨¡
            n_samples = len(X_train)
            n_features = X_train.shape[1]
            
            # åŸºäºæ•°æ®è§„æ¨¡é€‰æ‹©æœ€ä½³ç­–ç•¥
            if n_samples < 100:
                strategy = 'ultra_simple'
            elif n_samples < 500:
                strategy = 'simple'
            else:
                strategy = 'standard'
            
            logger.info(f"é€‰æ‹©ç­–ç•¥: {strategy}")
            
            # åº”ç”¨ç›¸åº”ç­–ç•¥
            if strategy == 'ultra_simple':
                fixed_model = self._apply_ultra_simple_strategy(model, X_train.shape[1])
            elif strategy == 'simple':
                fixed_model = self._apply_simple_strategy(model, X_train.shape[1])
            else:
                fixed_model = self._apply_standard_strategy(model, X_train.shape[1])
            
            # ä¼˜åŒ–è®­ç»ƒå‚æ•°
            optimized_params = self._get_optimized_params(strategy, n_samples, n_features)
            
            result = {
                'status': 'success',
                'strategy_applied': strategy,
                'original_model': str(model),
                'fixed_model': str(fixed_model),
                'optimized_params': optimized_params,
                'fix_timestamp': datetime.now().isoformat()
            }
            
            # ä¿å­˜ä¿®å¤åçš„æ¨¡å‹
            self._save_fixed_model(fixed_model, strategy)
            
            logger.info("âœ… æ¨¡å‹æ€§èƒ½ä¿®å¤å®Œæˆ")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ä¿®å¤æ¨¡å‹æ€§èƒ½å¤±è´¥: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def _apply_ultra_simple_strategy(self, model: nn.Module, input_size: int) -> nn.Module:
        """åº”ç”¨è¶…ç®€å•ç­–ç•¥"""
        try:
            # åˆ›å»ºæç®€æ¨¡å‹
            class UltraSimpleLSTM(nn.Module):
                def __init__(self, input_size: int):
                    super(UltraSimpleLSTM, self).__init__()
                    
                    # æç®€è®¾è®¡ï¼šæœ€å°éšè—å±‚ï¼Œæ— dropout
                    hidden_size = max(4, input_size // 16)
                    
                    self.lstm = nn.LSTM(
                        input_size=input_size,
                        hidden_size=hidden_size,
                        num_layers=1,
                        batch_first=True
                    )
                    
                    self.fc = nn.Linear(hidden_size, 1)
                    
                def forward(self, x):
                    lstm_out, _ = self.lstm(x)
                    last_output = lstm_out[:, -1, :]
                    return self.fc(last_output)
            
            return UltraSimpleLSTM(input_size)
            
        except Exception as e:
            logger.error(f"âŒ åº”ç”¨è¶…ç®€å•ç­–ç•¥å¤±è´¥: {e}")
            raise
    
    def _apply_simple_strategy(self, model: nn.Module, input_size: int) -> nn.Module:
        """åº”ç”¨ç®€å•ç­–ç•¥"""
        try:
            # åˆ›å»ºç®€å•æ¨¡å‹
            class SimpleLSTM(nn.Module):
                def __init__(self, input_size: int):
                    super(SimpleLSTM, self).__init__()
                    
                    # ç®€å•è®¾è®¡ï¼šé€‚ä¸­çš„éšè—å±‚ï¼Œè½»å¾®æ­£åˆ™åŒ–
                    hidden_size = max(8, input_size // 8)
                    
                    self.lstm = nn.LSTM(
                        input_size=input_size,
                        hidden_size=hidden_size,
                        num_layers=1,
                        batch_first=True,
                        dropout=0.1  # è½»å¾®dropout
                    )
                    
                    self.dropout = nn.Dropout(0.1)
                    self.fc = nn.Linear(hidden_size, 1)
                    
                def forward(self, x):
                    lstm_out, _ = self.lstm(x)
                    last_output = lstm_out[:, -1, :]
                    out = self.dropout(last_output)
                    return self.fc(out)
            
            return SimpleLSTM(input_size)
            
        except Exception as e:
            logger.error(f"âŒ åº”ç”¨ç®€å•ç­–ç•¥å¤±è´¥: {e}")
            raise
    
    def _apply_standard_strategy(self, model: nn.Module, input_size: int) -> nn.Module:
        """åº”ç”¨æ ‡å‡†ç­–ç•¥"""
        try:
            # åˆ›å»ºæ ‡å‡†æ¨¡å‹
            class StandardLSTM(nn.Module):
                def __init__(self, input_size: int):
                    super(StandardLSTM, self).__init__()
                    
                    # æ ‡å‡†è®¾è®¡ï¼šåˆç†çš„éšè—å±‚ï¼Œé€‚åº¦æ­£åˆ™åŒ–
                    hidden_size = max(16, input_size // 4)
                    
                    self.lstm = nn.LSTM(
                        input_size=input_size,
                        hidden_size=hidden_size,
                        num_layers=2,  # 2å±‚LSTM
                        batch_first=True,
                        dropout=0.2
                    )
                    
                    self.dropout = nn.Dropout(0.2)
                    self.fc = nn.Linear(hidden_size, 1)
                    
                def forward(self, x):
                    lstm_out, _ = self.lstm(x)
                    last_output = lstm_out[:, -1, :]
                    out = self.dropout(last_output)
                    return self.fc(out)
            
            return StandardLSTM(input_size)
            
        except Exception as e:
            logger.error(f"âŒ åº”ç”¨æ ‡å‡†ç­–ç•¥å¤±è´¥: {e}")
            raise
    
    def _get_optimized_params(self, strategy: str, n_samples: int, n_features: int) -> Dict:
        """è·å–ä¼˜åŒ–çš„è®­ç»ƒå‚æ•°"""
        try:
            if strategy == 'ultra_simple':
                params = {
                    'batch_size': 4,
                    'epochs': 15,
                    'learning_rate': 0.01,
                    'patience': 3,
                    'early_stopping': True,
                    'reduce_lr_on_plateau': True,
                    'weight_decay': 0.0001
                }
            elif strategy == 'simple':
                params = {
                    'batch_size': 8,
                    'epochs': 25,
                    'learning_rate': 0.005,
                    'patience': 5,
                    'early_stopping': True,
                    'reduce_lr_on_plateau': True,
                    'weight_decay': 0.0005
                }
            else:  # standard
                params = {
                    'batch_size': 16,
                    'epochs': 40,
                    'learning_rate': 0.001,
                    'patience': 8,
                    'early_stopping': True,
                    'reduce_lr_on_plateau': True,
                    'weight_decay': 0.001
                }
            
            # æ ¹æ®æ•°æ®ç‰¹å¾è°ƒæ•´
            if n_features > n_samples // 3:
                params['batch_size'] = max(2, params['batch_size'] // 2)
                params['epochs'] = min(params['epochs'], 20)
            
            return params
            
        except Exception as e:
            logger.error(f"âŒ è·å–ä¼˜åŒ–å‚æ•°å¤±è´¥: {e}")
            return {}
    
    def _save_fixed_model(self, model: nn.Module, strategy: str):
        """ä¿å­˜ä¿®å¤åçš„æ¨¡å‹"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            model_path = f"models/fixed/fixed_model_{strategy}_{timestamp}.pth"
            
            torch.save({
                'model_state_dict': model.state_dict(),
                'strategy': strategy,
                'fix_timestamp': timestamp
            }, model_path)
            
            logger.info(f"âœ… ä¿®å¤åçš„æ¨¡å‹å·²ä¿å­˜: {model_path}")
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ä¿®å¤åçš„æ¨¡å‹å¤±è´¥: {e}")
    
    def _save_diagnosis_result(self, result: Dict):
        """ä¿å­˜è¯Šæ–­ç»“æœ"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            result_file = f"models/fixed/diagnosis_result_{timestamp}.json"
            
            import json
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜è¯Šæ–­ç»“æœå¤±è´¥: {e}")
    
    def get_fix_summary(self) -> Dict:
        """è·å–ä¿®å¤æ‘˜è¦"""
        if not self.fix_history:
            return {"message": "æš‚æ— ä¿®å¤è®°å½•"}
        
        total_fixes = len(self.fix_history)
        successful_fixes = sum(1 for r in self.fix_history if r['final_status'] in ['overfitting_fixed', 'no_overfitting'])
        
        # ç»Ÿè®¡å„ç§çŠ¶æ€
        status_counts = {}
        for result in self.fix_history:
            status = result.get('final_status', 'unknown')
            status_counts[status] = status_counts.get(status, 0) + 1
        
        return {
            "total_fixes": total_fixes,
            "successful_fixes": successful_fixes,
            "success_rate": f"{successful_fixes/total_fixes*100:.1f}%",
            "status_distribution": status_counts,
            "last_fix": self.fix_history[-1].get('timestamp', 'Unknown')
        }
