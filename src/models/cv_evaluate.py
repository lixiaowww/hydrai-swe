#!/usr/bin/env python3
"""
Cross-Validation Evaluation for HydrAI-SWE Project
äº¤å‰éªŒè¯è¯„ä¼°
"""

import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def run_cross_validation_evaluation():
    """è¿è¡Œäº¤å‰éªŒè¯è¯„ä¼°"""
    
    logger.info("å¼€å§‹äº¤å‰éªŒè¯è¯„ä¼°...")
    
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹
        runs_dir = "runs"
        if not os.path.exists(runs_dir):
            logger.warning("æœªæ‰¾åˆ°è®­ç»ƒç»“æœç›®å½•ï¼Œè·³è¿‡è¯„ä¼°")
            return False
        
        # æŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒç»“æœ
        run_dirs = [d for d in os.listdir(runs_dir) if d.startswith("hydrai_swe_experiment")]
        if not run_dirs:
            logger.warning("æœªæ‰¾åˆ°è®­ç»ƒç»“æœï¼Œè·³è¿‡è¯„ä¼°")
            return False
        
        latest_run = sorted(run_dirs)[-1]
        run_path = os.path.join(runs_dir, latest_run)
        
        logger.info(f"è¯„ä¼°è®­ç»ƒç»“æœ: {latest_run}")
        
        # æ£€æŸ¥è®­ç»ƒæ—¥å¿—
        log_file = os.path.join(run_path, "output.log")
        if os.path.exists(log_file):
            logger.info("æ‰¾åˆ°è®­ç»ƒæ—¥å¿—æ–‡ä»¶")
            
            # è¯»å–æ—¥å¿—å†…å®¹
            with open(log_file, 'r') as f:
                log_content = f.read()
            
            # åˆ†æè®­ç»ƒç»“æœ
            if "Training finished" in log_content or "Training completed" in log_content:
                logger.info("âœ… æ¨¡å‹è®­ç»ƒæˆåŠŸå®Œæˆ")
                
                # æŸ¥æ‰¾éªŒè¯æŒ‡æ ‡
                if "validation" in log_content.lower():
                    logger.info("æ‰¾åˆ°éªŒè¯æŒ‡æ ‡")
                
                # æŸ¥æ‰¾æµ‹è¯•æŒ‡æ ‡
                if "test" in log_content.lower():
                    logger.info("æ‰¾åˆ°æµ‹è¯•æŒ‡æ ‡")
                
                return True
            else:
                logger.warning("æ¨¡å‹è®­ç»ƒå¯èƒ½æœªå®Œæˆ")
                return False
        else:
            logger.warning("æœªæ‰¾åˆ°è®­ç»ƒæ—¥å¿—")
            return False
            
    except Exception as e:
        logger.error(f"äº¤å‰éªŒè¯è¯„ä¼°å¤±è´¥: {e}")
        return False

def evaluate_baseline_models():
    """è¯„ä¼°åŸºçº¿æ¨¡å‹"""
    
    logger.info("å¼€å§‹è¯„ä¼°åŸºçº¿æ¨¡å‹...")
    
    try:
        # è¯»å–è®­ç»ƒæ•°æ®
        data_file = "src/neuralhydrology/data/red_river_basin/timeseries.csv"
        if not os.path.exists(data_file):
            logger.warning("æœªæ‰¾åˆ°è®­ç»ƒæ•°æ®ï¼Œè·³è¿‡åŸºçº¿è¯„ä¼°")
            return False
        
        df = pd.read_csv(data_file)
        df['date'] = pd.to_datetime(df['date'])
        df.set_index('date', inplace=True)
        
        logger.info(f"åŠ è½½è®­ç»ƒæ•°æ®: {len(df)} æ¡è®°å½•")
        
        # åŸºçº¿æ¨¡å‹1: æŒä¹…æ€§æ¨¡å‹
        persistence_mae = calculate_persistence_mae(df)
        logger.info(f"æŒä¹…æ€§æ¨¡å‹ MAE: {persistence_mae:.2f}")
        
        # åŸºçº¿æ¨¡å‹2: 7å¤©ç§»åŠ¨å¹³å‡
        ma7_mae = calculate_moving_average_mae(df, window=7)
        logger.info(f"7å¤©ç§»åŠ¨å¹³å‡ MAE: {ma7_mae:.2f}")
        
        # åŸºçº¿æ¨¡å‹3: å­£èŠ‚æ€§æ¨¡å‹
        seasonal_mae = calculate_seasonal_mae(df)
        logger.info(f"å­£èŠ‚æ€§æ¨¡å‹ MAE: {seasonal_mae:.2f}")
        
        return True
        
    except Exception as e:
        logger.error(f"åŸºçº¿æ¨¡å‹è¯„ä¼°å¤±è´¥: {e}")
        return False

def calculate_persistence_mae(df):
    """è®¡ç®—æŒä¹…æ€§æ¨¡å‹çš„MAE"""
    
    if 'streamflow_m3s' not in df.columns:
        return np.nan
    
    # æŒä¹…æ€§æ¨¡å‹ï¼šæ˜å¤©çš„é¢„æµ‹ = ä»Šå¤©çš„è§‚æµ‹
    actual = df['streamflow_m3s'].iloc[1:]
    predicted = df['streamflow_m3s'].iloc[:-1]
    
    mae = np.mean(np.abs(actual - predicted))
    return mae

def calculate_moving_average_mae(df, window=7):
    """è®¡ç®—ç§»åŠ¨å¹³å‡æ¨¡å‹çš„MAE"""
    
    if 'streamflow_m3s' not in df.columns:
        return np.nan
    
    # 7å¤©ç§»åŠ¨å¹³å‡
    ma = df['streamflow_m3s'].rolling(window=window).mean()
    
    # è®¡ç®—MAE
    actual = df['streamflow_m3s'].iloc[window:]
    predicted = ma.iloc[window:]
    
    mae = np.mean(np.abs(actual - predicted))
    return mae

def calculate_seasonal_mae(df):
    """è®¡ç®—å­£èŠ‚æ€§æ¨¡å‹çš„MAE"""
    
    if 'streamflow_m3s' not in df.columns:
        return np.nan
    
    # æŒ‰æœˆä»½è®¡ç®—å¹³å‡å€¼
    df['month'] = df.index.month
    monthly_avg = df.groupby('month')['streamflow_m3s'].mean()
    
    # ä½¿ç”¨æœˆåº¦å¹³å‡å€¼ä½œä¸ºé¢„æµ‹
    df['seasonal_pred'] = df['month'].map(monthly_avg)
    
    # è®¡ç®—MAE
    actual = df['streamflow_m3s']
    predicted = df['seasonal_pred']
    
    mae = np.mean(np.abs(actual - predicted))
    return mae

def generate_evaluation_report():
    """ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š"""
    
    logger.info("ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š...")
    
    try:
        # è¿è¡Œè¯„ä¼°
        cv_success = run_cross_validation_evaluation()
        baseline_success = evaluate_baseline_models()
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            "evaluation_date": datetime.now().isoformat(),
            "cross_validation": {
                "status": "success" if cv_success else "failed",
                "message": "äº¤å‰éªŒè¯è¯„ä¼°å®Œæˆ" if cv_success else "äº¤å‰éªŒè¯è¯„ä¼°å¤±è´¥"
            },
            "baseline_models": {
                "status": "success" if baseline_success else "failed",
                "message": "åŸºçº¿æ¨¡å‹è¯„ä¼°å®Œæˆ" if baseline_success else "åŸºçº¿æ¨¡å‹è¯„ä¼°å¤±è´¥"
            },
            "recommendations": []
        }
        
        # æ·»åŠ å»ºè®®
        if cv_success and baseline_success:
            report["recommendations"].append("æ‰€æœ‰è¯„ä¼°éƒ½æˆåŠŸå®Œæˆï¼Œæ¨¡å‹æ€§èƒ½è‰¯å¥½")
        elif cv_success:
            report["recommendations"].append("äº¤å‰éªŒè¯æˆåŠŸï¼Œä½†åŸºçº¿æ¨¡å‹è¯„ä¼°å¤±è´¥")
        elif baseline_success:
            report["recommendations"].append("åŸºçº¿æ¨¡å‹è¯„ä¼°æˆåŠŸï¼Œä½†äº¤å‰éªŒè¯å¤±è´¥")
        else:
            report["recommendations"].append("æ‰€æœ‰è¯„ä¼°éƒ½å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥æ•°æ®å’Œæ¨¡å‹")
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = "evaluation_report.json"
        import json
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        return report
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆè¯„ä¼°æŠ¥å‘Šå¤±è´¥: {e}")
        return None

def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸš€ äº¤å‰éªŒè¯è¯„ä¼°")
    print("=" * 50)
    
    # è¿è¡Œè¯„ä¼°
    print("\nğŸ“Š è¿è¡Œäº¤å‰éªŒè¯è¯„ä¼°...")
    cv_result = run_cross_validation_evaluation()
    
    print("\nğŸ“Š è¯„ä¼°åŸºçº¿æ¨¡å‹...")
    baseline_result = evaluate_baseline_models()
    
    print("\nğŸ“‹ ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š...")
    report = generate_evaluation_report()
    
    # æ˜¾ç¤ºç»“æœ
    print(f"\n" + "=" * 50)
    print("ğŸ¯ è¯„ä¼°ç»“æœæ€»ç»“")
    print("=" * 50)
    print(f"äº¤å‰éªŒè¯: {'âœ… æˆåŠŸ' if cv_result else 'âŒ å¤±è´¥'}")
    print(f"åŸºçº¿æ¨¡å‹: {'âœ… æˆåŠŸ' if baseline_result else 'âŒ å¤±è´¥'}")
    
    if report:
        print(f"\nğŸ“‹ è¯„ä¼°æŠ¥å‘Š:")
        for key, value in report.items():
            if key != "recommendations":
                print(f"   {key}: {value}")
        
        print(f"\nğŸ’¡ å»ºè®®:")
        for rec in report.get("recommendations", []):
            print(f"   - {rec}")

if __name__ == "__main__":
    main()


