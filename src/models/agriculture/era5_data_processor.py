#!/usr/bin/env python3
"""
ERA5æ•°æ®å¤„ç†å™¨
ä¸“é—¨å¤„ç†ERA5æ›¿ä»£æ•°æ®ï¼Œç”¨äºå†œä¸šæ¨¡å—
"""

import os
import pandas as pd
import numpy as np
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import json

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ERA5DataProcessor:
    """ERA5æ•°æ®å¤„ç†å™¨"""
    
    def __init__(self, data_path: str = "data/raw/era5_alternative"):
        self.data_path = data_path
        self.csv_file = os.path.join(data_path, "era5_soil_moisture_data.csv")
        self.json_file = os.path.join(data_path, "era5_soil_moisture_data.json")
        
        # æ•°æ®é…ç½®
        self.config = {
            'input_size': None,  # åŠ¨æ€è®¾ç½®
            'sequence_length': 7,  # æ”¹ä¸º7å¤©ï¼Œé€‚åˆå°æ•°æ®é›†
            'target_variable': 'soil_moisture',
            'feature_variables': ['temperature', 'precipitation'],
            'time_variables': ['day_of_year', 'month', 'season']
        }
        
        logger.info(f"âœ… ERA5æ•°æ®å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ•°æ®è·¯å¾„: {data_path}")
    
    def load_data(self) -> pd.DataFrame:
        """åŠ è½½ERA5æ•°æ®"""
        try:
            logger.info("ğŸ“¥ åŠ è½½ERA5æ•°æ®...")
            
            if not os.path.exists(self.csv_file):
                raise FileNotFoundError(f"ERA5æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.csv_file}")
            
            # è¯»å–CSVæ•°æ®
            df = pd.read_csv(self.csv_file)
            
            # è½¬æ¢æ—¥æœŸåˆ—
            df['date'] = pd.to_datetime(df['date'])
            
            # æ·»åŠ æ—¶é—´ç‰¹å¾
            df = self._add_time_features(df)
            
            # æ·»åŠ å·¥ç¨‹ç‰¹å¾
            df = self._add_engineered_features(df)
            
            # è®¾ç½®è¾“å…¥å¤§å°
            self.config['input_size'] = len(df.columns) - 2  # å‡å»dateå’Œtarget_variable
            
            logger.info(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {len(df)} è¡Œ, {len(df.columns)} åˆ—")
            logger.info(f"ğŸ“Š è¾“å…¥ç‰¹å¾æ•°é‡: {self.config['input_size']}")
            
            return df
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            raise
    
    def _add_time_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ æ—¶é—´ç‰¹å¾"""
        try:
            logger.info("â° æ·»åŠ æ—¶é—´ç‰¹å¾...")
            
            # æ—¥æœŸçš„å¹´ç§¯æ—¥
            df['day_of_year'] = df['date'].dt.dayofyear
            
            # æœˆä»½
            df['month'] = df['date'].dt.month
            
            # å­£èŠ‚ (1=æ˜¥å­£, 2=å¤å­£, 3=ç§‹å­£, 4=å†¬å­£)
            df['season'] = df['date'].dt.month.map({
                3: 1, 4: 1, 5: 1,      # æ˜¥å­£
                6: 2, 7: 2, 8: 2,      # å¤å­£
                9: 3, 10: 3, 11: 3,    # ç§‹å­£
                12: 4, 1: 4, 2: 4      # å†¬å­£
            })
            
            # å‘¨å‡ 
            df['day_of_week'] = df['date'].dt.dayofweek
            
            # æ˜¯å¦å‘¨æœ«
            df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)
            
            logger.info("âœ… æ—¶é—´ç‰¹å¾æ·»åŠ å®Œæˆ")
            return df
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ æ—¶é—´ç‰¹å¾å¤±è´¥: {e}")
            return df
    
    def _add_engineered_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ å·¥ç¨‹ç‰¹å¾"""
        try:
            logger.info("ğŸ”§ æ·»åŠ å·¥ç¨‹ç‰¹å¾...")
            
            # æ¸©åº¦ç›¸å…³ç‰¹å¾
            df['temperature_squared'] = df['temperature'] ** 2
            df['temperature_cubed'] = df['temperature'] ** 3
            
            # é™æ°´ç›¸å…³ç‰¹å¾
            df['precipitation_squared'] = df['precipitation'] ** 2
            df['precipitation_log'] = np.log1p(df['precipitation'])  # log(1+x)é¿å…log(0)
            
            # äº¤äº’ç‰¹å¾
            df['temp_precip_interaction'] = df['temperature'] * df['precipitation']
            
            # æ»åç‰¹å¾ (å‰1å¤©ã€å‰3å¤©ã€å‰7å¤©)
            for lag in [1, 3, 7]:
                df[f'soil_moisture_lag_{lag}'] = df['soil_moisture'].shift(lag)
                df[f'temperature_lag_{lag}'] = df['temperature'].shift(lag)
                df[f'precipitation_lag_{lag}'] = df['precipitation'].shift(lag)
            
            # ç§»åŠ¨å¹³å‡ç‰¹å¾
            for window in [3, 7, 14]:
                df[f'soil_moisture_ma_{window}'] = df['soil_moisture'].rolling(window=window, min_periods=1).mean()
                df[f'temperature_ma_{window}'] = df['temperature'].rolling(window=window, min_periods=1).mean()
                df[f'precipitation_ma_{window}'] = df['precipitation'].rolling(window=window, min_periods=1).mean()
            
            # è¶‹åŠ¿ç‰¹å¾
            df['soil_moisture_trend'] = df['soil_moisture'].diff()
            df['temperature_trend'] = df['temperature'].diff()
            df['precipitation_trend'] = df['precipitation'].diff()
            
            logger.info("âœ… å·¥ç¨‹ç‰¹å¾æ·»åŠ å®Œæˆ")
            return df
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ å·¥ç¨‹ç‰¹å¾å¤±è´¥: {e}")
            return df
    
    def prepare_training_data(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        try:
            logger.info("ğŸ”§ å‡†å¤‡è®­ç»ƒæ•°æ®...")
            
            # é€‰æ‹©ç‰¹å¾åˆ— (æ’é™¤dateå’Œtarget_variable)
            feature_columns = [col for col in df.columns 
                             if col not in ['date', self.config['target_variable']]]
            
            # å¤„ç†ç¼ºå¤±å€¼
            df_clean = df[feature_columns + [self.config['target_variable']]].dropna()
            
            if len(df_clean) == 0:
                raise ValueError("æ¸…ç†åæ²¡æœ‰å¯ç”¨æ•°æ®")
            
            # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
            X = df_clean[feature_columns].values
            y = df_clean[self.config['target_variable']].values
            
            # åˆ›å»ºåºåˆ—æ•°æ®
            X_sequences, y_sequences = self._create_sequences(X, y)
            
            logger.info(f"âœ… è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆ: {X_sequences.shape} -> {y_sequences.shape}")
            
            return X_sequences, y_sequences
            
        except Exception as e:
            logger.error(f"âŒ å‡†å¤‡è®­ç»ƒæ•°æ®å¤±è´¥: {e}")
            raise
    
    def _create_sequences(self, X: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """åˆ›å»ºåºåˆ—æ•°æ®"""
        try:
            sequence_length = self.config['sequence_length']
            
            X_sequences = []
            y_sequences = []
            
            for i in range(len(X) - sequence_length):
                X_sequences.append(X[i:(i + sequence_length)])
                y_sequences.append(y[i + sequence_length])
            
            return np.array(X_sequences), np.array(y_sequences)
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºåºåˆ—æ•°æ®å¤±è´¥: {e}")
            raise
    
    def split_data(self, X: np.ndarray, y: np.ndarray, 
                   train_ratio: float = 0.7, val_ratio: float = 0.15) -> Dict:
        """åˆ†å‰²æ•°æ®ä¸ºè®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•é›†"""
        try:
            logger.info("âœ‚ï¸ åˆ†å‰²æ•°æ®...")
            
            total_samples = len(X)
            train_size = int(total_samples * train_ratio)
            val_size = int(total_samples * val_ratio)
            
            # æ—¶é—´åºåˆ—åˆ†å‰² (ä¿æŒæ—¶é—´é¡ºåº)
            X_train = X[:train_size]
            y_train = y[:train_size]
            
            X_val = X[train_size:train_size + val_size]
            y_val = y[train_size:train_size + val_size]
            
            X_test = X[train_size + val_size:]
            y_test = y[train_size + val_size:]
            
            split_info = {
                'train': {'X': X_train, 'y': y_train, 'size': len(X_train)},
                'validation': {'X': X_val, 'y': y_val, 'size': len(X_val)},
                'test': {'X': X_test, 'y': y_test, 'size': len(X_test)},
                'total_samples': total_samples,
                'split_ratios': {'train': train_ratio, 'val': val_ratio, 'test': 1 - train_ratio - val_ratio}
            }
            
            logger.info(f"âœ… æ•°æ®åˆ†å‰²å®Œæˆ:")
            logger.info(f"  ğŸ“Š è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
            logger.info(f"  ğŸ“Š éªŒè¯é›†: {len(X_val)} æ ·æœ¬")
            logger.info(f"  ğŸ“Š æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
            
            return split_info
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åˆ†å‰²å¤±è´¥: {e}")
            raise
    
    def get_feature_names(self) -> List[str]:
        """è·å–ç‰¹å¾åç§°"""
        try:
            if not hasattr(self, '_feature_names'):
                # åŠ è½½æ•°æ®è·å–ç‰¹å¾åç§°
                df = self.load_data()
                feature_columns = [col for col in df.columns 
                                 if col not in ['date', self.config['target_variable']]]
                self._feature_names = feature_columns
            
            return self._feature_names
            
        except Exception as e:
            logger.error(f"âŒ è·å–ç‰¹å¾åç§°å¤±è´¥: {e}")
            return []
    
    def get_data_summary(self) -> Dict:
        """è·å–æ•°æ®æ‘˜è¦"""
        try:
            df = self.load_data()
            
            summary = {
                'data_source': 'ERA5_Alternative',
                'total_records': len(df),
                'date_range': {
                    'start': df['date'].min().strftime('%Y-%m-%d'),
                    'end': df['date'].max().strftime('%Y-%m-%d')
                },
                'features': {
                    'total': len(df.columns),
                    'input_features': self.config['input_size'],
                    'target_variable': self.config['target_variable']
                },
                'variables': {
                    'soil_moisture': {
                        'mean': float(df['soil_moisture'].mean()),
                        'std': float(df['soil_moisture'].std()),
                        'min': float(df['soil_moisture'].min()),
                        'max': float(df['soil_moisture'].max())
                    },
                    'temperature': {
                        'mean': float(df['temperature'].mean()),
                        'std': float(df['temperature'].std()),
                        'min': float(df['temperature'].min()),
                        'max': float(df['temperature'].max())
                    },
                    'precipitation': {
                        'mean': float(df['precipitation'].mean()),
                        'std': float(df['precipitation'].std()),
                        'min': float(df['precipitation'].min()),
                        'max': float(df['precipitation'].max())
                    }
                },
                'config': self.config
            }
            
            return summary
            
        except Exception as e:
            logger.error(f"âŒ è·å–æ•°æ®æ‘˜è¦å¤±è´¥: {e}")
            return {'error': str(e)}
    
    def save_processed_data(self, output_dir: str = "data/processed/era5") -> Dict:
        """ä¿å­˜å¤„ç†åçš„æ•°æ®"""
        try:
            logger.info("ğŸ’¾ ä¿å­˜å¤„ç†åçš„æ•°æ®...")
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(output_dir, exist_ok=True)
            
            # åŠ è½½å’Œå‡†å¤‡æ•°æ®
            df = self.load_data()
            X, y = self.prepare_training_data(df)
            split_info = self.split_data(X, y)
            
            # ä¿å­˜åˆ†å‰²åçš„æ•°æ®
            np.save(os.path.join(output_dir, 'X_train.npy'), split_info['train']['X'])
            np.save(os.path.join(output_dir, 'y_train.npy'), split_info['train']['y'])
            np.save(os.path.join(output_dir, 'X_val.npy'), split_info['validation']['X'])
            np.save(os.path.join(output_dir, 'y_val.npy'), split_info['validation']['y'])
            np.save(os.path.join(output_dir, 'X_test.npy'), split_info['test']['X'])
            np.save(os.path.join(output_dir, 'y_test.npy'), split_info['test']['y'])
            
            # ä¿å­˜ç‰¹å¾åç§°
            feature_names = self.get_feature_names()
            with open(os.path.join(output_dir, 'feature_names.json'), 'w') as f:
                json.dump(feature_names, f)
            
            # ä¿å­˜é…ç½®
            with open(os.path.join(output_dir, 'config.json'), 'w') as f:
                json.dump(self.config, f, indent=2)
            
            # ä¿å­˜æ•°æ®æ‘˜è¦
            summary = self.get_data_summary()
            with open(os.path.join(output_dir, 'data_summary.json'), 'w') as f:
                json.dump(summary, f, indent=2)
            
            logger.info(f"âœ… å¤„ç†åæ•°æ®ä¿å­˜å®Œæˆ: {output_dir}")
            
            return {
                'status': 'success',
                'output_dir': output_dir,
                'files_saved': [
                    'X_train.npy', 'y_train.npy',
                    'X_val.npy', 'y_val.npy',
                    'X_test.npy', 'y_test.npy',
                    'feature_names.json', 'config.json', 'data_summary.json'
                ],
                'data_summary': summary
            }
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜å¤„ç†åæ•°æ®å¤±è´¥: {e}")
            return {'status': 'error', 'error': str(e)}

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ERA5æ•°æ®å¤„ç†å™¨æµ‹è¯•")
    print("=" * 60)
    
    try:
        # åˆ›å»ºæ•°æ®å¤„ç†å™¨
        processor = ERA5DataProcessor()
        
        # è·å–æ•°æ®æ‘˜è¦
        print("\nğŸ“Š æ•°æ®æ‘˜è¦:")
        summary = processor.get_data_summary()
        print(f"ğŸ“ æ•°æ®æº: {summary.get('data_source', 'Unknown')}")
        print(f"ğŸ“Š æ€»è®°å½•æ•°: {summary.get('total_records', 0)}")
        print(f"ğŸ“… æ—¥æœŸèŒƒå›´: {summary.get('date_range', {}).get('start', 'Unknown')} åˆ° {summary.get('date_range', {}).get('end', 'Unknown')}")
        print(f"ğŸ”§ ç‰¹å¾æ•°é‡: {summary.get('features', {}).get('input_features', 0)}")
        
        # ä¿å­˜å¤„ç†åçš„æ•°æ®
        print("\nğŸ’¾ ä¿å­˜å¤„ç†åçš„æ•°æ®...")
        save_result = processor.save_processed_data()
        
        if save_result['status'] == 'success':
            print(f"âœ… æ•°æ®ä¿å­˜æˆåŠŸ!")
            print(f"ğŸ“ è¾“å‡ºç›®å½•: {save_result['output_dir']}")
            print(f"ğŸ“„ ä¿å­˜çš„æ–‡ä»¶: {len(save_result['files_saved'])} ä¸ª")
        else:
            print(f"âŒ æ•°æ®ä¿å­˜å¤±è´¥: {save_result.get('error', 'Unknown error')}")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    main()
