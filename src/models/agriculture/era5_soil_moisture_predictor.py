#!/usr/bin/env python3
"""
ERA5åœŸå£¤æ¹¿åº¦é¢„æµ‹æ¨¡å‹
åŸºäºERA5æ›¿ä»£æ•°æ®çš„LSTMæ¨¡å‹
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import pandas as pd
import logging
import json
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ERA5SoilMoistureLSTM(nn.Module):
    """ERA5åœŸå£¤æ¹¿åº¦LSTMæ¨¡å‹"""
    
    def __init__(self, input_size: int, hidden_size: int = 64, num_layers: int = 2, dropout: float = 0.2):
        super(ERA5SoilMoistureLSTM, self).__init__()
        
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        # LSTMå±‚
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0
        )
        
        # å…¨è¿æ¥å±‚
        self.fc1 = nn.Linear(hidden_size, 32)
        self.fc2 = nn.Linear(32, 16)
        self.fc3 = nn.Linear(16, 1)
        
        # Dropoutå±‚
        self.dropout = nn.Dropout(dropout)
        
        # æ¿€æ´»å‡½æ•°
        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()
        
        logger.info(f"âœ… ERA5åœŸå£¤æ¹¿åº¦LSTMæ¨¡å‹åˆ›å»ºå®Œæˆ: input_size={input_size}, hidden_size={hidden_size}, num_layers={num_layers}")
    
    def forward(self, x):
        # LSTMå‰å‘ä¼ æ’­
        lstm_out, _ = self.lstm(x)
        
        # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
        last_output = lstm_out[:, -1, :]
        
        # å…¨è¿æ¥å±‚
        x = self.relu(self.fc1(last_output))
        x = self.dropout(x)
        x = self.relu(self.fc2(x))
        x = self.dropout(x)
        x = self.fc3(x)
        
        # ä½¿ç”¨sigmoidç¡®ä¿è¾“å‡ºåœ¨0-1ä¹‹é—´ (åœŸå£¤æ¹¿åº¦èŒƒå›´)
        x = self.sigmoid(x)
        
        return x

class ERA5SoilMoisturePredictor:
    """ERA5åœŸå£¤æ¹¿åº¦é¢„æµ‹å™¨"""
    
    def __init__(self, model_dir: str = "models/era5_soil_moisture"):
        self.model_dir = model_dir
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # æ¨¡å‹é…ç½®
        self.config = {
            'input_size': None,  # åŠ¨æ€è®¾ç½®
            'hidden_size': 64,
            'num_layers': 2,
            'dropout': 0.2,
            'learning_rate': 0.001,
            'batch_size': 16,
            'epochs': 100,
            'sequence_length': 30,
            'patience': 15,
            'min_delta': 0.0001
        }
        
        # æ¨¡å‹å’Œä¼˜åŒ–å™¨
        self.model = None
        self.optimizer = None
        self.criterion = None
        
        # è®­ç»ƒå†å²
        self.training_history = {
            'train_loss': [],
            'val_loss': [],
            'train_mae': [],
            'val_mae': []
        }
        
        logger.info(f"âœ… ERA5åœŸå£¤æ¹¿åº¦é¢„æµ‹å™¨åˆå§‹åŒ–å®Œæˆï¼Œè®¾å¤‡: {self.device}")
    
    def build_model(self, input_size: int) -> None:
        """æ„å»ºæ¨¡å‹"""
        try:
            logger.info(f"ğŸ”§ æ„å»ºæ¨¡å‹ï¼Œè¾“å…¥ç‰¹å¾æ•°: {input_size}")
            
            self.config['input_size'] = input_size
            
            # åˆ›å»ºæ¨¡å‹
            self.model = ERA5SoilMoistureLSTM(
                input_size=input_size,
                hidden_size=self.config['hidden_size'],
                num_layers=self.config['num_layers'],
                dropout=self.config['dropout']
            ).to(self.device)
            
            # åˆ›å»ºä¼˜åŒ–å™¨
            self.optimizer = optim.Adam(
                self.model.parameters(), 
                lr=self.config['learning_rate']
            )
            
            # åˆ›å»ºæŸå¤±å‡½æ•°
            self.criterion = nn.MSELoss()
            
            # å­¦ä¹ ç‡è°ƒåº¦å™¨
            self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
                self.optimizer, 
                mode='min', 
                factor=0.5, 
                patience=10
            )
            
            logger.info("âœ… æ¨¡å‹æ„å»ºå®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹æ„å»ºå¤±è´¥: {e}")
            raise
    
    def load_data(self, data_dir: str = "data/processed/era5") -> Dict:
        """åŠ è½½å¤„ç†åçš„æ•°æ®"""
        try:
            logger.info(f"ğŸ“¥ åŠ è½½æ•°æ®: {data_dir}")
            
            # æ£€æŸ¥æ•°æ®æ–‡ä»¶
            required_files = ['X_train.npy', 'y_train.npy', 'X_val.npy', 'y_val.npy', 'X_test.npy', 'y_test.npy']
            for file in required_files:
                file_path = os.path.join(data_dir, file)
                if not os.path.exists(file_path):
                    raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
            # åŠ è½½æ•°æ®
            data = {}
            for split in ['train', 'val', 'test']:
                X_file = os.path.join(data_dir, f'X_{split}.npy')
                y_file = os.path.join(data_dir, f'y_{split}.npy')
                
                data[f'X_{split}'] = np.load(X_file)
                data[f'y_{split}'] = np.load(y_file)
                
                logger.info(f"  ğŸ“Š {split}: X={data[f'X_{split}'].shape}, y={data[f'y_{split}'].shape}")
            
            # åŠ è½½é…ç½®
            config_file = os.path.join(data_dir, 'config.json')
            if os.path.exists(config_file):
                with open(config_file, 'r') as f:
                    data_config = json.load(f)
                    self.config['sequence_length'] = data_config.get('sequence_length', 30)
            
            logger.info("âœ… æ•°æ®åŠ è½½å®Œæˆ")
            return data
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            raise
    
    def create_data_loaders(self, data: Dict, batch_size: int = None) -> Dict:
        """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
        try:
            logger.info("ğŸ”§ åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
            
            if batch_size is None:
                batch_size = self.config['batch_size']
            
            loaders = {}
            
            for split in ['train', 'val', 'test']:
                X = torch.FloatTensor(data[f'X_{split}']).to(self.device)
                y = torch.FloatTensor(data[f'y_{split}']).to(self.device)
                
                dataset = TensorDataset(X, y)
                loader = DataLoader(
                    dataset, 
                    batch_size=batch_size, 
                    shuffle=(split == 'train')
                )
                
                loaders[split] = loader
                logger.info(f"  ğŸ“Š {split}: {len(loader)} æ‰¹æ¬¡")
            
            logger.info("âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ")
            return loaders
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºæ•°æ®åŠ è½½å™¨å¤±è´¥: {e}")
            raise
    
    def train_model(self, data_loaders: Dict) -> Dict:
        """è®­ç»ƒæ¨¡å‹"""
        try:
            logger.info("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹...")
            
            if self.model is None:
                raise ValueError("æ¨¡å‹æœªæ„å»ºï¼Œè¯·å…ˆè°ƒç”¨build_model()")
            
            # è®­ç»ƒå‚æ•°
            epochs = self.config['epochs']
            patience = self.config['patience']
            min_delta = self.config['min_delta']
            
            # æ—©åœå˜é‡
            best_val_loss = float('inf')
            patience_counter = 0
            
            # è®­ç»ƒå¾ªç¯
            for epoch in range(epochs):
                # è®­ç»ƒé˜¶æ®µ
                self.model.train()
                train_loss = 0.0
                train_mae = 0.0
                train_batches = 0
                
                for batch_X, batch_y in data_loaders['train']:
                    self.optimizer.zero_grad()
                    
                    # å‰å‘ä¼ æ’­
                    outputs = self.model(batch_X)
                    loss = self.criterion(outputs.squeeze(), batch_y)
                    
                    # åå‘ä¼ æ’­
                    loss.backward()
                    self.optimizer.step()
                    
                    # ç»Ÿè®¡
                    train_loss += loss.item()
                    train_mae += mean_absolute_error(
                        batch_y.cpu().numpy(), 
                        outputs.detach().cpu().numpy().squeeze()
                    )
                    train_batches += 1
                
                # éªŒè¯é˜¶æ®µ
                self.model.eval()
                val_loss = 0.0
                val_mae = 0.0
                val_batches = 0
                
                with torch.no_grad():
                    for batch_X, batch_y in data_loaders['val']:
                        outputs = self.model(batch_X)
                        loss = self.criterion(outputs.squeeze(), batch_y)
                        
                        val_loss += loss.item()
                        val_mae += mean_absolute_error(
                            batch_y.cpu().numpy(), 
                            outputs.cpu().numpy().squeeze()
                        )
                        val_batches += 1
                
                # è®¡ç®—å¹³å‡æŸå¤±
                avg_train_loss = train_loss / train_batches
                avg_val_loss = val_loss / val_batches
                avg_train_mae = train_mae / train_batches
                avg_val_mae = val_mae / val_batches
                
                # æ›´æ–°å­¦ä¹ ç‡
                self.scheduler.step(avg_val_loss)
                
                # è®°å½•å†å²
                self.training_history['train_loss'].append(avg_train_loss)
                self.training_history['val_loss'].append(avg_val_loss)
                self.training_history['train_mae'].append(avg_train_mae)
                self.training_history['val_mae'].append(avg_val_mae)
                
                # æ‰“å°è¿›åº¦
                if (epoch + 1) % 10 == 0:
                    logger.info(f"Epoch {epoch+1}/{epochs}: "
                              f"Train Loss: {avg_train_loss:.6f}, "
                              f"Val Loss: {avg_val_loss:.6f}, "
                              f"Train MAE: {avg_train_mae:.6f}, "
                              f"Val MAE: {avg_val_mae:.6f}")
                
                # æ—©åœæ£€æŸ¥
                if avg_val_loss < best_val_loss - min_delta:
                    best_val_loss = avg_val_loss
                    patience_counter = 0
                    
                    # ä¿å­˜æœ€ä½³æ¨¡å‹
                    self.save_model('best_model.pth')
                else:
                    patience_counter += 1
                
                # æ—©åœ
                if patience_counter >= patience:
                    logger.info(f"æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬ {epoch+1} è½®åœæ­¢è®­ç»ƒ")
                    break
            
            logger.info("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")
            
            return {
                'status': 'success',
                'epochs_trained': epoch + 1,
                'best_val_loss': best_val_loss,
                'final_train_loss': avg_train_loss,
                'final_val_loss': avg_val_loss,
                'training_history': self.training_history
            }
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def evaluate_model(self, data_loaders: Dict) -> Dict:
        """è¯„ä¼°æ¨¡å‹"""
        try:
            logger.info("ğŸ“Š è¯„ä¼°æ¨¡å‹...")
            
            if self.model is None:
                raise ValueError("æ¨¡å‹æœªæ„å»º")
            
            self.model.eval()
            results = {}
            
            with torch.no_grad():
                for split in ['train', 'val', 'test']:
                    all_predictions = []
                    all_targets = []
                    
                    for batch_X, batch_y in data_loaders[split]:
                        outputs = self.model(batch_X)
                        predictions = outputs.cpu().numpy().squeeze()
                        targets = batch_y.cpu().numpy()
                        
                        all_predictions.extend(predictions)
                        all_targets.extend(targets)
                    
                    # è®¡ç®—æŒ‡æ ‡
                    mse = mean_squared_error(all_targets, all_predictions)
                    mae = mean_absolute_error(all_targets, all_predictions)
                    r2 = r2_score(all_targets, all_predictions)
                    
                    results[split] = {
                        'mse': mse,
                        'mae': mae,
                        'r2': r2,
                        'rmse': np.sqrt(mse),
                        'predictions': all_predictions,
                        'targets': all_targets
                    }
                    
                    logger.info(f"  ğŸ“Š {split}: MSE={mse:.6f}, MAE={mae:.6f}, RÂ²={r2:.6f}")
            
            logger.info("âœ… æ¨¡å‹è¯„ä¼°å®Œæˆ")
            return results
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹è¯„ä¼°å¤±è´¥: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def save_model(self, filename: str) -> None:
        """ä¿å­˜æ¨¡å‹"""
        try:
            os.makedirs(self.model_dir, exist_ok=True)
            model_path = os.path.join(self.model_dir, filename)
            
            torch.save({
                'model_state_dict': self.model.state_dict(),
                'optimizer_state_dict': self.optimizer.state_dict(),
                'config': self.config,
                'training_history': self.training_history
            }, model_path)
            
            logger.info(f"âœ… æ¨¡å‹ä¿å­˜å®Œæˆ: {model_path}")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹ä¿å­˜å¤±è´¥: {e}")
            raise
    
    def load_model(self, filename: str) -> None:
        """åŠ è½½æ¨¡å‹"""
        try:
            model_path = os.path.join(self.model_dir, filename)
            
            if not os.path.exists(model_path):
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            
            checkpoint = torch.load(model_path, map_location=self.device)
            
            # æ„å»ºæ¨¡å‹
            if self.model is None:
                input_size = checkpoint['config'].get('input_size')
                if input_size is None:
                    # å¦‚æœæ²¡æœ‰input_sizeï¼Œä½¿ç”¨é»˜è®¤å€¼
                    input_size = 35
                self.build_model(input_size)
            
            # åŠ è½½çŠ¶æ€
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            self.config = checkpoint['config']
            self.training_history = checkpoint['training_history']
            
            logger.info(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ: {model_path}")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """è¿›è¡Œé¢„æµ‹"""
        try:
            if self.model is None:
                raise ValueError("æ¨¡å‹æœªæ„å»º")
            
            self.model.eval()
            
            # è½¬æ¢ä¸ºtensor
            X_tensor = torch.FloatTensor(X).to(self.device)
            
            with torch.no_grad():
                predictions = self.model(X_tensor)
                return predictions.cpu().numpy().squeeze()
                
        except Exception as e:
            logger.error(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
            raise
    
    def plot_training_history(self, save_path: str = None) -> None:
        """ç»˜åˆ¶è®­ç»ƒå†å²"""
        try:
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
            
            # æŸå¤±æ›²çº¿
            ax1.plot(self.training_history['train_loss'], label='Train Loss')
            ax1.plot(self.training_history['val_loss'], label='Validation Loss')
            ax1.set_title('Training and Validation Loss')
            ax1.set_xlabel('Epoch')
            ax1.set_ylabel('Loss')
            ax1.legend()
            ax1.grid(True)
            
            # MAEæ›²çº¿
            ax2.plot(self.training_history['train_mae'], label='Train MAE')
            ax2.plot(self.training_history['val_mae'], label='Validation MAE')
            ax2.set_title('Training and Validation MAE')
            ax2.set_xlabel('Epoch')
            ax2.set_ylabel('MAE')
            ax2.legend()
            ax2.grid(True)
            
            plt.tight_layout()
            
            if save_path:
                plt.savefig(save_path, dpi=300, bbox_inches='tight')
                logger.info(f"âœ… è®­ç»ƒå†å²å›¾ä¿å­˜: {save_path}")
            
            plt.show()
            
        except Exception as e:
            logger.error(f"âŒ ç»˜åˆ¶è®­ç»ƒå†å²å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ERA5åœŸå£¤æ¹¿åº¦é¢„æµ‹æ¨¡å‹æµ‹è¯•")
    print("=" * 60)
    
    try:
        # åˆ›å»ºé¢„æµ‹å™¨
        predictor = ERA5SoilMoisturePredictor()
        
        # åŠ è½½æ•°æ®
        print("\nğŸ“¥ åŠ è½½æ•°æ®...")
        data = predictor.load_data()
        
        # æ„å»ºæ¨¡å‹
        print("\nğŸ”§ æ„å»ºæ¨¡å‹...")
        input_size = data['X_train'].shape[2]  # ç‰¹å¾æ•°é‡
        predictor.build_model(input_size)
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        print("\nğŸ”§ åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
        data_loaders = predictor.create_data_loaders(data)
        
        # è®­ç»ƒæ¨¡å‹
        print("\nğŸš€ è®­ç»ƒæ¨¡å‹...")
        training_result = predictor.train_model(data_loaders)
        
        if training_result['status'] == 'success':
            print(f"âœ… è®­ç»ƒå®Œæˆ!")
            print(f"ğŸ“Š è®­ç»ƒè½®æ•°: {training_result['epochs_trained']}")
            print(f"ğŸ“Š æœ€ä½³éªŒè¯æŸå¤±: {training_result['best_val_loss']:.6f}")
            
            # è¯„ä¼°æ¨¡å‹
            print("\nğŸ“Š è¯„ä¼°æ¨¡å‹...")
            evaluation_results = predictor.evaluate_model(data_loaders)
            
            # ä¿å­˜æ¨¡å‹
            print("\nğŸ’¾ ä¿å­˜æ¨¡å‹...")
            predictor.save_model('era5_soil_moisture_model.pth')
            
            # ç»˜åˆ¶è®­ç»ƒå†å²
            print("\nğŸ“ˆ ç»˜åˆ¶è®­ç»ƒå†å²...")
            plot_path = os.path.join(predictor.model_dir, 'training_history.png')
            predictor.plot_training_history(plot_path)
            
        else:
            print(f"âŒ è®­ç»ƒå¤±è´¥: {training_result.get('error', 'Unknown error')}")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    main()
