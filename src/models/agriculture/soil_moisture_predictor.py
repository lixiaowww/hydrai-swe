#!/usr/bin/env python3
"""
HydrAI-SWE å†œä¸šæ¨¡å— - åœŸå£¤æ°´åˆ†é¢„æµ‹å™¨
åŸºäºGitHubé¡¹ç›® SoilWeatherPredictor é›†æˆ
"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

class SoilMoistureLSTM(nn.Module):
    """åœŸå£¤æ°´åˆ†é¢„æµ‹LSTMæ¨¡å‹ - åŸºäºSoilWeatherPredictoræ¶æ„"""
    
    def __init__(self, input_size, hidden_size, num_layers, dropout=0.2):
        super(SoilMoistureLSTM, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        # LSTMå±‚
        self.lstm = nn.LSTM(
            input_size, 
            hidden_size, 
            num_layers, 
            batch_first=True, 
            dropout=dropout if num_layers > 1 else 0
        )
        
        # å…¨è¿æ¥å±‚
        self.dropout = nn.Dropout(dropout)
        self.fc1 = nn.Linear(hidden_size, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 1)
        
        # æ¿€æ´»å‡½æ•°
        self.relu = nn.ReLU()
        
    def forward(self, x):
        # x shape: (batch_size, seq_length, input_size)
        lstm_out, _ = self.lstm(x)
        
        # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
        last_output = lstm_out[:, -1, :]
        
        # å…¨è¿æ¥å±‚
        x = self.dropout(last_output)
        x = self.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.relu(self.fc2(x))
        x = self.dropout(x)
        output = self.fc3(x)
        
        return output

class AgricultureDataProcessor:
    """å†œä¸šæ•°æ®å¤„ç†å™¨"""
    
    def __init__(self):
        self.scaler_X = StandardScaler()
        self.scaler_y = StandardScaler()
        self.config = {
            'input_size': None,
            'sequence_length': 30
        }
        
    def prepare_soil_moisture_data(self, data_path, sequence_length=30):
        """
        å‡†å¤‡åœŸå£¤æ°´åˆ†é¢„æµ‹æ•°æ®
        
        Args:
            data_path (str): æ•°æ®æ–‡ä»¶è·¯å¾„
            sequence_length (int): åºåˆ—é•¿åº¦
            
        Returns:
            tuple: (X_train, y_train, X_val, y_val, X_test, y_test, scalers)
        """
        print("ğŸ“Š å‡†å¤‡åœŸå£¤æ°´åˆ†é¢„æµ‹æ•°æ®...")
        
        # åŠ è½½æ•°æ®
        df = pd.read_csv(data_path, parse_dates=['date'])
        df.set_index('date', inplace=True)
        
        # é€‰æ‹©ç‰¹å¾åˆ—
        feature_columns = [
            'snow_depth_mm', 'snow_water_equivalent_mm',
            'day_of_year', 'month', 'year'
        ]
        
        # ç¡®ä¿æ‰€æœ‰ç‰¹å¾åˆ—å­˜åœ¨
        available_features = [col for col in feature_columns if col in df.columns]
        print(f"å¯ç”¨ç‰¹å¾: {available_features}")
        
        # å¤„ç†ç¼ºå¤±å€¼
        df = df.fillna(method='ffill').fillna(0)
        
        # å¦‚æœæ²¡æœ‰åœŸå£¤æ°´åˆ†åˆ—ï¼Œä½¿ç”¨çœŸå®æ•°æ®æˆ–æ ‡è®°ä¸ºä¸å¯ç”¨
        if 'soil_moisture' not in df.columns:
            print("âš ï¸ è­¦å‘Šï¼šæ²¡æœ‰åœŸå£¤æ°´åˆ†æ•°æ®åˆ—")
            print("âŒ ç³»ç»Ÿç¦æ­¢ä½¿ç”¨åˆæˆæ•°æ®ï¼Œè¯·æä¾›çœŸå®çš„åœŸå£¤æ°´åˆ†è§‚æµ‹æ•°æ®")
            print("ğŸ’¡ å»ºè®®ï¼šè”ç³»æ•°æ®æä¾›æ–¹è·å–çœŸå®çš„åœŸå£¤æ°´åˆ†ä¼ æ„Ÿå™¨æ•°æ®")
            raise ValueError("Missing soil moisture data. Synthetic data generation is prohibited.")
        
        # åˆ›å»ºåºåˆ—æ•°æ®
        X, y = [], []
        for i in range(sequence_length, len(df)):
            X.append(df[available_features].iloc[i-sequence_length:i].values)
            y.append(df['soil_moisture'].iloc[i])
        
        X = np.array(X)
        y = np.array(y)
        
        print(f"åºåˆ—æ•°æ®å½¢çŠ¶: X={X.shape}, y={y.shape}")
        
        # æ•°æ®æ ‡å‡†åŒ–
        X_reshaped = X.reshape(-1, X.shape[-1])
        X_scaled = self.scaler_X.fit_transform(X_reshaped)
        X_scaled = X_scaled.reshape(X.shape)
        
        y_scaled = self.scaler_y.fit_transform(y.reshape(-1, 1)).flatten()
        
        # åˆ’åˆ†æ•°æ®é›†
        train_size = int(0.7 * len(X_scaled))
        val_size = int(0.15 * len(X_scaled))
        
        X_train = X_scaled[:train_size]
        y_train = y_scaled[:train_size]
        X_val = X_scaled[train_size:train_size+val_size]
        y_val = y_scaled[train_size:train_size+val_size]
        X_test = X_scaled[train_size+val_size:]
        y_test = y_scaled[train_size+val_size:]
        
        print(f"æ•°æ®é›†åˆ’åˆ†: è®­ç»ƒ={len(X_train)}, éªŒè¯={len(X_val)}, æµ‹è¯•={len(X_test)}")
        
        # åŠ¨æ€è®¾ç½®input_size
        self.config['input_size'] = len(available_features)
        print(f"ğŸ”§ åŠ¨æ€è®¾ç½®input_size: {self.config['input_size']}")
        
        return X_train, y_train, X_val, y_val, X_test, y_test, (self.scaler_X, self.scaler_y)
    
    def process_real_soil_data(self, weather_data, soil_measurements):
        """
        å¤„ç†çœŸå®åœŸå£¤æ°´åˆ†è§‚æµ‹æ•°æ®
        
        Args:
            weather_data (pd.DataFrame): å¤©æ°”æ•°æ®
            soil_measurements (pd.Series): çœŸå®åœŸå£¤æ°´åˆ†è§‚æµ‹æ•°æ®
            
        Returns:
            pd.Series: å¤„ç†åçš„åœŸå£¤æ°´åˆ†æ•°æ®
        """
        print("ğŸŒ± å¤„ç†çœŸå®åœŸå£¤æ°´åˆ†è§‚æµ‹æ•°æ®...")
        
        if soil_measurements is None or soil_measurements.empty:
            print("âš ï¸ è­¦å‘Šï¼šæ²¡æœ‰æä¾›çœŸå®åœŸå£¤æ°´åˆ†æ•°æ®")
            print("âš ï¸ æ³¨æ„ï¼šç³»ç»Ÿç¦æ­¢ä½¿ç”¨åˆæˆæ•°æ®ï¼Œè¯·æä¾›çœŸå®çš„è§‚æµ‹æ•°æ®")
            return pd.Series(dtype=float)
        
        # æ•°æ®è´¨é‡æ£€æŸ¥
        missing_rate = soil_measurements.isnull().sum() / len(soil_measurements) * 100
        if missing_rate > 50:
            print(f"âš ï¸ è­¦å‘Šï¼šåœŸå£¤æ°´åˆ†æ•°æ®ç¼ºå¤±ç‡è¿‡é«˜ ({missing_rate:.1f}%)")
            print("âš ï¸ å»ºè®®ï¼šæ£€æŸ¥æ•°æ®æºæˆ–è”ç³»æ•°æ®æä¾›æ–¹")
        
        # ç®€å•çš„æ•°æ®æ¸…ç†ï¼ˆä¸ç”Ÿæˆæ–°æ•°æ®ï¼‰
        cleaned_data = soil_measurements.copy()
        
        # åªå¯¹å°‘é‡ç¼ºå¤±å€¼è¿›è¡Œæ’å€¼ï¼Œå¤§é‡ç¼ºå¤±åˆ™æ ‡è®°ä¸ºä¸å¯ç”¨
        if missing_rate <= 20:
            cleaned_data = cleaned_data.interpolate(method='linear', limit=3)
            print(f"âœ… å·²æ¸…ç†åœŸå£¤æ°´åˆ†æ•°æ®ï¼Œç¼ºå¤±ç‡ä» {missing_rate:.1f}% é™è‡³ {cleaned_data.isnull().sum() / len(cleaned_data) * 100:.1f}%")
        else:
            print(f"âš ï¸ æ•°æ®ç¼ºå¤±ç‡è¿‡é«˜ï¼Œæ— æ³•è¿›è¡Œæœ‰æ•ˆæ’å€¼")
        
        return cleaned_data

class SoilMoisturePredictor:
    """åœŸå£¤æ°´åˆ†é¢„æµ‹å™¨ä¸»ç±»"""
    
    def __init__(self, config=None):
        """
        åˆå§‹åŒ–åœŸå£¤æ°´åˆ†é¢„æµ‹å™¨
        
        Args:
            config (dict): é…ç½®å‚æ•°
        """
        self.config = config or self._default_config()
        self.model = None
        self.data_processor = AgricultureDataProcessor()
        self.training_history = {}
        
    def _default_config(self):
        """é»˜è®¤é…ç½®"""
        return {
            'input_size': None,  # åŠ¨æ€è®¾ç½®ï¼ŒåŒ¹é…å®é™…ç‰¹å¾æ•°é‡
            'hidden_size': 64,    # å‡å°‘éšè—å±‚å¤§å°ï¼Œé¿å…è¿‡æ‹Ÿåˆ
            'num_layers': 1,      # å‡å°‘å±‚æ•°ï¼Œç®€åŒ–æ¨¡å‹
            'dropout': 0.1,       # å‡å°‘dropoutï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§
            'learning_rate': 0.0005,  # é™ä½å­¦ä¹ ç‡ï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§
            'batch_size': 64,     # å¢åŠ batch sizeï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§
            'epochs': 100,
            'sequence_length': 30,
            'patience': 15,       # æ—©åœè€å¿ƒå€¼
            'min_delta': 0.0001   # æœ€å°æ”¹å–„é˜ˆå€¼
        }
    
    def build_model(self):
        """æ„å»ºæ¨¡å‹"""
        print("ğŸ—ï¸ æ„å»ºåœŸå£¤æ°´åˆ†é¢„æµ‹æ¨¡å‹...")
        
        # ç¡®ä¿input_sizeå·²è®¾ç½®
        if self.config['input_size'] is None:
            raise ValueError("input_sizeæœªè®¾ç½®ï¼Œè¯·å…ˆå‡†å¤‡æ•°æ®")
        
        self.model = SoilMoistureLSTM(
            input_size=self.config['input_size'],
            hidden_size=self.config['hidden_size'],
            num_layers=self.config['num_layers'],
            dropout=self.config['dropout']
        )
        
        print(f"âœ… æ¨¡å‹æ„å»ºå®Œæˆ: {self.model}")
        return self.model
    
    def train_model(self, X_train, y_train, X_val, y_val):
        """
        è®­ç»ƒæ¨¡å‹
        
        Args:
            X_train, y_train: è®­ç»ƒæ•°æ®
            X_val, y_val: éªŒè¯æ•°æ®
            
        Returns:
            dict: è®­ç»ƒå†å²
        """
        print("ğŸš€ å¼€å§‹è®­ç»ƒåœŸå£¤æ°´åˆ†é¢„æµ‹æ¨¡å‹...")
        
        if self.model is None:
            self.build_model()
        
        # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        criterion = nn.MSELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config['learning_rate'])
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode='min', factor=0.5, patience=5
        )
        
        # è®­ç»ƒå†å²
        train_losses = []
        val_losses = []
        learning_rates = []
        
        # æ—©åœæœºåˆ¶
        patience = self.config['patience']
        min_delta = self.config['min_delta']
        best_val_loss = float('inf')
        epochs_no_improve = 0
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(self.config['epochs']):
            self.model.train()
            
            # å‰å‘ä¼ æ’­
            outputs = self.model(torch.FloatTensor(X_train))
            loss = criterion(outputs.squeeze(), torch.FloatTensor(y_train))
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            # éªŒè¯
            self.model.eval()
            with torch.no_grad():
                val_outputs = self.model(torch.FloatTensor(X_val))
                val_loss = criterion(val_outputs.squeeze(), torch.FloatTensor(y_val))
            
            train_losses.append(loss.item())
            val_losses.append(val_loss.item())
            
            # æ›´æ–°å­¦ä¹ ç‡
            scheduler.step(val_loss)
            learning_rates.append(optimizer.param_groups[0]['lr'])
            
            # æ—©åœæ£€æŸ¥
            if val_loss < best_val_loss - min_delta:
                best_val_loss = val_loss
                epochs_no_improve = 0
            else:
                epochs_no_improve += 1
                if epochs_no_improve >= patience:
                    print(f"æ—©åœæœºåˆ¶è§¦å‘ï¼ŒéªŒè¯æŸå¤±åœ¨ {patience} è½®åæ²¡æœ‰æ”¹å–„ã€‚")
                    break
            
            if (epoch + 1) % 10 == 0:
                print(f"Epoch [{epoch+1}/{self.config['epochs']}], "
                      f"Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, "
                      f"LR: {optimizer.param_groups[0]['lr']:.6f}")
        
        print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!")
        
        self.training_history = {
            'train_losses': train_losses,
            'val_losses': val_losses,
            'learning_rates': learning_rates
        }
        
        return self.training_history
    
    def predict(self, X, scaler_y):
        """
        è¿›è¡Œé¢„æµ‹
        
        Args:
            X (np.array): è¾“å…¥æ•°æ®
            scaler_y (StandardScaler): ç›®æ ‡å˜é‡æ ‡å‡†åŒ–å™¨
            
        Returns:
            np.array: é¢„æµ‹ç»“æœ
        """
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹")
        
        self.model.eval()
        with torch.no_grad():
            predictions = self.model(torch.FloatTensor(X))
            predictions = predictions.squeeze().numpy()
        
        # åæ ‡å‡†åŒ–
        predictions_original = scaler_y.inverse_transform(predictions.reshape(-1, 1)).flatten()
        
        return predictions_original
    
    def evaluate_model(self, X_test, y_test, scaler_y):
        """
        è¯„ä¼°æ¨¡å‹æ€§èƒ½
        
        Args:
            X_test, y_test: æµ‹è¯•æ•°æ®
            scaler_y: ç›®æ ‡å˜é‡æ ‡å‡†åŒ–å™¨
            
        Returns:
            dict: è¯„ä¼°æŒ‡æ ‡
        """
        print("ğŸ“ˆ è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
        
        predictions = self.predict(X_test, scaler_y)
        y_test_original = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()
        
        # è®¡ç®—æŒ‡æ ‡
        mse = mean_squared_error(y_test_original, predictions)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test_original, predictions)
        r2 = r2_score(y_test_original, predictions)
        
        metrics = {
            'mse': mse,
            'rmse': rmse,
            'mae': mae,
            'r2': r2
        }
        
        print(f"ğŸ“Š æ¨¡å‹æ€§èƒ½æŒ‡æ ‡:")
        print(f"  MSE: {mse:.4f}")
        print(f"  RMSE: {rmse:.4f}")
        print(f"  MAE: {mae:.4f}")
        print(f"  RÂ²: {r2:.4f}")
        
        return predictions, y_test_original, metrics
    
    def save_model(self, filepath):
        """ä¿å­˜æ¨¡å‹"""
        if self.model is None:
            raise ValueError("æ²¡æœ‰æ¨¡å‹å¯ä¿å­˜")
        
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'config': self.config,
            'training_history': self.training_history
        }, filepath)
        
        print(f"ğŸ’¾ æ¨¡å‹ä¿å­˜åˆ°: {filepath}")
    
    def load_model(self, filepath):
        """åŠ è½½æ¨¡å‹"""
        checkpoint = torch.load(filepath)
        
        self.config = checkpoint['config']
        self.training_history = checkpoint.get('training_history', {})
        
        self.build_model()
        self.model.load_state_dict(checkpoint['model_state_dict'])
        
        print(f"ğŸ“¥ æ¨¡å‹ä» {filepath} åŠ è½½å®Œæˆ")
    
    def plot_training_history(self, save_path=None):
        """ç»˜åˆ¶è®­ç»ƒå†å²"""
        if not self.training_history:
            print("âŒ æ²¡æœ‰è®­ç»ƒå†å²æ•°æ®")
            return
        
        plt.figure(figsize=(12, 5))
        
        # è®­ç»ƒæŸå¤±
        plt.subplot(1, 2, 1)
        plt.plot(self.training_history['train_losses'], label='è®­ç»ƒæŸå¤±', alpha=0.7)
        plt.plot(self.training_history['val_losses'], label='éªŒè¯æŸå¤±', alpha=0.7)
        plt.xlabel('è®­ç»ƒè½®æ•°')
        plt.ylabel('æŸå¤±å€¼')
        plt.title('åœŸå£¤æ°´åˆ†é¢„æµ‹æ¨¡å‹è®­ç»ƒå†å²')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # æŸå¤±å¯¹æ¯”
        plt.subplot(1, 2, 2)
        final_train_loss = self.training_history['train_losses'][-1]
        final_val_loss = self.training_history['val_losses'][-1]
        
        plt.bar(['è®­ç»ƒæŸå¤±', 'éªŒè¯æŸå¤±'], [final_train_loss, final_val_loss], 
                color=['skyblue', 'lightcoral'])
        plt.ylabel('æŸå¤±å€¼')
        plt.title('æœ€ç»ˆæŸå¤±å¯¹æ¯”')
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š è®­ç»ƒå†å²å›¾ä¿å­˜åˆ°: {save_path}")
        
        plt.show()

def main():
    """ä¸»å‡½æ•° - ç¤ºä¾‹ç”¨æ³•"""
    print("ğŸš€ HydrAI-SWE å†œä¸šæ¨¡å— - åœŸå£¤æ°´åˆ†é¢„æµ‹å™¨")
    print("=" * 60)
    
    # åˆ›å»ºé¢„æµ‹å™¨
    predictor = SoilMoisturePredictor()
    
    # å‡†å¤‡æ•°æ®
    data_path = "../../neuralhydrology/data/red_river_basin/timeseries.csv"
    
    try:
        # å‡†å¤‡æ•°æ®
        X_train, y_train, X_val, y_val, X_test, y_test, scalers = \
            predictor.data_processor.prepare_soil_moisture_data(data_path)
        
        # è®­ç»ƒæ¨¡å‹
        training_history = predictor.train_model(X_train, y_train, X_val, y_val)
        
        # è¯„ä¼°æ¨¡å‹
        predictions, actual, metrics = predictor.evaluate_model(X_test, y_test, scalers[1])
        
        # ä¿å­˜æ¨¡å‹
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        model_save_path = f"soil_moisture_model_{timestamp}.pth"
        predictor.save_model(model_save_path)
        
        # ç»˜åˆ¶è®­ç»ƒå†å²
        predictor.plot_training_history(f"training_history_{timestamp}.png")
        
        print("\nâœ… åœŸå£¤æ°´åˆ†é¢„æµ‹å™¨è®­ç»ƒå®Œæˆ!")
        print(f"ğŸ“Š æœ€ç»ˆæ€§èƒ½: RMSE={metrics['rmse']:.4f}, RÂ²={metrics['r2']:.4f}")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶è·¯å¾„å’Œæ ¼å¼")

if __name__ == "__main__":
    main()
