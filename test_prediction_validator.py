#!/usr/bin/env python3
"""
HydrAI-SWE é¢„æµ‹éªŒè¯å™¨æµ‹è¯•è„šæœ¬
æµ‹è¯•é¢„æµ‹è´¨é‡éªŒè¯å™¨å’Œå®æ—¶éªŒè¯å™¨çš„åŠŸèƒ½
"""

import pandas as pd
import numpy as np
import logging
import json
import os
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_prediction_validator():
    """æµ‹è¯•é¢„æµ‹è´¨é‡éªŒè¯å™¨"""
    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•é¢„æµ‹è´¨é‡éªŒè¯å™¨")
    
    try:
        # å¯¼å…¥éªŒè¯å™¨
        from src.models.validation.prediction_validator import PredictionQualityValidator
        
        # åˆ›å»ºéªŒè¯å™¨
        validator = PredictionQualityValidator()
        logger.info("âœ… é¢„æµ‹è´¨é‡éªŒè¯å™¨åˆ›å»ºæˆåŠŸ")
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        np.random.seed(42)
        dates = pd.date_range('2024-01-01', periods=100, freq='D')
        
        # æµ‹è¯•1ï¼šæ­£å¸¸çš„åœŸå£¤æ¹¿åº¦é¢„æµ‹
        logger.info("\n" + "="*50)
        logger.info("æµ‹è¯•1ï¼šæ­£å¸¸çš„åœŸå£¤æ¹¿åº¦é¢„æµ‹")
        
        normal_predictions = pd.DataFrame({
            'soil_moisture': np.random.uniform(0.1, 0.8, 100)
        }, index=dates)
        
        normal_result = validator.validate_prediction_quality(
            normal_predictions, 'soil_moisture', 'normal_model'
        )
        
        logger.info(f"æ­£å¸¸é¢„æµ‹éªŒè¯ç»“æœ:")
        logger.info(f"  æœ‰æ•ˆæ€§: {normal_result.is_valid}")
        logger.info(f"  ç½®ä¿¡åº¦åˆ†æ•°: {normal_result.confidence_score:.2%}")
        logger.info(f"  è­¦å‘Šæ•°é‡: {len(normal_result.warnings)}")
        logger.info(f"  é”™è¯¯æ•°é‡: {len(normal_result.errors)}")
        
        # æµ‹è¯•2ï¼šå¼‚å¸¸çš„åœŸå£¤æ¹¿åº¦é¢„æµ‹
        logger.info("\n" + "="*50)
        logger.info("æµ‹è¯•2ï¼šå¼‚å¸¸çš„åœŸå£¤æ¹¿åº¦é¢„æµ‹")
        
        abnormal_predictions = pd.DataFrame({
            'soil_moisture': np.random.uniform(-0.1, 1.2, 100)  # åŒ…å«è´Ÿå€¼å’Œè¶…è¿‡1çš„å€¼
        }, index=dates)
        
        abnormal_result = validator.validate_prediction_quality(
            abnormal_predictions, 'soil_moisture', 'abnormal_model'
        )
        
        logger.info(f"å¼‚å¸¸é¢„æµ‹éªŒè¯ç»“æœ:")
        logger.info(f"  æœ‰æ•ˆæ€§: {abnormal_result.is_valid}")
        logger.info(f"  ç½®ä¿¡åº¦åˆ†æ•°: {abnormal_result.confidence_score:.2%}")
        logger.info(f"  è­¦å‘Šæ•°é‡: {len(abnormal_result.warnings)}")
        logger.info(f"  é”™è¯¯æ•°é‡: {len(abnormal_result.errors)}")
        
        # æµ‹è¯•3ï¼šå¤šæ•°æ®æºä¸€è‡´æ€§éªŒè¯
        logger.info("\n" + "="*50)
        logger.info("æµ‹è¯•3ï¼šå¤šæ•°æ®æºä¸€è‡´æ€§éªŒè¯")
        
        source1_predictions = pd.DataFrame({
            'soil_moisture': np.random.uniform(0.2, 0.7, 50)
        }, index=dates[:50])
        
        source2_predictions = pd.DataFrame({
            'soil_moisture': np.random.uniform(0.2, 0.7, 50) + np.random.normal(0, 0.1, 50)
        }, index=dates[:50])
        
        multi_source_predictions = {
            'source1': source1_predictions,
            'source2': source2_predictions
        }
        
        multi_source_result = validator.validate_prediction_quality(
            multi_source_predictions, 'soil_moisture', 'multi_source'
        )
        
        logger.info(f"å¤šæºä¸€è‡´æ€§éªŒè¯ç»“æœ:")
        logger.info(f"  æœ‰æ•ˆæ€§: {multi_source_result.is_valid}")
        logger.info(f"  ç½®ä¿¡åº¦åˆ†æ•°: {multi_source_result.confidence_score:.2%}")
        logger.info(f"  è­¦å‘Šæ•°é‡: {len(multi_source_result.warnings)}")
        logger.info(f"  é”™è¯¯æ•°é‡: {len(multi_source_result.errors)}")
        
        # ç”ŸæˆéªŒè¯æŠ¥å‘Š
        logger.info("\n" + "="*50)
        logger.info("ç”ŸæˆéªŒè¯æŠ¥å‘Š")
        
        normal_report = validator.generate_validation_report(normal_result)
        abnormal_report = validator.generate_validation_report(abnormal_result)
        multi_source_report = validator.generate_validation_report(multi_source_result)
        
        # ä¿å­˜æŠ¥å‘Š
        os.makedirs("test_validation_reports", exist_ok=True)
        
        with open("test_validation_reports/normal_validation_report.md", "w", encoding="utf-8") as f:
            f.write(normal_report)
        
        with open("test_validation_reports/abnormal_validation_report.md", "w", encoding="utf-8") as f:
            f.write(abnormal_report)
        
        with open("test_validation_reports/multi_source_validation_report.md", "w", encoding="utf-8") as f:
            f.write(multi_source_report)
        
        logger.info("âœ… é¢„æµ‹è´¨é‡éªŒè¯å™¨æµ‹è¯•å®Œæˆï¼ŒæŠ¥å‘Šå·²ä¿å­˜")
        return True
        
    except Exception as e:
        logger.error(f"âŒ é¢„æµ‹è´¨é‡éªŒè¯å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_real_time_validator():
    """æµ‹è¯•å®æ—¶éªŒè¯å™¨"""
    logger.info("\nğŸ§ª å¼€å§‹æµ‹è¯•å®æ—¶éªŒè¯å™¨")
    
    try:
        # å¯¼å…¥éªŒè¯å™¨
        from src.models.validation.real_time_validator import RealTimeValidator
        
        # åˆ›å»ºéªŒè¯å™¨
        validator = RealTimeValidator()
        logger.info("âœ… å®æ—¶éªŒè¯å™¨åˆ›å»ºæˆåŠŸ")
        
        # ç”Ÿæˆå‚è€ƒæ•°æ®
        np.random.seed(42)
        reference_dates = pd.date_range('2023-01-01', periods=1000, freq='H')
        reference_data = pd.DataFrame({
            'soil_moisture': np.random.uniform(0.1, 0.8, 1000)
        }, index=reference_dates)
        
        # åˆå§‹åŒ–å‚è€ƒåˆ†å¸ƒ
        validator.initialize_reference_distribution(reference_data)
        logger.info("âœ… å‚è€ƒåˆ†å¸ƒåˆå§‹åŒ–å®Œæˆ")
        
        # æµ‹è¯•å®æ—¶éªŒè¯
        logger.info("\n" + "="*50)
        logger.info("æµ‹è¯•å®æ—¶éªŒè¯åŠŸèƒ½")
        
        for i in range(5):
            # ç”Ÿæˆé¢„æµ‹æ•°æ®
            pred_dates = pd.date_range(f'2024-01-{i+1:02d}', periods=24, freq='H')
            predictions = pd.DataFrame({
                'soil_moisture': np.random.uniform(0.1, 0.8, 24)
            }, index=pred_dates)
            
            # æ·»åŠ éªŒè¯ä»»åŠ¡
            validator.add_validation_task(
                predictions, 'soil_moisture', 'test_model', f"test_pred_{i}"
            )
            
            logger.info(f"  å·²æ·»åŠ éªŒè¯ä»»åŠ¡ {i+1}/5")
        
        # ç­‰å¾…ä»»åŠ¡å¤„ç†
        import time
        logger.info("ç­‰å¾…ä»»åŠ¡å¤„ç†å®Œæˆ...")
        time.sleep(10)
        
        # è·å–çŠ¶æ€å’Œç»“æœ
        status = validator.get_validation_status()
        recent_results = validator.get_recent_results(5)
        
        logger.info(f"å®æ—¶éªŒè¯çŠ¶æ€:")
        logger.info(f"  é˜Ÿåˆ—å¤§å°: {status['queue_size']}")
        logger.info(f"  æ€»éªŒè¯æ•°: {status['total_validations']}")
        logger.info(f"  ç›‘æ§çŠ¶æ€: {status['active_monitoring']}")
        
        logger.info(f"æœ€è¿‘éªŒè¯ç»“æœ:")
        for i, result in enumerate(recent_results):
            logger.info(f"  ç»“æœ {i+1}: è´¨é‡åˆ†æ•° {result.quality_score:.2%}, æœ‰æ•ˆ: {result.is_valid}")
        
        # åœæ­¢ç›‘æ§
        validator.stop_monitoring()
        logger.info("âœ… å®æ—¶éªŒè¯å™¨æµ‹è¯•å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ å®æ—¶éªŒè¯å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_api_integration():
    """æµ‹è¯•APIé›†æˆ"""
    logger.info("\nğŸ§ª å¼€å§‹æµ‹è¯•APIé›†æˆ")
    
    try:
        # å¯¼å…¥APIè·¯ç”±
        from src.api.routers.prediction_validation import router
        
        logger.info("âœ… APIè·¯ç”±å¯¼å…¥æˆåŠŸ")
        
        # æ£€æŸ¥APIç«¯ç‚¹
        routes = [route.path for route in router.routes]
        logger.info(f"å¯ç”¨çš„APIç«¯ç‚¹:")
        for route in routes:
            logger.info(f"  {route}")
        
        # æµ‹è¯•æ•°æ®æ¨¡å‹
        from src.api.routers.prediction_validation import ValidationRequest, ValidationResponse
        
        # åˆ›å»ºæµ‹è¯•è¯·æ±‚
        test_predictions = [
            {'timestamp': '2024-01-01T00:00:00', 'soil_moisture': 0.5},
            {'timestamp': '2024-01-01T01:00:00', 'soil_moisture': 0.6},
            {'timestamp': '2024-01-01T02:00:00', 'soil_moisture': 0.4}
        ]
        
        test_request = ValidationRequest(
            predictions=test_predictions,
            variable_type='soil_moisture',
            source_name='test_api',
            prediction_id='test_001',
            include_historical_validation=True
        )
        
        logger.info(f"æµ‹è¯•è¯·æ±‚åˆ›å»ºæˆåŠŸ:")
        logger.info(f"  å˜é‡ç±»å‹: {test_request.variable_type}")
        logger.info(f"  æ•°æ®æº: {test_request.source_name}")
        logger.info(f"  é¢„æµ‹æ•°é‡: {len(test_request.predictions)}")
        
        logger.info("âœ… APIé›†æˆæµ‹è¯•å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ APIé›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_validation_workflow():
    """æµ‹è¯•å®Œæ•´éªŒè¯å·¥ä½œæµ"""
    logger.info("\nğŸ§ª å¼€å§‹æµ‹è¯•å®Œæ•´éªŒè¯å·¥ä½œæµ")
    
    try:
        # å¯¼å…¥éªŒè¯å™¨
        from src.models.validation.prediction_validator import PredictionQualityValidator
        
        # åˆ›å»ºéªŒè¯å™¨
        validator = PredictionQualityValidator()
        
        # æ¨¡æ‹ŸçœŸå®åœºæ™¯çš„éªŒè¯å·¥ä½œæµ
        logger.info("æ¨¡æ‹ŸçœŸå®åœºæ™¯éªŒè¯å·¥ä½œæµ...")
        
        # 1. éªŒè¯åœŸå£¤æ¹¿åº¦é¢„æµ‹
        soil_moisture_data = pd.DataFrame({
            'soil_moisture': np.random.uniform(0.2, 0.7, 50)
        }, index=pd.date_range('2024-01-01', periods=50, freq='D'))
        
        soil_result = validator.validate_prediction_quality(
            soil_moisture_data, 'soil_moisture', 'agriculture_model'
        )
        
        # 2. éªŒè¯ç§¯é›ªæ°´å½“é‡é¢„æµ‹
        swe_data = pd.DataFrame({
            'snow_water_equivalent': np.random.uniform(0, 1500, 30)
        }, index=pd.date_range('2024-01-01', periods=30, freq='D'))
        
        swe_result = validator.validate_prediction_quality(
            swe_data, 'snow_water_equivalent', 'snow_model'
        )
        
        # 3. éªŒè¯å¾„æµé¢„æµ‹
        runoff_data = pd.DataFrame({
            'runoff': np.random.uniform(0, 5000, 40)
        }, index=pd.date_range('2024-01-01', periods=40, freq='D'))
        
        runoff_result = validator.validate_prediction_quality(
            runoff_data, 'runoff', 'hydrology_model'
        )
        
        # æ±‡æ€»ç»“æœ
        logger.info("éªŒè¯å·¥ä½œæµç»“æœæ±‡æ€»:")
        logger.info(f"  åœŸå£¤æ¹¿åº¦: æœ‰æ•ˆ={soil_result.is_valid}, åˆ†æ•°={soil_result.confidence_score:.2%}")
        logger.info(f"  ç§¯é›ªæ°´å½“é‡: æœ‰æ•ˆ={swe_result.is_valid}, åˆ†æ•°={swe_result.confidence_score:.2%}")
        logger.info(f"  å¾„æµ: æœ‰æ•ˆ={runoff_result.is_valid}, åˆ†æ•°={runoff_result.confidence_score:.2%}")
        
        # è®¡ç®—æ•´ä½“æœ‰æ•ˆæ€§
        overall_valid = all([soil_result.is_valid, swe_result.is_valid, runoff_result.is_valid])
        overall_score = (soil_result.confidence_score + swe_result.confidence_score + runoff_result.confidence_score) / 3
        
        logger.info(f"æ•´ä½“éªŒè¯ç»“æœ: æœ‰æ•ˆ={overall_valid}, å¹³å‡åˆ†æ•°={overall_score:.2%}")
        
        logger.info("âœ… å®Œæ•´éªŒè¯å·¥ä½œæµæµ‹è¯•å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ å®Œæ•´éªŒè¯å·¥ä½œæµæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹HydrAI-SWEé¢„æµ‹éªŒè¯å™¨å…¨é¢æµ‹è¯•")
    
    # åˆ›å»ºæµ‹è¯•ç»“æœç›®å½•
    os.makedirs("test_results", exist_ok=True)
    
    # è®°å½•æµ‹è¯•å¼€å§‹æ—¶é—´
    start_time = datetime.now()
    
    # æ‰§è¡Œæµ‹è¯•
    test_results = {}
    
    # æµ‹è¯•1ï¼šé¢„æµ‹è´¨é‡éªŒè¯å™¨
    test_results['prediction_validator'] = test_prediction_validator()
    
    # æµ‹è¯•2ï¼šå®æ—¶éªŒè¯å™¨
    test_results['real_time_validator'] = test_real_time_validator()
    
    # æµ‹è¯•3ï¼šAPIé›†æˆ
    test_results['api_integration'] = test_api_integration()
    
    # æµ‹è¯•4ï¼šå®Œæ•´éªŒè¯å·¥ä½œæµ
    test_results['validation_workflow'] = test_validation_workflow()
    
    # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
    end_time = datetime.now()
    duration = end_time - start_time
    
    test_summary = {
        'test_start_time': start_time.isoformat(),
        'test_end_time': end_time.isoformat(),
        'test_duration_seconds': duration.total_seconds(),
        'test_results': test_results,
        'overall_success': all(test_results.values()),
        'success_count': sum(test_results.values()),
        'total_tests': len(test_results)
    }
    
    # ä¿å­˜æµ‹è¯•æŠ¥å‘Š
    with open("test_results/validation_test_summary.json", "w", encoding="utf-8") as f:
        json.dump(test_summary, f, indent=2, ensure_ascii=False, default=str)
    
    # è¾“å‡ºæµ‹è¯•ç»“æœ
    logger.info("\n" + "="*60)
    logger.info("ğŸ¯ æµ‹è¯•ç»“æœæ±‡æ€»")
    logger.info("="*60)
    
    for test_name, result in test_results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        logger.info(f"{test_name}: {status}")
    
    logger.info(f"\næ€»ä½“ç»“æœ: {'âœ… å…¨éƒ¨é€šè¿‡' if test_summary['overall_success'] else 'âŒ éƒ¨åˆ†å¤±è´¥'}")
    logger.info(f"é€šè¿‡ç‡: {test_summary['success_count']}/{test_summary['total_tests']}")
    logger.info(f"æµ‹è¯•è€—æ—¶: {duration.total_seconds():.1f} ç§’")
    
    if test_summary['overall_success']:
        logger.info("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼é¢„æµ‹éªŒè¯å™¨åŠŸèƒ½æ­£å¸¸")
    else:
        logger.info("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½")
    
    return test_summary['overall_success']

if __name__ == "__main__":
    try:
        success = main()
        exit(0 if success else 1)
    except KeyboardInterrupt:
        logger.info("\nğŸ›‘ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        exit(1)
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        exit(1)
