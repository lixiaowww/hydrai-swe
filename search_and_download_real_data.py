#!/usr/bin/env python3
"""
æœç´¢å’Œä¸‹è½½çœŸå®æ•°æ®æº
æ›¿ä»£åˆæˆæ•°æ®ï¼Œè·å–é«˜è´¨é‡çœŸå®è§‚æµ‹æ•°æ®
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import requests
import pandas as pd
import numpy as np
import logging
from datetime import datetime, timedelta
import json
from typing import Dict, List, Optional
import time
import zipfile
import io

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class RealDataSearcher:
    """çœŸå®æ•°æ®æœç´¢å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
    def search_noaa_climate_data(self) -> Dict:
        """æœç´¢NOAAæ°”å€™æ•°æ®"""
        try:
            logger.info("ğŸ” æœç´¢NOAAæ°”å€™æ•°æ®...")
            
            # NOAAæ°”å€™æ•°æ®åœ¨çº¿æœç´¢
            noaa_urls = {
                'daily_summaries': 'https://www.ncei.noaa.gov/data/global-summary-of-the-day/access/',
                'hourly_data': 'https://www.ncei.noaa.gov/data/global-hourly/access/',
                'precipitation': 'https://www.ncei.noaa.gov/data/global-precipitation-climatology-centre/access/',
                'soil_moisture': 'https://www.ncei.noaa.gov/data/soil-moisture/access/'
            }
            
            results = {}
            
            for data_type, url in noaa_urls.items():
                try:
                    logger.info(f"ğŸ“¥ æ£€æŸ¥ {data_type} æ•°æ®å¯ç”¨æ€§...")
                    response = self.session.get(url, timeout=10)
                    
                    if response.status_code == 200:
                        results[data_type] = {
                            'status': 'available',
                            'url': url,
                            'size': len(response.content)
                        }
                        logger.info(f"âœ… {data_type} æ•°æ®å¯ç”¨")
                    else:
                        results[data_type] = {
                            'status': 'unavailable',
                            'url': url,
                            'error': f"HTTP {response.status_code}"
                        }
                        logger.info(f"âŒ {data_type} æ•°æ®ä¸å¯ç”¨: HTTP {response.status_code}")
                        
                except Exception as e:
                    results[data_type] = {
                        'status': 'error',
                        'url': url,
                        'error': str(e)
                    }
                    logger.warning(f"âš ï¸ {data_type} æ•°æ®æ£€æŸ¥å¤±è´¥: {e}")
                
                time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ NOAAæ•°æ®æœç´¢å¤±è´¥: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def search_nasa_earth_data(self) -> Dict:
        """æœç´¢NASAåœ°çƒæ•°æ®"""
        try:
            logger.info("ğŸ” æœç´¢NASAåœ°çƒæ•°æ®...")
            
            # NASA Earthdataæœç´¢
            nasa_urls = {
                'smap_soil_moisture': 'https://cmr.earthdata.nasa.gov/search/collections.json?keyword=SMAP&type=dataset',
                'modis_land': 'https://cmr.earthdata.nasa.gov/search/collections.json?keyword=MODIS&type=dataset',
                'grace_water': 'https://cmr.earthdata.nasa.gov/search/collections.json?keyword=GRACE&type=dataset'
            }
            
            results = {}
            
            for data_type, url in nasa_urls.items():
                try:
                    logger.info(f"ğŸ“¥ æ£€æŸ¥ {data_type} æ•°æ®å¯ç”¨æ€§...")
                    response = self.session.get(url, timeout=10)
                    
                    if response.status_code == 200:
                        data = response.json()
                        if 'feed' in data and 'entry' in data['feed']:
                            results[data_type] = {
                                'status': 'available',
                                'url': url,
                                'datasets': len(data['feed']['entry'])
                            }
                            logger.info(f"âœ… {data_type} æ•°æ®å¯ç”¨: {len(data['feed']['entry'])} ä¸ªæ•°æ®é›†")
                        else:
                            results[data_type] = {
                                'status': 'available',
                                'url': url,
                                'datasets': 'unknown'
                            }
                            logger.info(f"âœ… {data_type} æ•°æ®å¯ç”¨")
                    else:
                        results[data_type] = {
                            'status': 'unavailable',
                            'url': url,
                            'error': f"HTTP {response.status_code}"
                        }
                        logger.info(f"âŒ {data_type} æ•°æ®ä¸å¯ç”¨: HTTP {response.status_code}")
                        
                except Exception as e:
                    results[data_type] = {
                        'status': 'error',
                        'url': url,
                        'error': str(e)
                    }
                    logger.warning(f"âš ï¸ {data_type} æ•°æ®æ£€æŸ¥å¤±è´¥: {e}")
                
                time.sleep(1)
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ NASAæ•°æ®æœç´¢å¤±è´¥: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def search_european_weather_data(self) -> Dict:
        """æœç´¢æ¬§æ´²å¤©æ°”æ•°æ®"""
        try:
            logger.info("ğŸ” æœç´¢æ¬§æ´²å¤©æ°”æ•°æ®...")
            
            # ECMWFå’Œæ¬§æ´²å¤©æ°”æ•°æ®
            european_urls = {
                'era5_reanalysis': 'https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels',
                'era5_land': 'https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land',
                'eobs_daily': 'https://www.ecad.eu/download/ensembles/download.php'
            }
            
            results = {}
            
            for data_type, url in european_urls.items():
                try:
                    logger.info(f"ğŸ“¥ æ£€æŸ¥ {data_type} æ•°æ®å¯ç”¨æ€§...")
                    response = self.session.get(url, timeout=10)
                    
                    if response.status_code == 200:
                        results[data_type] = {
                            'status': 'available',
                            'url': url,
                            'size': len(response.content)
                        }
                        logger.info(f"âœ… {data_type} æ•°æ®å¯ç”¨")
                    else:
                        results[data_type] = {
                            'status': 'unavailable',
                            'url': url,
                            'error': f"HTTP {response.status_code}"
                        }
                        logger.info(f"âŒ {data_type} æ•°æ®ä¸å¯ç”¨: HTTP {response.status_code}")
                        
                except Exception as e:
                    results[data_type] = {
                        'status': 'error',
                        'url': url,
                        'error': str(e)
                    }
                    logger.warning(f"âš ï¸ {data_type} æ•°æ®æ£€æŸ¥å¤±è´¥: {e}")
                
                time.sleep(1)
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ æ¬§æ´²æ•°æ®æœç´¢å¤±è´¥: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def search_canadian_weather_data(self) -> Dict:
        """æœç´¢åŠ æ‹¿å¤§å¤©æ°”æ•°æ®"""
        try:
            logger.info("ğŸ” æœç´¢åŠ æ‹¿å¤§å¤©æ°”æ•°æ®...")
            
            # Environment Canadaå’ŒåŠ æ‹¿å¤§å¤©æ°”æ•°æ®
            canadian_urls = {
                'environment_canada': 'https://climate.weather.gc.ca/',
                'hydat_water': 'https://www.canada.ca/en/environment-climate-change/services/water-overview/quantity/monitoring/survey/data-products-services/national-archive-hydat.html',
                'agriculture_data': 'https://agriculture.canada.ca/en/agriculture-and-environment/weather-and-climate'
            }
            
            results = {}
            
            for data_type, url in canadian_urls.items():
                try:
                    logger.info(f"ğŸ“¥ æ£€æŸ¥ {data_type} æ•°æ®å¯ç”¨æ€§...")
                    response = self.session.get(url, timeout=10)
                    
                    if response.status_code == 200:
                        results[data_type] = {
                            'status': 'available',
                            'url': url,
                            'size': len(response.content)
                        }
                        logger.info(f"âœ… {data_type} æ•°æ®å¯ç”¨")
                    else:
                        results[data_type] = {
                            'status': 'unavailable',
                            'url': url,
                            'error': f"HTTP {response.status_code}"
                        }
                        logger.info(f"âŒ {data_type} æ•°æ®ä¸å¯ç”¨: HTTP {response.status_code}")
                        
                except Exception as e:
                    results[data_type] = {
                        'status': 'error',
                        'url': url,
                        'error': str(e)
                    }
                    logger.warning(f"âš ï¸ {data_type} æ•°æ®æ£€æŸ¥å¤±è´¥: {e}")
                
                time.sleep(1)
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ åŠ æ‹¿å¤§æ•°æ®æœç´¢å¤±è´¥: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def search_open_weather_datasets(self) -> Dict:
        """æœç´¢å¼€æ”¾å¤©æ°”æ•°æ®é›†"""
        try:
            logger.info("ğŸ” æœç´¢å¼€æ”¾å¤©æ°”æ•°æ®é›†...")
            
            # å¼€æ”¾å¤©æ°”æ•°æ®å¹³å°
            open_weather_urls = {
                'openweathermap': 'https://openweathermap.org/api',
                'weatherbit': 'https://www.weatherbit.io/api',
                'visualcrossing': 'https://www.visualcrossing.com/weather-api',
                'openmeteo': 'https://open-meteo.com/en/docs'
            }
            
            results = {}
            
            for data_type, url in open_weather_urls.items():
                try:
                    logger.info(f"ğŸ“¥ æ£€æŸ¥ {data_type} æ•°æ®å¯ç”¨æ€§...")
                    response = self.session.get(url, timeout=10)
                    
                    if response.status_code == 200:
                        results[data_type] = {
                            'status': 'available',
                            'url': url,
                            'size': len(response.content)
                        }
                        logger.info(f"âœ… {data_type} æ•°æ®å¯ç”¨")
                    else:
                        results[data_type] = {
                            'status': 'unavailable',
                            'url': url,
                            'error': f"HTTP {response.status_code}"
                        }
                        logger.info(f"âŒ {data_type} æ•°æ®ä¸å¯ç”¨: HTTP {response.status_code}")
                        
                except Exception as e:
                    results[data_type] = {
                        'status': 'error',
                        'url': url,
                        'error': str(e)
                    }
                    logger.warning(f"âš ï¸ {data_type} æ•°æ®æ£€æŸ¥å¤±è´¥: {e}")
                
                time.sleep(1)
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ å¼€æ”¾å¤©æ°”æ•°æ®æœç´¢å¤±è´¥: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def download_sample_data(self, data_source: str, url: str) -> Optional[str]:
        """ä¸‹è½½æ ·æœ¬æ•°æ®"""
        try:
            logger.info(f"ğŸ“¥ å°è¯•ä¸‹è½½ {data_source} æ ·æœ¬æ•°æ®...")
            
            # åˆ›å»ºä¸‹è½½ç›®å½•
            download_dir = f"data/real_samples/{data_source}"
            os.makedirs(download_dir, exist_ok=True)
            
            # å°è¯•ä¸‹è½½
            response = self.session.get(url, timeout=30)
            
            if response.status_code == 200:
                # ä¿å­˜æ•°æ®
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"{data_source}_sample_{timestamp}.txt"
                filepath = os.path.join(download_dir, filename)
                
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(response.text)
                
                logger.info(f"âœ… æ ·æœ¬æ•°æ®å·²ä¿å­˜: {filepath}")
                return filepath
            else:
                logger.warning(f"âš ï¸ ä¸‹è½½å¤±è´¥: HTTP {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½æ ·æœ¬æ•°æ®å¤±è´¥: {e}")
            return None
    
    def generate_search_report(self, all_results: Dict) -> Dict:
        """ç”Ÿæˆæœç´¢æŠ¥å‘Š"""
        try:
            report = {
                'timestamp': datetime.now().isoformat(),
                'summary': {
                    'total_sources': len(all_results),
                    'available_sources': 0,
                    'unavailable_sources': 0,
                    'error_sources': 0
                },
                'recommendations': [],
                'data_sources': all_results
            }
            
            # ç»Ÿè®¡ç»“æœ
            for source_type, results in all_results.items():
                for data_type, result in results.items():
                    if result['status'] == 'available':
                        report['summary']['available_sources'] += 1
                    elif result['status'] == 'unavailable':
                        report['summary']['unavailable_sources'] += 1
                    else:
                        report['summary']['error_sources'] += 1
            
            # ç”Ÿæˆå»ºè®®
            if report['summary']['available_sources'] > 0:
                report['recommendations'].append("å‘ç°å¤šä¸ªå¯ç”¨æ•°æ®æºï¼Œå»ºè®®ä¼˜å…ˆä½¿ç”¨")
                report['recommendations'].append("å¯ä»¥ç»„åˆå¤šä¸ªæ•°æ®æºæé«˜æ•°æ®è´¨é‡")
            else:
                report['recommendations'].append("æœªå‘ç°å¯ç”¨æ•°æ®æºï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥")
                report['recommendations'].append("è€ƒè™‘ä½¿ç”¨APIå¯†é’¥æˆ–æ³¨å†Œè´¦æˆ·")
            
            return report
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæœç´¢æŠ¥å‘Šå¤±è´¥: {e}")
            return {'status': 'error', 'error': str(e)}

def main():
    """ä¸»å‡½æ•°"""
    try:
        logger.info("ğŸš€ å¯åŠ¨çœŸå®æ•°æ®æºæœç´¢...")
        
        # åˆ›å»ºæœç´¢å™¨
        searcher = RealDataSearcher()
        
        # æœç´¢å„ç§æ•°æ®æº
        all_results = {}
        
        # 1. NOAAæ°”å€™æ•°æ®
        logger.info("ğŸ” 1/5 æœç´¢NOAAæ°”å€™æ•°æ®...")
        noaa_results = searcher.search_noaa_climate_data()
        all_results['noaa'] = noaa_results
        
        # 2. NASAåœ°çƒæ•°æ®
        logger.info("ğŸ” 2/5 æœç´¢NASAåœ°çƒæ•°æ®...")
        nasa_results = searcher.search_nasa_earth_data()
        all_results['nasa'] = nasa_results
        
        # 3. æ¬§æ´²å¤©æ°”æ•°æ®
        logger.info("ğŸ” 3/5 æœç´¢æ¬§æ´²å¤©æ°”æ•°æ®...")
        european_results = searcher.search_european_weather_data()
        all_results['european'] = european_results
        
        # 4. åŠ æ‹¿å¤§å¤©æ°”æ•°æ®
        logger.info("ğŸ” 4/5 æœç´¢åŠ æ‹¿å¤§å¤©æ°”æ•°æ®...")
        canadian_results = searcher.search_canadian_weather_data()
        all_results['canadian'] = canadian_results
        
        # 5. å¼€æ”¾å¤©æ°”æ•°æ®é›†
        logger.info("ğŸ” 5/5 æœç´¢å¼€æ”¾å¤©æ°”æ•°æ®é›†...")
        open_weather_results = searcher.search_open_weather_datasets()
        all_results['open_weather'] = open_weather_results
        
        # ç”Ÿæˆæœç´¢æŠ¥å‘Š
        logger.info("ğŸ“Š ç”Ÿæˆæœç´¢æŠ¥å‘Š...")
        report = searcher.generate_search_report(all_results)
        
        # ä¿å­˜æŠ¥å‘Š
        output_dir = "data/search_reports"
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = os.path.join(output_dir, f"real_data_search_report_{timestamp}.json")
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"âœ… æœç´¢æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        logger.info("ğŸ‰ çœŸå®æ•°æ®æºæœç´¢å®Œæˆï¼")
        logger.info(f"ğŸ“Š æœç´¢æ‘˜è¦:")
        logger.info(f"  æ€»æ•°æ®æº: {report['summary']['total_sources']}")
        logger.info(f"  å¯ç”¨æ•°æ®æº: {report['summary']['available_sources']}")
        logger.info(f"  ä¸å¯ç”¨æ•°æ®æº: {report['summary']['unavailable_sources']}")
        logger.info(f"  é”™è¯¯æ•°æ®æº: {report['summary']['error_sources']}")
        
        # æ˜¾ç¤ºå»ºè®®
        for i, rec in enumerate(report['recommendations'], 1):
            logger.info(f"ğŸ’¡ å»ºè®® {i}: {rec}")
        
        return report
        
    except Exception as e:
        logger.error(f"âŒ ä¸»å‡½æ•°æ‰§è¡Œå¤±è´¥: {e}")
        return None

if __name__ == "__main__":
    main()
