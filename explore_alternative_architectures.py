#!/usr/bin/env python3
"""
æ¢ç´¢æ›¿ä»£æ¨¡å‹æ¶æ„
å°è¯•Transformerã€GRUã€1D-CNNç­‰æ›¿ä»£LSTMçš„æ¶æ„
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import matplotlib.pyplot as plt
import os
from datetime import datetime
import time

class SWELSTMModel(nn.Module):
    """SWE LSTMé¢„æµ‹æ¨¡å‹"""
    
    def __init__(self, input_size=6, hidden_size=64, num_layers=2, dropout=0.1, sequence_length=30):
        super(SWELSTMModel, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, 
                           dropout=dropout if num_layers > 1 else 0, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        lstm_out = self.dropout(lstm_out)
        output = self.fc(lstm_out[:, -1, :])
        return output

class TransformerModel(nn.Module):
    """Transformeræ¨¡å‹ç”¨äºæ—¶é—´åºåˆ—é¢„æµ‹"""
    
    def __init__(self, input_size=6, d_model=64, nhead=8, num_layers=2, dropout=0.1, sequence_length=30):
        super(TransformerModel, self).__init__()
        self.d_model = d_model
        self.sequence_length = sequence_length
        
        # è¾“å…¥æŠ•å½±å±‚
        self.input_projection = nn.Linear(input_size, d_model)
        
        # ä½ç½®ç¼–ç 
        self.pos_encoding = nn.Parameter(torch.randn(1, sequence_length, d_model))
        
        # Transformerç¼–ç å™¨
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=d_model * 4,
            dropout=dropout,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        # è¾“å‡ºå±‚
        self.output_projection = nn.Linear(d_model, 1)
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x):
        # è¾“å…¥æŠ•å½±
        x = self.input_projection(x)
        
        # æ·»åŠ ä½ç½®ç¼–ç 
        x = x + self.pos_encoding[:, :x.size(1), :]
        
        # Transformerç¼–ç 
        x = self.transformer(x)
        
        # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
        x = x[:, -1, :]
        
        # è¾“å‡ºæŠ•å½±
        x = self.dropout(x)
        x = self.output_projection(x)
        
        return x

class GRUModel(nn.Module):
    """GRUæ¨¡å‹ç”¨äºæ—¶é—´åºåˆ—é¢„æµ‹"""
    
    def __init__(self, input_size=6, hidden_size=64, num_layers=2, dropout=0.1, sequence_length=30):
        super(GRUModel, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        self.gru = nn.GRU(input_size, hidden_size, num_layers, 
                          dropout=dropout if num_layers > 1 else 0, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x):
        gru_out, _ = self.gru(x)
        gru_out = self.dropout(gru_out)
        output = self.fc(gru_out[:, -1, :])
        return output

class CNN1DModel(nn.Module):
    """1D-CNNæ¨¡å‹ç”¨äºæ—¶é—´åºåˆ—é¢„æµ‹"""
    
    def __init__(self, input_size=6, num_filters=64, kernel_size=3, num_layers=3, dropout=0.1, sequence_length=30):
        super(CNN1DModel, self).__init__()
        self.num_filters = num_filters
        self.sequence_length = sequence_length
        
        # 1Då·ç§¯å±‚
        layers = []
        in_channels = input_size
        
        for i in range(num_layers):
            layers.extend([
                nn.Conv1d(in_channels, num_filters, kernel_size, padding=kernel_size//2),
                nn.BatchNorm1d(num_filters),
                nn.ReLU(),
                nn.Dropout(dropout)
            ])
            in_channels = num_filters
        
        self.conv_layers = nn.Sequential(*layers)
        
        # å…¨å±€å¹³å‡æ± åŒ–
        self.global_pool = nn.AdaptiveAvgPool1d(1)
        
        # è¾“å‡ºå±‚
        self.fc = nn.Linear(num_filters, 1)
        
    def forward(self, x):
        # è½¬æ¢ç»´åº¦: (batch, seq_len, features) -> (batch, features, seq_len)
        x = x.transpose(1, 2)
        
        # å·ç§¯å±‚
        x = self.conv_layers(x)
        
        # å…¨å±€å¹³å‡æ± åŒ–
        x = self.global_pool(x).squeeze(-1)
        
        # è¾“å‡ºå±‚
        x = self.fc(x)
        return x

class HybridModel(nn.Module):
    """æ··åˆæ¨¡å‹ï¼šç»“åˆCNNå’ŒLSTM"""
    
    def __init__(self, input_size=6, cnn_filters=32, lstm_hidden=64, num_layers=2, dropout=0.1, sequence_length=30):
        super(HybridModel, self).__init__()
        self.sequence_length = sequence_length
        
        # CNNç‰¹å¾æå–
        self.cnn = nn.Sequential(
            nn.Conv1d(input_size, cnn_filters, kernel_size=3, padding=1),
            nn.BatchNorm1d(cnn_filters),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Conv1d(cnn_filters, cnn_filters, kernel_size=3, padding=1),
            nn.BatchNorm1d(cnn_filters),
            nn.ReLU(),
            nn.Dropout(dropout)
        )
        
        # LSTMå¤„ç†åºåˆ—
        self.lstm = nn.LSTM(cnn_filters, lstm_hidden, num_layers, 
                           dropout=dropout if num_layers > 1 else 0, batch_first=True)
        
        # è¾“å‡ºå±‚
        self.fc = nn.Linear(lstm_hidden, 1)
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x):
        # CNNç‰¹å¾æå–
        x = x.transpose(1, 2)  # (batch, features, seq_len)
        x = self.cnn(x)
        x = x.transpose(1, 2)  # (batch, seq_len, features)
        
        # LSTMå¤„ç†
        lstm_out, _ = self.lstm(x)
        lstm_out = self.dropout(lstm_out)
        
        # è¾“å‡º
        output = self.fc(lstm_out[:, -1, :])
        return output

class ArchitectureExplorer:
    """æ¨¡å‹æ¶æ„æ¢ç´¢å™¨"""
    
    def __init__(self):
        self.models = {}
        self.training_results = {}
        self.validation_results = {}
        self.scaler_X = None
        self.scaler_y = None
        self.sequence_length = 30
        
    def load_data_and_scalers(self):
        """åŠ è½½æ•°æ®å’Œæ ‡å‡†åŒ–å™¨"""
        print("ğŸ“Š åŠ è½½æ•°æ®å’Œæ ‡å‡†åŒ–å™¨...")
        
        try:
            # åŠ è½½æ ‡å‡†åŒ–æ•°æ®
            data_path = "data/processed/standardized_training_dataset.csv"
            data = pd.read_csv(data_path, index_col=0, parse_dates=True)
            print(f"âœ… åŠ è½½æ•°æ®: {len(data)} æ¡è®°å½•")
            
            # åŠ è½½æ ‡å‡†åŒ–å™¨å‚æ•°
            import pickle
            with open('models/standardization_params.pkl', 'rb') as f:
                params = pickle.load(f)
            
            # é‡å»ºæ ‡å‡†åŒ–å™¨
            self.scaler_X = StandardScaler()
            self.scaler_X.mean_ = params['scaler_X_mean']
            self.scaler_X.scale_ = params['scaler_X_scale']
            
            self.scaler_y = StandardScaler()
            self.scaler_y.mean_ = params['scaler_y_mean']
            self.scaler_y.scale_ = params['scaler_y_scale']
            
            print("âœ… æ ‡å‡†åŒ–å™¨åŠ è½½æˆåŠŸ")
            return data
            
        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥: {e}")
            return None
    
    def prepare_sequences(self, data):
        """å‡†å¤‡åºåˆ—æ•°æ®"""
        print("ğŸ”„ å‡†å¤‡åºåˆ—æ•°æ®...")
        
        feature_cols = ['snow_depth_mm', 'snow_fall_mm', 'snow_water_equivalent_mm', 
                       'day_of_year', 'month', 'year']
        target_col = 'snow_water_equivalent_mm'
        
        X = data[feature_cols].values
        y = data[target_col].values
        
        # æ ‡å‡†åŒ–
        X_scaled = self.scaler_X.transform(X)
        y_scaled = self.scaler_y.transform(y.reshape(-1, 1)).flatten()
        
        # åˆ›å»ºåºåˆ—
        X_seq, y_seq = [], []
        for i in range(len(X_scaled) - self.sequence_length):
            X_seq.append(X_scaled[i:(i + self.sequence_length)])
            y_seq.append(y_scaled[i + self.sequence_length])
        
        X_seq = np.array(X_seq)
        y_seq = np.array(y_seq)
        
        print(f"âœ… åºåˆ—æ•°æ®å‡†å¤‡å®Œæˆ: {X_seq.shape}, {y_seq.shape}")
        return X_seq, y_seq
    
    def split_data(self, X, y, train_ratio=0.7, val_ratio=0.15):
        """åˆ†å‰²æ•°æ®"""
        n = len(X)
        train_end = int(n * train_ratio)
        val_end = int(n * (train_ratio + val_ratio))
        
        X_train = X[:train_end]
        y_train = y[:train_end]
        X_val = X[train_end:val_end]
        y_val = y[train_end:val_end]
        X_test = X[val_end:]
        y_test = y[val_end:]
        
        print(f"ğŸ“Š æ•°æ®åˆ†å‰²:")
        print(f"   è®­ç»ƒé›†: {len(X_train)} ä¸ªåºåˆ—")
        print(f"   éªŒè¯é›†: {len(X_val)} ä¸ªåºåˆ—")
        print(f"   æµ‹è¯•é›†: {len(X_test)} ä¸ªåºåˆ—")
        
        return (X_train, y_train), (X_val, y_val), (X_test, y_test)
    
    def create_data_loaders(self, train_data, val_data, test_data, batch_size=32):
        """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
        X_train, y_train = train_data
        X_val, y_val = val_data
        X_test, y_test = test_data
        
        train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))
        val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))
        test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))
        
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
        
        return train_loader, val_loader, test_loader
    
    def define_models(self):
        """å®šä¹‰è¦æ¢ç´¢çš„æ¨¡å‹"""
        print("ğŸ—ï¸ å®šä¹‰æ¨¡å‹æ¶æ„...")
        
        models = {
            'LSTM_Original': SWELSTMModel(input_size=6, hidden_size=64, num_layers=2, dropout=0.1),
            'Transformer': TransformerModel(input_size=6, d_model=64, nhead=8, num_layers=2, dropout=0.1),
            'GRU': GRUModel(input_size=6, hidden_size=64, num_layers=2, dropout=0.1),
            'CNN1D': CNN1DModel(input_size=6, num_filters=64, kernel_size=3, num_layers=3, dropout=0.1),
            'Hybrid_CNN_LSTM': HybridModel(input_size=6, cnn_filters=32, lstm_hidden=64, num_layers=2, dropout=0.1)
        }
        
        # æ‰“å°æ¨¡å‹å‚æ•°æ•°é‡
        for name, model in models.items():
            total_params = sum(p.numel() for p in model.parameters())
            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
            print(f"  {name}: {total_params:,} å‚æ•° ({trainable_params:,} å¯è®­ç»ƒ)")
        
        self.models = models
        return models
    
    def train_model(self, model, train_loader, val_loader, model_name, epochs=50, learning_rate=0.001):
        """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
        print(f"ğŸš€ è®­ç»ƒæ¨¡å‹: {model_name}")
        
        # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        criterion = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)
        
        # è®­ç»ƒå†å²
        train_losses = []
        val_losses = []
        best_val_loss = float('inf')
        patience_counter = 0
        patience = 10
        
        start_time = time.time()
        
        for epoch in range(epochs):
            # è®­ç»ƒé˜¶æ®µ
            model.train()
            train_loss = 0.0
            for batch_X, batch_y in train_loader:
                optimizer.zero_grad()
                outputs = model(batch_X)
                loss = criterion(outputs.squeeze(), batch_y)
                loss.backward()
                optimizer.step()
                train_loss += loss.item()
            
            train_loss /= len(train_loader)
            train_losses.append(train_loss)
            
            # éªŒè¯é˜¶æ®µ
            model.eval()
            val_loss = 0.0
            with torch.no_grad():
                for batch_X, batch_y in val_loader:
                    outputs = model(batch_X)
                    loss = criterion(outputs.squeeze(), batch_y)
                    val_loss += loss.item()
            
            val_loss /= len(val_loader)
            val_losses.append(val_loss)
            
            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step(val_loss)
            
            # æ—©åœæ£€æŸ¥
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                patience_counter = 0
            else:
                patience_counter += 1
            
            if epoch % 10 == 0:
                print(f"  Epoch {epoch:3d}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}")
            
            if patience_counter >= patience:
                print(f"  Early stopping at epoch {epoch}")
                break
        
        training_time = time.time() - start_time
        
        # ä¿å­˜è®­ç»ƒç»“æœ
        self.training_results[model_name] = {
            'train_losses': train_losses,
            'val_losses': val_losses,
            'best_val_loss': best_val_loss,
            'epochs_trained': len(train_losses),
            'training_time': training_time
        }
        
        print(f"âœ… {model_name} è®­ç»ƒå®Œæˆ! æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}")
        print(f"   è®­ç»ƒæ—¶é—´: {training_time:.2f} ç§’")
        
        return model
    
    def evaluate_model(self, model, test_loader, model_name):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        print(f"ğŸ“Š è¯„ä¼°æ¨¡å‹: {model_name}")
        
        model.eval()
        predictions = []
        actuals = []
        
        with torch.no_grad():
            for batch_X, batch_y in test_loader:
                outputs = model(batch_X)
                predictions.extend(outputs.squeeze().cpu().numpy())
                actuals.extend(batch_y.cpu().numpy())
        
        predictions = np.array(predictions)
        actuals = np.array(actuals)
        
        # åæ ‡å‡†åŒ–
        predictions_rescaled = self.scaler_y.inverse_transform(predictions.reshape(-1, 1)).flatten()
        actuals_rescaled = self.scaler_y.inverse_transform(actuals.reshape(-1, 1)).flatten()
        
        # è®¡ç®—æŒ‡æ ‡
        mse = mean_squared_error(actuals_rescaled, predictions_rescaled)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(actuals_rescaled, predictions_rescaled)
        r2 = r2_score(actuals_rescaled, predictions_rescaled)
        
        # ä¿å­˜éªŒè¯ç»“æœ
        self.validation_results[model_name] = {
            'rmse': rmse,
            'mae': mae,
            'r2': r2,
            'mse': mse
        }
        
        print(f"ğŸ“ˆ {model_name} æµ‹è¯•é›†æ€§èƒ½:")
        print(f"   RMSE: {rmse:.4f}")
        print(f"   MAE:  {mae:.4f}")
        print(f"   RÂ²:   {r2:.4f}")
        
        return {
            'rmse': rmse,
            'mae': mae,
            'r2': r2,
            'mse': mse
        }
    
    def run_architecture_exploration(self):
        """è¿è¡Œæ¶æ„æ¢ç´¢"""
        print("ğŸ”¬ å¼€å§‹æ¨¡å‹æ¶æ„æ¢ç´¢...")
        
        # åŠ è½½æ•°æ®
        data = self.load_data_and_scalers()
        if data is None:
            return
        
        # å‡†å¤‡åºåˆ—æ•°æ®
        X, y = self.prepare_sequences(data)
        
        # åˆ†å‰²æ•°æ®
        train_data, val_data, test_data = self.split_data(X, y)
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader, val_loader, test_loader = self.create_data_loaders(
            train_data, val_data, test_data, batch_size=32
        )
        
        # å®šä¹‰æ¨¡å‹
        models = self.define_models()
        
        # è®­ç»ƒå’Œè¯„ä¼°æ‰€æœ‰æ¨¡å‹
        all_results = {}
        
        for model_name, model in models.items():
            print(f"\n{'='*60}")
            print(f"ğŸ¯ æ¨¡å‹: {model_name}")
            print(f"{'='*60}")
            
            try:
                # è®­ç»ƒæ¨¡å‹
                trained_model = self.train_model(model, train_loader, val_loader, model_name)
                
                # è¯„ä¼°æ¨¡å‹
                metrics = self.evaluate_model(trained_model, test_loader, model_name)
                all_results[model_name] = metrics
                
                # ä¿å­˜æ¨¡å‹
                model_path = f"models/{model_name.lower().replace(' ', '_')}.pth"
                torch.save({
                    'model_state_dict': trained_model.state_dict(),
                    'model_type': model_name,
                    'scaler_X': self.scaler_X,
                    'scaler_y': self.scaler_y,
                    'sequence_length': self.sequence_length,
                    'input_size': 6,
                    'validation_metrics': metrics
                }, model_path)
                
                print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {model_path}")
                
            except Exception as e:
                print(f"âŒ {model_name} è®­ç»ƒ/è¯„ä¼°å¤±è´¥: {e}")
                all_results[model_name] = {'error': str(e)}
        
        # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        self.generate_architecture_comparison_report(all_results)
        
        return all_results
    
    def generate_architecture_comparison_report(self, results):
        """ç”Ÿæˆæ¶æ„å¯¹æ¯”æŠ¥å‘Š"""
        print("ğŸ“ ç”Ÿæˆæ¶æ„å¯¹æ¯”æŠ¥å‘Š...")
        
        # è¿‡æ»¤æ‰æœ‰é”™è¯¯çš„æ¨¡å‹
        valid_results = {k: v for k, v in results.items() if 'error' not in v}
        
        if not valid_results:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æ¨¡å‹ç»“æœ")
            return
        
        # æŒ‰RMSEæ’åº
        sorted_results = sorted(valid_results.items(), key=lambda x: x[1]['rmse'])
        
        # æ‰“å°å¯¹æ¯”ç»“æœ
        print(f"\n{'='*80}")
        print("ğŸ“Š æ¨¡å‹æ¶æ„å¯¹æ¯”ç»“æœ")
        print(f"{'='*80}")
        
        print(f"{'æ¨¡å‹':<25} {'RMSE':<12} {'MAE':<12} {'RÂ²':<12} {'è®­ç»ƒæ—¶é—´':<12}")
        print(f"{'-'*80}")
        
        for model_name, metrics in sorted_results:
            training_time = self.training_results.get(model_name, {}).get('training_time', 0)
            print(f"{model_name:<25} {metrics['rmse']:<12.4f} {metrics['mae']:<12.4f} "
                  f"{metrics['r2']:<12.4f} {training_time:<12.2f}s")
        
        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_model = sorted_results[0]
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model[0]} (RMSE: {best_model[1]['rmse']:.4f})")
        
        # ä¿å­˜æŠ¥å‘Š
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_path = f"logs/architecture_exploration_report_{timestamp}.md"
        
        report_content = f"""# æ¨¡å‹æ¶æ„æ¢ç´¢æŠ¥å‘Š

## æŠ¥å‘Šæ—¶é—´
{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## æ¢ç´¢çš„æ¶æ„

| æ¨¡å‹ | æè¿° | ç‰¹ç‚¹ |
|------|------|------|
| LSTM_Original | åŸå§‹LSTMæ¨¡å‹ | 2å±‚LSTMï¼Œ64éšè—å•å…ƒ |
| Transformer | Transformerç¼–ç å™¨ | å¤šå¤´æ³¨æ„åŠ›ï¼Œä½ç½®ç¼–ç  |
| GRU | é—¨æ§å¾ªç¯å•å…ƒ | ç®€åŒ–LSTMï¼Œæ›´å°‘å‚æ•° |
| CNN1D | ä¸€ç»´å·ç§¯ç½‘ç»œ | å±€éƒ¨ç‰¹å¾æå– |
| Hybrid_CNN_LSTM | æ··åˆæ¨¡å‹ | CNN+LSTMç»„åˆ |

## æ€§èƒ½å¯¹æ¯”ç»“æœ

| æ¨¡å‹ | RMSE | MAE | RÂ² | è®­ç»ƒæ—¶é—´(s) |
|------|------|-----|----|-------------|
"""
        
        for model_name, metrics in sorted_results:
            training_time = self.training_results.get(model_name, {}).get('training_time', 0)
            report_content += f"| {model_name} | {metrics['rmse']:.4f} | {metrics['mae']:.4f} | {metrics['r2']:.4f} | {training_time:.2f} |\n"
        
        report_content += f"""

## æœ€ä½³æ¨¡å‹
ğŸ† **{best_model[0]}** - RMSE: {best_model[1]['rmse']:.4f}

## å…³é”®å‘ç°
1. **æ€§èƒ½å¯¹æ¯”**: ä¸åŒæ¶æ„åœ¨SWEé¢„æµ‹ä»»åŠ¡ä¸Šçš„è¡¨ç°å·®å¼‚
2. **è®­ç»ƒæ•ˆç‡**: å„æ¨¡å‹çš„è®­ç»ƒæ—¶é—´å’Œæ”¶æ•›é€Ÿåº¦
3. **æ³›åŒ–èƒ½åŠ›**: åœ¨æµ‹è¯•é›†ä¸Šçš„è¡¨ç°vséªŒè¯é›†
4. **æ¶æ„ä¼˜åŠ¿**: æ¯ç§æ¶æ„çš„ä¼˜ç¼ºç‚¹åˆ†æ

## å»ºè®®
åŸºäºæ¢ç´¢ç»“æœï¼Œå»ºè®®ï¼š
- é‡‡ç”¨ {best_model[0]} ä½œä¸ºä¸»è¦æ¨¡å‹
- è€ƒè™‘æ¨¡å‹é›†æˆä»¥æé«˜ç¨³å®šæ€§
- è¿›ä¸€æ­¥ä¼˜åŒ–è¶…å‚æ•°
- æ¢ç´¢æ›´å¤šåˆ›æ–°æ¶æ„
"""
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"âœ… æ¶æ„å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ HydrAI-SWE æ¨¡å‹æ¶æ„æ¢ç´¢")
    print("=" * 60)
    
    try:
        # åˆ›å»ºæ¢ç´¢å™¨
        explorer = ArchitectureExplorer()
        
        # è¿è¡Œæ¶æ„æ¢ç´¢
        results = explorer.run_architecture_exploration()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ¨¡å‹æ¶æ„æ¢ç´¢å®Œæˆ!")
        print(f"âœ… å…±æ¢ç´¢ {len(results)} ç§æ¶æ„")
        print("âœ… æ‰€æœ‰æ¨¡å‹å·²è®­ç»ƒå’Œè¯„ä¼°")
        print("âœ… å¯¹æ¯”æŠ¥å‘Šå·²ç”Ÿæˆ")
        
    except Exception as e:
        print(f"âŒ æ¶æ„æ¢ç´¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
