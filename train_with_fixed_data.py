#!/usr/bin/env python3
"""
ä½¿ç”¨ä¿®å¤åçš„æ•°æ®é‡æ–°è®­ç»ƒæ¨¡å‹
éªŒè¯æ•°æ®è´¨é‡ä¿®å¤æ˜¯å¦è§£å†³äº†RÂ²ä¸ºè´Ÿå€¼çš„é—®é¢˜
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
import logging
from datetime import datetime
import json

# å¯¼å…¥ERA5åœŸå£¤æ¹¿åº¦é¢„æµ‹å™¨
from src.models.agriculture.era5_soil_moisture_predictor import ERA5SoilMoisturePredictor

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def train_with_fixed_data():
    """ä½¿ç”¨ä¿®å¤åçš„æ•°æ®é‡æ–°è®­ç»ƒæ¨¡å‹"""
    try:
        logger.info("ğŸš€ å¼€å§‹ä½¿ç”¨ä¿®å¤åçš„æ•°æ®é‡æ–°è®­ç»ƒæ¨¡å‹...")
        
        # æ­¥éª¤1: åŠ è½½ä¿®å¤åçš„æ•°æ®
        logger.info("ğŸ“Š æ­¥éª¤1: åŠ è½½ä¿®å¤åçš„æ•°æ®...")
        fixed_data_dir = "data/processed/era5_fixed"
        
        if not os.path.exists(fixed_data_dir):
            logger.error(f"âŒ ä¿®å¤åçš„æ•°æ®ç›®å½•ä¸å­˜åœ¨: {fixed_data_dir}")
            return {'status': 'error', 'error': 'ä¿®å¤åçš„æ•°æ®ä¸å­˜åœ¨'}
        
        # åŠ è½½ä¿®å¤åçš„æ•°æ®
        X_train_fixed = np.load(os.path.join(fixed_data_dir, 'X_train_fixed.npy'))
        y_train_fixed = np.load(os.path.join(fixed_data_dir, 'y_train_fixed.npy'))
        
        logger.info(f"âœ… æˆåŠŸåŠ è½½ä¿®å¤åçš„æ•°æ®: X={X_train_fixed.shape}, y={y_train_fixed.shape}")
        
        # æ­¥éª¤2: é‡æ–°æ„å»ºæ•°æ®
        logger.info("ğŸ”§ æ­¥éª¤2: é‡æ–°æ„å»ºæ•°æ®...")
        
        # å°†å±•å¹³çš„æ•°æ®é‡æ–°ç»„ç»‡ä¸ºåºåˆ—æ ¼å¼
        sequence_length = 7  # åŸå§‹åºåˆ—é•¿åº¦
        n_samples = len(y_train_fixed) // sequence_length
        
        # é‡æ–°ç»„ç»‡ä¸ºåºåˆ—æ ¼å¼
        X_train_reshaped = X_train_fixed[:n_samples * sequence_length].reshape(n_samples, sequence_length, -1)
        y_train_reshaped = y_train_fixed[:n_samples * sequence_length:sequence_length]  # æ¯ä¸ªåºåˆ—å–ä¸€ä¸ªyå€¼
        
        logger.info(f"âœ… æ•°æ®é‡æ–°ç»„ç»‡å®Œæˆ: X={X_train_reshaped.shape}, y={y_train_reshaped.shape}")
        
        # æ­¥éª¤3: åˆ›å»ºæ–°çš„æ•°æ®åŠ è½½å™¨
        logger.info("ğŸ”§ æ­¥éª¤3: åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
        
        # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
        train_size = int(0.8 * len(X_train_reshaped))
        X_train = X_train_reshaped[:train_size]
        y_train = y_train_reshaped[:train_size]
        X_val = X_train_reshaped[train_size:]
        y_val = y_train_reshaped[train_size:]
        
        logger.info(f"ğŸ“Š æ•°æ®åˆ†å‰²å®Œæˆ: è®­ç»ƒé›† {X_train.shape}, éªŒè¯é›† {X_val.shape}")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_dataset = TensorDataset(
            torch.FloatTensor(X_train), 
            torch.FloatTensor(y_train)
        )
        val_dataset = TensorDataset(
            torch.FloatTensor(X_val), 
            torch.FloatTensor(y_val)
        )
        
        train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=len(X_val))
        
        data_loaders = {
            'train': train_loader,
            'val': val_loader,
            'test': val_loader  # æš‚æ—¶ç”¨éªŒè¯é›†ä½œä¸ºæµ‹è¯•é›†
        }
        
        logger.info("âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ")
        
        # æ­¥éª¤4: åˆ›å»ºå¹¶è®­ç»ƒæ–°æ¨¡å‹
        logger.info("ğŸ”§ æ­¥éª¤4: åˆ›å»ºå¹¶è®­ç»ƒæ–°æ¨¡å‹...")
        
        # åˆ›å»ºæ–°çš„é¢„æµ‹å™¨
        predictor = ERA5SoilMoisturePredictor()
        
        # æ„å»ºæ¨¡å‹ï¼ˆä½¿ç”¨ä¿®å¤åçš„ç‰¹å¾æ•°é‡ï¼‰
        input_size = X_train.shape[-1]
        predictor.build_model(input_size)
        
        logger.info(f"âœ… æ–°æ¨¡å‹æ„å»ºå®Œæˆï¼Œè¾“å…¥ç‰¹å¾æ•°: {input_size}")
        
        # è®­ç»ƒæ¨¡å‹
        training_result = predictor.train_model(data_loaders)
        
        if training_result['status'] != 'success':
            logger.error(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥: {training_result}")
            return {'status': 'error', 'error': 'æ¨¡å‹è®­ç»ƒå¤±è´¥'}
        
        logger.info("âœ… æ–°æ¨¡å‹è®­ç»ƒå®Œæˆ")
        
        # æ­¥éª¤5: è¯„ä¼°æ–°æ¨¡å‹æ€§èƒ½
        logger.info("ğŸ“Š æ­¥éª¤5: è¯„ä¼°æ–°æ¨¡å‹æ€§èƒ½...")
        
        # ä½¿ç”¨éªŒè¯é›†è¯„ä¼°
        predictor.model.eval()
        val_predictions = []
        val_targets = []
        
        with torch.no_grad():
            for batch_X, batch_y in data_loaders['val']:
                outputs = predictor.model(batch_X)
                val_predictions.extend(outputs.squeeze().cpu().numpy())
                val_targets.extend(batch_y.cpu().numpy())
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        val_predictions = np.array(val_predictions)
        val_targets = np.array(val_targets)
        
        # RÂ²
        ss_res = np.sum((val_targets - val_predictions) ** 2)
        ss_tot = np.sum((val_targets - np.mean(val_targets)) ** 2)
        r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0
        
        # MAE
        mae = np.mean(np.abs(val_targets - val_predictions))
        
        # RMSE
        rmse = np.sqrt(np.mean((val_targets - val_predictions) ** 2))
        
        performance = {
            'r2_score': r2,
            'mae': mae,
            'rmse': rmse,
            'status': 'overfitting' if r2 < 0 else 'normal',
            'val_samples': len(val_targets)
        }
        
        logger.info(f"ğŸ“Š æ–°æ¨¡å‹æ€§èƒ½è¯„ä¼°å®Œæˆ:")
        logger.info(f"  RÂ²: {r2:.4f}")
        logger.info(f"  MAE: {mae:.4f}")
        logger.info(f"  RMSE: {rmse:.4f}")
        logger.info(f"  çŠ¶æ€: {'è¿‡æ‹Ÿåˆ' if r2 < 0 else 'æ­£å¸¸'}")
        
        # ä¿å­˜æ–°æ¨¡å‹
        predictor.save_model('model_with_fixed_data.pth')
        logger.info("âœ… æ–°æ¨¡å‹å·²ä¿å­˜")
        
        # ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š
        report = {
            'status': 'success',
            'timestamp': datetime.now().isoformat(),
            'data_quality_improvement': {
                'original_features': 35,
                'fixed_features': input_size,
                'feature_reduction': f"{((35 - input_size) / 35 * 100):.1f}%"
            },
            'model_performance': performance,
            'training_summary': training_result,
            'data_shape': {
                'X_train': X_train.shape,
                'y_train': y_train.shape,
                'X_val': X_val.shape,
                'y_val': y_val.shape
            }
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = f"training_with_fixed_data_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"âœ… è®­ç»ƒæŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        return report
        
    except Exception as e:
        logger.error(f"âŒ ä½¿ç”¨ä¿®å¤åçš„æ•°æ®è®­ç»ƒæ¨¡å‹å¤±è´¥: {e}")
        return {'status': 'error', 'error': str(e)}

def main():
    """ä¸»å‡½æ•°"""
    try:
        logger.info("ğŸš€ å¯åŠ¨ä½¿ç”¨ä¿®å¤åçš„æ•°æ®é‡æ–°è®­ç»ƒæ¨¡å‹...")
        
        # è®­ç»ƒæ¨¡å‹
        result = train_with_fixed_data()
        
        if result['status'] == 'success':
            logger.info("ğŸ‰ ä½¿ç”¨ä¿®å¤åçš„æ•°æ®è®­ç»ƒæ¨¡å‹æˆåŠŸï¼")
            
            # æ˜¾ç¤ºæ€§èƒ½ç»“æœ
            performance = result['model_performance']
            logger.info(f"ğŸ¯ æœ€ç»ˆæ€§èƒ½: RÂ² = {performance['r2_score']:.4f}")
            
            if performance['r2_score'] > 0:
                logger.info("âœ… æˆåŠŸï¼RÂ²å·²è½¬ä¸ºæ­£å€¼ï¼Œæ•°æ®è´¨é‡ä¿®å¤æœ‰æ•ˆï¼")
            else:
                logger.info("âš ï¸ RÂ²ä»ä¸ºè´Ÿå€¼ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
            
            # æ˜¾ç¤ºæ•°æ®è´¨é‡æ”¹è¿›
            data_improvement = result['data_quality_improvement']
            logger.info(f"ğŸ“Š æ•°æ®è´¨é‡æ”¹è¿›:")
            logger.info(f"  ç‰¹å¾æ•°é‡: {data_improvement['original_features']} -> {data_improvement['fixed_features']}")
            logger.info(f"  ç‰¹å¾å‡å°‘: {data_improvement['feature_reduction']}")
            
        else:
            logger.error(f"âŒ è®­ç»ƒå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ ä¸»å‡½æ•°æ‰§è¡Œå¤±è´¥: {e}")
        return {'status': 'error', 'error': str(e)}

if __name__ == "__main__":
    main()
