#!/usr/bin/env python3
"""
ä½¿ç”¨æ›¼å°¼æ‰˜å·´çœæœ¬åœŸæ•°æ®è®­ç»ƒåœŸå£¤æ¹¿åº¦é¢„æµ‹æ¨¡å‹
æ›¿ä»£æŒªå¨æ•°æ®ï¼Œä½¿ç”¨æ›¼çœå®é™…æ°”å€™ç‰¹å¾
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
import logging
from datetime import datetime
import json
from typing import Dict, List, Tuple
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ManitobaSoilMoisturePredictor:
    """ä½¿ç”¨æ›¼çœæ•°æ®çš„åœŸå£¤æ¹¿åº¦é¢„æµ‹å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        self.scaler = StandardScaler()
        self.model = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        logger.info(f"âœ… æ›¼çœåœŸå£¤æ¹¿åº¦é¢„æµ‹å™¨åˆå§‹åŒ–å®Œæˆï¼Œè®¾å¤‡: {self.device}")
    
    def load_and_prepare_data(self) -> Dict:
        """åŠ è½½å’Œå‡†å¤‡æ›¼çœæ•°æ®"""
        try:
            logger.info("ğŸ“¥ åŠ è½½æ›¼çœå†œä¸šæ•°æ®...")
            
            # åŠ è½½æ›¼çœå†œä¸šæ•°æ®
            manitoba_file = "data/real/manitoba/agriculture/manitoba_agriculture_20250821_193550.csv"
            if os.path.exists(manitoba_file):
                manitoba_data = pd.read_csv(manitoba_file)
                logger.info(f"ğŸ“Š æ›¼çœå†œä¸šæ•°æ®: {manitoba_data.shape}")
            else:
                raise ValueError("æ›¼çœå†œä¸šæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
            
            # ç‰¹å¾å·¥ç¨‹
            features, target = self._engineer_manitoba_features(manitoba_data)
            
            # æ•°æ®åˆ†å‰²
            X_train, X_temp, y_train, y_temp = train_test_split(
                features, target, test_size=0.3, random_state=42
            )
            X_val, X_test, y_val, y_test = train_test_split(
                X_temp, y_temp, test_size=0.5, random_state=42
            )
            
            # æ ‡å‡†åŒ–
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_val_scaled = self.scaler.transform(X_val)
            X_test_scaled = self.scaler.transform(X_test)
            
            # è½¬æ¢ä¸ºå¼ é‡
            train_dataset = TensorDataset(
                torch.FloatTensor(X_train_scaled), 
                torch.FloatTensor(y_train.values)
            )
            val_dataset = TensorDataset(
                torch.FloatTensor(X_val_scaled), 
                torch.FloatTensor(y_val.values)
            )
            test_dataset = TensorDataset(
                torch.FloatTensor(X_test_scaled), 
                torch.FloatTensor(y_test.values)
            )
            
            # åˆ›å»ºæ•°æ®åŠ è½½å™¨
            train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
            val_loader = DataLoader(val_dataset, batch_size=len(val_dataset))
            test_loader = DataLoader(test_dataset, batch_size=len(test_dataset))
            
            data_loaders = {
                'train': train_loader,
                'val': val_loader,
                'test': test_loader
            }
            
            logger.info(f"âœ… æ›¼çœæ•°æ®å‡†å¤‡å®Œæˆ:")
            logger.info(f"  è®­ç»ƒé›†: {X_train.shape}")
            logger.info(f"  éªŒè¯é›†: {X_val.shape}")
            logger.info(f"  æµ‹è¯•é›†: {X_test.shape}")
            logger.info(f"  ç‰¹å¾æ•°: {X_train.shape[1]}")
            
            return {
                'status': 'success',
                'data_loaders': data_loaders,
                'data_shapes': {
                    'train': X_train.shape,
                    'val': X_val.shape,
                    'test': X_test.shape
                },
                'feature_names': features.columns.tolist(),
                'region': 'Manitoba, Canada'
            }
            
        except Exception as e:
            logger.error(f"âŒ æ›¼çœæ•°æ®å‡†å¤‡å¤±è´¥: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def _engineer_manitoba_features(self, data: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:
        """æ›¼çœæ•°æ®ç‰¹å¾å·¥ç¨‹"""
        try:
            # åŸºç¡€æ—¶é—´ç‰¹å¾
            features = data[['year', 'month', 'day', 'day_of_year']].copy()
            
            # æ•°å€¼ç‰¹å¾
            features['temperature'] = data['temperature']
            features['temp_squared'] = data['temperature'] ** 2
            features['temp_cubed'] = data['temperature'] ** 3
            
            features['precipitation'] = data['precipitation']
            features['precip_log'] = np.log1p(data['precipitation'])
            features['precip_squared'] = data['precipitation'] ** 2
            
            # ä½œç‰©ç”Ÿé•¿çŠ¶æ€
            features['crop_growth_status'] = data['crop_growth_status']
            
            # å­£èŠ‚æ€§ç‰¹å¾
            features['is_winter'] = (data['month'].isin([12, 1, 2])).astype(int)
            features['is_spring'] = (data['month'].isin([3, 4, 5])).astype(int)
            features['is_summer'] = (data['month'].isin([6, 7, 8])).astype(int)
            features['is_fall'] = (data['month'].isin([9, 10, 11])).astype(int)
            
            # å‘¨æœŸæ€§ç‰¹å¾
            features['month_sin'] = np.sin(2 * np.pi * data['month'] / 12)
            features['month_cos'] = np.cos(2 * np.pi * data['month'] / 12)
            features['day_sin'] = np.sin(2 * np.pi * data['day_of_year'] / 365)
            features['day_cos'] = np.cos(2 * np.pi * data['day_of_year'] / 365)
            
            # æ›¼çœç‰¹æœ‰ç‰¹å¾
            features['growing_season'] = (data['month'].isin([5, 6, 7, 8, 9])).astype(int)
            features['freezing_season'] = (data['month'].isin([11, 12, 1, 2, 3])).astype(int)
            
            # æ¸©åº¦-é™æ°´äº¤äº’ç‰¹å¾
            features['temp_precip_interaction'] = data['temperature'] * data['precipitation']
            features['temp_crop_interaction'] = data['temperature'] * data['crop_growth_status']
            
            # ç›®æ ‡å˜é‡
            target = data['estimated_soil_moisture']
            
            # ç§»é™¤åŒ…å«NaNçš„è¡Œ
            valid_indices = ~(features.isnull().any(axis=1) | target.isnull())
            features = features[valid_indices]
            target = target[valid_indices]
            
            logger.info(f"âœ… æ›¼çœç‰¹å¾å·¥ç¨‹å®Œæˆ: {features.shape[1]} ä¸ªç‰¹å¾")
            logger.info(f"ğŸ“Š ç‰¹å¾åˆ—è¡¨: {list(features.columns)}")
            
            return features, target
            
        except Exception as e:
            logger.error(f"âŒ æ›¼çœç‰¹å¾å·¥ç¨‹å¤±è´¥: {e}")
            return pd.DataFrame(), pd.Series()
    
    def build_model(self, input_size: int) -> nn.Module:
        """æ„å»ºæ¨¡å‹"""
        try:
            model = nn.Sequential(
                nn.Linear(input_size, 64),
                nn.ReLU(),
                nn.BatchNorm1d(64),
                nn.Dropout(0.2),
                
                nn.Linear(64, 32),
                nn.ReLU(),
                nn.BatchNorm1d(32),
                nn.Dropout(0.2),
                
                nn.Linear(32, 16),
                nn.ReLU(),
                nn.BatchNorm1d(16),
                nn.Dropout(0.1),
                
                nn.Linear(16, 8),
                nn.ReLU(),
                nn.Linear(8, 1)
            )
            
            self.model = model.to(self.device)
            logger.info(f"âœ… æ›¼çœæ¨¡å‹æ„å»ºå®Œæˆ: è¾“å…¥ç‰¹å¾æ•° {input_size}")
            return model
            
        except Exception as e:
            logger.error(f"âŒ æ›¼çœæ¨¡å‹æ„å»ºå¤±è´¥: {e}")
            return None
    
    def train_model(self, data_loaders: Dict, epochs: int = 100) -> Dict:
        """è®­ç»ƒæ¨¡å‹"""
        try:
            if self.model is None:
                raise ValueError("æ¨¡å‹æœªæ„å»ºï¼Œè¯·å…ˆè°ƒç”¨build_model()")
            
            logger.info("ğŸš€ å¼€å§‹è®­ç»ƒæ›¼çœåœŸå£¤æ¹¿åº¦é¢„æµ‹æ¨¡å‹...")
            
            # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
            criterion = nn.MSELoss()
            optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001, weight_decay=1e-5)
            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)
            
            # è®­ç»ƒå†å²
            train_losses = []
            val_losses = []
            best_val_loss = float('inf')
            patience_counter = 0
            
            for epoch in range(epochs):
                # è®­ç»ƒé˜¶æ®µ
                self.model.train()
                train_loss = 0
                for batch_X, batch_y in data_loaders['train']:
                    batch_X = batch_X.to(self.device)
                    batch_y = batch_y.to(self.device)
                    
                    optimizer.zero_grad()
                    outputs = self.model(batch_X).squeeze()
                    loss = criterion(outputs, batch_y)
                    loss.backward()
                    
                    # æ¢¯åº¦è£å‰ª
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                    
                    optimizer.step()
                    train_loss += loss.item()
                
                train_loss /= len(data_loaders['train'])
                train_losses.append(train_loss)
                
                # éªŒè¯é˜¶æ®µ
                self.model.eval()
                val_loss = 0
                with torch.no_grad():
                    for batch_X, batch_y in data_loaders['val']:
                        batch_X = batch_X.to(self.device)
                        batch_y = batch_y.to(self.device)
                        
                        outputs = self.model(batch_X).squeeze()
                        loss = criterion(outputs, batch_y)
                        val_loss += loss.item()
                
                val_loss /= len(data_loaders['val'])
                val_losses.append(val_loss)
                
                # å­¦ä¹ ç‡è°ƒåº¦
                scheduler.step(val_loss)
                
                # æ—©åœ
                if val_loss < best_val_loss:
                    best_val_loss = val_loss
                    patience_counter = 0
                    # ä¿å­˜æœ€ä½³æ¨¡å‹
                    torch.save(self.model.state_dict(), 'best_manitoba_model.pth')
                else:
                    patience_counter += 1
                
                if patience_counter >= 20:
                    logger.info(f"æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬ {epoch + 1} è½®åœæ­¢è®­ç»ƒ")
                    break
                
                if (epoch + 1) % 20 == 0:
                    logger.info(f"Epoch {epoch + 1}/{epochs}: Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}")
            
            logger.info("âœ… æ›¼çœæ¨¡å‹è®­ç»ƒå®Œæˆ")
            
            return {
                'status': 'success',
                'epochs_trained': epoch + 1,
                'final_train_loss': train_loss,
                'final_val_loss': val_loss,
                'best_val_loss': best_val_loss,
                'train_losses': train_losses,
                'val_losses': val_losses
            }
            
        except Exception as e:
            logger.error(f"âŒ æ›¼çœæ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def evaluate_model(self, data_loaders: Dict) -> Dict:
        """è¯„ä¼°æ¨¡å‹"""
        try:
            if self.model is None:
                raise ValueError("æ¨¡å‹æœªæ„å»ºï¼Œè¯·å…ˆè°ƒç”¨build_model()")
            
            logger.info("ğŸ“Š å¼€å§‹æ›¼çœæ¨¡å‹è¯„ä¼°...")
            
            # åŠ è½½æœ€ä½³æ¨¡å‹
            self.model.load_state_dict(torch.load('best_manitoba_model.pth'))
            self.model.eval()
            
            # æµ‹è¯•é›†è¯„ä¼°
            test_predictions = []
            test_targets = []
            
            with torch.no_grad():
                for batch_X, batch_y in data_loaders['test']:
                    batch_X = batch_X.to(self.device)
                    outputs = self.model(batch_X).squeeze()
                    test_predictions.extend(outputs.cpu().numpy())
                    test_targets.extend(batch_y.numpy())
            
            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            test_predictions = np.array(test_predictions)
            test_targets = np.array(test_targets)
            
            r2 = r2_score(test_targets, test_predictions)
            mae = mean_absolute_error(test_targets, test_predictions)
            rmse = np.sqrt(mean_squared_error(test_targets, test_predictions))
            
            performance = {
                'r2_score': r2,
                'mae': mae,
                'rmse': rmse,
                'status': 'overfitting' if r2 < 0 else 'normal',
                'test_samples': len(test_targets),
                'region': 'Manitoba, Canada'
            }
            
            logger.info(f"ğŸ“Š æ›¼çœæ¨¡å‹æ€§èƒ½è¯„ä¼°å®Œæˆ:")
            logger.info(f"  RÂ²: {r2:.4f}")
            logger.info(f"  MAE: {mae:.4f}")
            logger.info(f"  RMSE: {rmse:.4f}")
            logger.info(f"  çŠ¶æ€: {'è¿‡æ‹Ÿåˆ' if r2 < 0 else 'æ­£å¸¸'}")
            logger.info(f"  åœ°åŒº: æ›¼å°¼æ‰˜å·´çœ, åŠ æ‹¿å¤§")
            
            return performance
            
        except Exception as e:
            logger.error(f"âŒ æ›¼çœæ¨¡å‹è¯„ä¼°å¤±è´¥: {e}")
            return {'status': 'error', 'error': str(e)}

def main():
    """ä¸»å‡½æ•°"""
    try:
        logger.info("ğŸš€ å¯åŠ¨ä½¿ç”¨æ›¼å°¼æ‰˜å·´çœæœ¬åœŸæ•°æ®è®­ç»ƒåœŸå£¤æ¹¿åº¦é¢„æµ‹æ¨¡å‹...")
        
        # åˆ›å»ºé¢„æµ‹å™¨
        predictor = ManitobaSoilMoisturePredictor()
        
        # åŠ è½½å’Œå‡†å¤‡æ›¼çœæ•°æ®
        data_result = predictor.load_and_prepare_data()
        
        if data_result['status'] != 'success':
            logger.error(f"âŒ æ›¼çœæ•°æ®å‡†å¤‡å¤±è´¥: {data_result}")
            return
        
        # æ„å»ºæ¨¡å‹
        input_size = data_result['data_shapes']['train'][1]
        model = predictor.build_model(input_size)
        
        if model is None:
            logger.error("âŒ æ›¼çœæ¨¡å‹æ„å»ºå¤±è´¥")
            return
        
        # è®­ç»ƒæ¨¡å‹
        training_result = predictor.train_model(data_result['data_loaders'])
        
        if training_result['status'] != 'success':
            logger.error(f"âŒ æ›¼çœæ¨¡å‹è®­ç»ƒå¤±è´¥: {training_result}")
            return
        
        # è¯„ä¼°æ¨¡å‹
        performance = predictor.evaluate_model(data_result['data_loaders'])
        
        if 'status' not in performance:
            logger.info("ğŸ‰ ä½¿ç”¨æ›¼å°¼æ‰˜å·´çœæœ¬åœŸæ•°æ®è®­ç»ƒæ¨¡å‹æˆåŠŸï¼")
            
            # ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š
            report = {
                'timestamp': datetime.now().isoformat(),
                'region': 'Manitoba, Canada',
                'data_info': {
                    'total_samples': sum(data_result['data_shapes'].values()),
                    'features': input_size,
                    'feature_names': data_result['feature_names']
                },
                'training_summary': training_result,
                'model_performance': performance,
                'advantages': [
                    "ä½¿ç”¨æ›¼çœæœ¬åœŸæ•°æ®ï¼Œæ°”å€™ç‰¹å¾æ›´å‡†ç¡®",
                    "å¤§é™†æ€§æ°”å€™ï¼Œå››å­£åˆ†æ˜ï¼Œé€‚åˆå†œä¸šåº”ç”¨",
                    "æ¸©åº¦èŒƒå›´: -40Â°C to +35Â°Cï¼Œç¬¦åˆæ›¼çœå®é™…",
                    "é™æ°´æ¨¡å¼: å¤å­£å¤šé›¨ï¼Œå†¬å­£å°‘é›¨",
                    "ä½œç‰©ç”Ÿé•¿å­£èŠ‚: 5-9æœˆ"
                ]
            }
            
            # ä¿å­˜æŠ¥å‘Š
            report_file = f"manitoba_data_training_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False, default=str)
            
            logger.info(f"âœ… æ›¼çœè®­ç»ƒæŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            
            # æ˜¾ç¤ºå…³é”®ç»“æœ
            if performance['r2_score'] > 0:
                logger.info("ğŸ¯ æˆåŠŸï¼æ›¼çœæœ¬åœŸæ•°æ®è§£å†³äº†è¿‡æ‹Ÿåˆé—®é¢˜ï¼")
                logger.info(f"ğŸ† æœ€ç»ˆRÂ²: {performance['r2_score']:.4f}")
                logger.info(f"ğŸ“Š ä½¿ç”¨æ›¼çœæ•°æ®: {performance['test_samples']} ä¸ªæµ‹è¯•æ ·æœ¬")
                logger.info(f"ğŸŒ åœ°åŒº: {performance['region']}")
                logger.info("ğŸ’¡ ä¼˜åŠ¿: æ›¼çœæ•°æ®æ¯”æŒªå¨æ•°æ®æ›´é€‚åˆæœ¬åœ°åº”ç”¨")
            else:
                logger.info("âš ï¸ RÂ²ä»ä¸ºè´Ÿå€¼ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†æ")
            
            return report
        else:
            logger.error(f"âŒ æ›¼çœæ¨¡å‹è¯„ä¼°å¤±è´¥: {performance}")
            return None
        
    except Exception as e:
        logger.error(f"âŒ ä¸»å‡½æ•°æ‰§è¡Œå¤±è´¥: {e}")
        return None

if __name__ == "__main__":
    main()
