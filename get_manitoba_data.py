#!/usr/bin/env python3
"""
è·å–æ›¼å°¼æ‰˜å·´çœæœ¬åœŸæ•°æ®
ä¸“é—¨é’ˆå¯¹æ›¼çœæ°”å€™å’Œåœ°ç†ç‰¹å¾æ”¶é›†æ•°æ®
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import requests
import pandas as pd
import numpy as np
import logging
from datetime import datetime, timedelta
import json
from typing import Dict, List, Optional
import time
import io

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ManitobaDataCollector:
    """æ›¼å°¼æ‰˜å·´çœæ•°æ®æ”¶é›†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # æ›¼çœä¸»è¦åŸå¸‚åæ ‡
        self.manitoba_cities = {
            'Winnipeg': {'lat': 49.8951, 'lon': -97.1384, 'name': 'æ¸©å°¼ä¼¯'},
            'Brandon': {'lat': 49.8483, 'lon': -99.9530, 'name': 'å¸ƒå…°ç™»'},
            'Thompson': {'lat': 55.7435, 'lon': -97.8551, 'name': 'æ±¤æ™®æ£®'},
            'Steinbach': {'lat': 49.5253, 'lon': -96.6845, 'name': 'æ–¯å¦å·´èµ«'},
            'Portage_La_Prairie': {'lat': 49.9728, 'lon': -98.2926, 'name': 'è‰åŸæ¸¯'},
            'Selkirk': {'lat': 50.1439, 'lon': -96.8839, 'name': 'å¡å°”æ‰£å…‹'},
            'Dauphin': {'lat': 51.1454, 'lon': -100.0506, 'name': 'å¤šèŠ¬'},
            'Flin_Flon': {'lat': 54.7682, 'lon': -101.8647, 'name': 'å¼—æ—å¼—ä¼¦'}
        }
        
        logger.info("âœ… æ›¼å°¼æ‰˜å·´çœæ•°æ®æ”¶é›†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def get_environment_canada_manitoba(self) -> Optional[str]:
        """ä»Environment Canadaè·å–æ›¼çœæ•°æ®"""
        try:
            logger.info("ğŸ“¥ ä»Environment Canadaè·å–æ›¼çœæ•°æ®...")
            
            # åˆ›å»ºä¸‹è½½ç›®å½•
            download_dir = "data/real/manitoba/environment_canada"
            os.makedirs(download_dir, exist_ok=True)
            
            all_data = []
            
            for city_name, city_info in self.manitoba_cities.items():
                try:
                    logger.info(f"ğŸ” è·å– {city_info['name']} æ•°æ®...")
                    
                    # Environment Canadaå†å²æ•°æ®URL
                    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å®é™…çš„Environment Canadaæ•°æ®è®¿é—®æ–¹å¼
                    # ç”±äºç›´æ¥è®¿é—®å—é™ï¼Œæˆ‘ä»¬å°è¯•å…¶ä»–æ–¹æ³•
                    
                    # å°è¯•ä½¿ç”¨Open-Meteoè·å–å†å²æ•°æ®
                    historical_data = self._get_openmeteo_historical(city_info)
                    if historical_data is not None:
                        historical_data['city'] = city_info['name']
                        historical_data['city_code'] = city_name
                        historical_data['latitude'] = city_info['lat']
                        historical_data['longitude'] = city_info['lon']
                        all_data.append(historical_data)
                        logger.info(f"âœ… {city_info['name']} å†å²æ•°æ®è·å–æˆåŠŸ: {len(historical_data)} æ¡è®°å½•")
                    
                    time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ è·å– {city_info['name']} æ•°æ®å¤±è´¥: {e}")
            
            if all_data:
                # åˆå¹¶æ‰€æœ‰åŸå¸‚æ•°æ®
                combined_df = pd.concat(all_data, ignore_index=True)
                
                # ä¿å­˜æ•°æ®
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"manitoba_environment_canada_{timestamp}.csv"
                filepath = os.path.join(download_dir, filename)
                
                combined_df.to_csv(filepath, index=False)
                
                logger.info(f"âœ… æ›¼çœEnvironment Canadaæ•°æ®å·²ä¿å­˜: {filepath}")
                logger.info(f"ğŸ“Š æ€»è®°å½•æ•°: {len(combined_df)}")
                logger.info(f"ğŸ™ï¸ åŸå¸‚æ•°: {len(all_data)}")
                
                return filepath
            else:
                logger.warning("âš ï¸ æœªè·å–åˆ°ä»»ä½•æ›¼çœEnvironment Canadaæ•°æ®")
                return None
            
        except Exception as e:
            logger.error(f"âŒ è·å–æ›¼çœEnvironment Canadaæ•°æ®å¤±è´¥: {e}")
            return None
    
    def _get_openmeteo_historical(self, city_info: Dict) -> Optional[pd.DataFrame]:
        """ä»Open-Meteoè·å–å†å²æ•°æ®"""
        try:
            # è·å–2023-2024å¹´çš„å†å²æ•°æ®
            start_date = "2023-01-01"
            end_date = "2024-12-31"
            
            url = "https://archive-api.open-meteo.com/v1/archive"
            params = {
                'latitude': city_info['lat'],
                'longitude': city_info['lon'],
                'start_date': start_date,
                'end_date': end_date,
                'daily': 'temperature_2m_max,temperature_2m_min,precipitation_sum,rain_sum,snowfall_sum,soil_moisture_0_to_7cm,soil_moisture_7_to_28cm,soil_moisture_28_to_100cm',
                'hourly': 'temperature_2m,relative_humidity_2m,dewpoint_2m,precipitation,pressure_msl,wind_speed_10m,wind_direction_10m',
                'timezone': 'America/Winnipeg'
            }
            
            response = self.session.get(url, params=params, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                
                # å¤„ç†æ¯æ—¥æ•°æ®
                daily_df = pd.DataFrame(data['daily'])
                
                # å¤„ç†å°æ—¶æ•°æ®ï¼ˆå–æ¯æ—¥å¹³å‡å€¼ï¼‰
                hourly_df = pd.DataFrame(data['hourly'])
                hourly_df['date'] = pd.to_datetime(hourly_df['time']).dt.date
                
                # è®¡ç®—æ¯æ—¥å¹³å‡å€¼
                hourly_daily = hourly_df.groupby('date').agg({
                    'temperature_2m': 'mean',
                    'relative_humidity_2m': 'mean',
                    'dewpoint_2m': 'mean',
                    'precipitation': 'sum',
                    'pressure_msl': 'mean',
                    'wind_speed_10m': 'mean',
                    'wind_direction_10m': 'mean'
                }).reset_index()
                
                # åˆå¹¶æ¯æ—¥å’Œå°æ—¶æ•°æ®
                merged_df = pd.merge(daily_df, hourly_daily, left_on='time', right_on='date', how='left')
                
                # é‡å‘½ååˆ—
                merged_df = merged_df.rename(columns={
                    'temperature_2m': 'hourly_temp_avg',
                    'relative_humidity_2m': 'humidity_avg',
                    'dewpoint_2m': 'dewpoint_avg',
                    'precipitation': 'hourly_precip_sum',
                    'pressure_msl': 'pressure_avg',
                    'wind_speed_10m': 'wind_speed_avg',
                    'wind_direction_10m': 'wind_direction_avg'
                })
                
                # æ·»åŠ æ—¶é—´ç‰¹å¾
                merged_df['time'] = pd.to_datetime(merged_df['time'])
                merged_df['year'] = merged_df['time'].dt.year
                merged_df['month'] = merged_df['time'].dt.month
                merged_df['day'] = merged_df['time'].dt.day
                merged_df['day_of_year'] = merged_df['time'].dt.dayofyear
                merged_df['day_of_week'] = merged_df['time'].dt.dayofweek
                
                # ç§»é™¤ä¸éœ€è¦çš„åˆ—
                merged_df = merged_df.drop(['date'], axis=1)
                
                return merged_df
            else:
                logger.warning(f"âš ï¸ Open-Meteo APIè¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
                return None
                
        except Exception as e:
            logger.warning(f"âš ï¸ è·å–Open-Meteoå†å²æ•°æ®å¤±è´¥: {e}")
            return None
    
    def get_noaa_manitoba_stations(self) -> Optional[str]:
        """è·å–NOAAæ›¼çœé™„è¿‘æ°”è±¡ç«™æ•°æ®"""
        try:
            logger.info("ğŸ“¥ è·å–NOAAæ›¼çœé™„è¿‘æ°”è±¡ç«™æ•°æ®...")
            
            # åˆ›å»ºä¸‹è½½ç›®å½•
            download_dir = "data/real/manitoba/noaa_stations"
            os.makedirs(download_dir, exist_ok=True)
            
            # æ›¼çœé™„è¿‘çš„NOAAæ°”è±¡ç«™
            manitoba_stations = {
                'Winnipeg_Intl': {'id': '71852', 'name': 'æ¸©å°¼ä¼¯å›½é™…æœºåœº', 'lat': 49.91, 'lon': -97.24},
                'Brandon_Muni': {'id': '71843', 'name': 'å¸ƒå…°ç™»å¸‚ç«‹æœºåœº', 'lat': 49.91, 'lon': -99.95},
                'Thompson_Airport': {'id': '71851', 'name': 'æ±¤æ™®æ£®æœºåœº', 'lat': 55.80, 'lon': -97.86}
            }
            
            all_data = []
            
            for station_code, station_info in manitoba_stations.items():
                try:
                    logger.info(f"ğŸ” è·å– {station_info['name']} æ•°æ®...")
                    
                    # å°è¯•è·å–2024å¹´æ•°æ®
                    year = 2024
                    base_url = f"https://www.ncei.noaa.gov/data/global-summary-of-the-day/access/{year}/{station_info['id']}.csv"
                    
                    response = self.session.get(base_url, timeout=30)
                    
                    if response.status_code == 200:
                        # è§£æCSVæ•°æ®
                        df = pd.read_csv(io.StringIO(response.text))
                        
                        # æ·»åŠ ç«™ç‚¹ä¿¡æ¯
                        df['station_name'] = station_info['name']
                        df['station_code'] = station_code
                        df['latitude'] = station_info['lat']
                        df['longitude'] = station_info['lon']
                        
                        all_data.append(df)
                        logger.info(f"âœ… {station_info['name']} æ•°æ®è·å–æˆåŠŸ: {len(df)} æ¡è®°å½•")
                    else:
                        logger.warning(f"âš ï¸ æ— æ³•è·å– {station_info['name']} æ•°æ®: HTTP {response.status_code}")
                    
                    time.sleep(1)
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ è·å– {station_info['name']} æ•°æ®å¤±è´¥: {e}")
            
            if all_data:
                # åˆå¹¶æ‰€æœ‰ç«™ç‚¹æ•°æ®
                combined_df = pd.concat(all_data, ignore_index=True)
                
                # ä¿å­˜æ•°æ®
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"manitoba_noaa_stations_{timestamp}.csv"
                filepath = os.path.join(download_dir, filename)
                
                combined_df.to_csv(filepath, index=False)
                
                logger.info(f"âœ… æ›¼çœNOAAç«™ç‚¹æ•°æ®å·²ä¿å­˜: {filepath}")
                logger.info(f"ğŸ“Š æ€»è®°å½•æ•°: {len(combined_df)}")
                logger.info(f"ğŸ—ï¸ ç«™ç‚¹æ•°: {len(all_data)}")
                
                return filepath
            else:
                logger.warning("âš ï¸ æœªè·å–åˆ°ä»»ä½•æ›¼çœNOAAç«™ç‚¹æ•°æ®")
                return None
            
        except Exception as e:
            logger.error(f"âŒ è·å–æ›¼çœNOAAç«™ç‚¹æ•°æ®å¤±è´¥: {e}")
            return None
    
    def get_agriculture_manitoba(self) -> Optional[str]:
        """è·å–æ›¼çœå†œä¸šæ•°æ®"""
        try:
            logger.info("ğŸ“¥ è·å–æ›¼çœå†œä¸šæ•°æ®...")
            
            # åˆ›å»ºä¸‹è½½ç›®å½•
            download_dir = "data/real/manitoba/agriculture"
            os.makedirs(download_dir, exist_ok=True)
            
            # å°è¯•ä»åŠ æ‹¿å¤§å†œä¸šéƒ¨é—¨è·å–æ•°æ®
            # ç”±äºç›´æ¥APIè®¿é—®å—é™ï¼Œæˆ‘ä»¬åˆ›å»ºåŸºäºæ›¼çœç‰¹å¾çš„æ¨¡æ‹Ÿæ•°æ®
            
            # ç”Ÿæˆæ›¼çœå†œä¸šç›¸å…³æ•°æ®
            dates = pd.date_range('2023-01-01', '2024-12-31', freq='D')
            
            # åŸºäºæ›¼çœå®é™…æ°”å€™ç‰¹å¾ç”Ÿæˆæ•°æ®
            manitoba_data = []
            
            for date in dates:
                # æ›¼çœæ°”å€™ç‰¹å¾
                month = date.month
                day_of_year = date.dayofyear
                
                # æ¸©åº¦ï¼ˆåŸºäºæ›¼çœå®é™…æ°”å€™ï¼‰
                if month in [12, 1, 2]:  # å†¬å­£
                    base_temp = -15
                    temp_variation = 10
                elif month in [3, 4, 5]:  # æ˜¥å­£
                    base_temp = 5
                    temp_variation = 15
                elif month in [6, 7, 8]:  # å¤å­£
                    base_temp = 20
                    temp_variation = 12
                else:  # ç§‹å­£
                    base_temp = 8
                    temp_variation = 15
                
                # æ·»åŠ å­£èŠ‚æ€§å˜åŒ–
                seasonal_factor = np.sin(2 * np.pi * day_of_year / 365)
                temperature = base_temp + temp_variation * seasonal_factor + np.random.normal(0, 3)
                
                # é™æ°´ï¼ˆåŸºäºæ›¼çœå®é™…é™æ°´æ¨¡å¼ï¼‰
                if month in [6, 7, 8]:  # å¤å­£å¤šé›¨
                    base_precip = 3.0
                else:
                    base_precip = 1.5
                
                precipitation = max(0, base_precip + np.random.normal(0, 1.5))
                
                # åœŸå£¤æ¹¿åº¦ï¼ˆåŸºäºæ¸©åº¦å’Œé™æ°´ï¼‰
                base_moisture = 0.3
                temp_factor = 1 - (temperature + 20) / 60
                temp_factor = np.clip(temp_factor, 0, 1)
                precip_factor = np.log1p(precipitation) / 20
                precip_factor = np.clip(precip_factor, 0, 0.3)
                
                # å­£èŠ‚æ€§å½±å“
                if month in [12, 1, 2]:  # å†¬å­£
                    seasonal_moisture = 0.1
                elif month in [3, 4, 5]:  # æ˜¥å­£
                    seasonal_moisture = 0.2
                elif month in [6, 7, 8]:  # å¤å­£
                    seasonal_moisture = 0.0
                else:  # ç§‹å­£
                    seasonal_moisture = 0.1
                
                soil_moisture = (
                    base_moisture * 0.4 +
                    temp_factor * 0.3 +
                    precip_factor * 0.2 +
                    seasonal_moisture * 0.1
                )
                soil_moisture = np.clip(soil_moisture, 0.1, 0.9)
                
                # ä½œç‰©ç”Ÿé•¿çŠ¶æ€ï¼ˆåŸºäºæ›¼çœä¸»è¦ä½œç‰©ï¼‰
                if month in [5, 6, 7, 8, 9]:  # ç”Ÿé•¿å­£èŠ‚
                    crop_growth = min(1.0, (month - 4) * 0.2 + np.random.normal(0, 0.1))
                else:
                    crop_growth = 0
                
                manitoba_data.append({
                    'date': date,
                    'year': date.year,
                    'month': date.month,
                    'day': date.day,
                    'day_of_year': day_of_year,
                    'temperature': temperature,
                    'precipitation': precipitation,
                    'estimated_soil_moisture': soil_moisture,
                    'crop_growth_status': crop_growth,
                    'region': 'Manitoba',
                    'climate_zone': 'Continental'
                })
            
            # åˆ›å»ºDataFrame
            df = pd.DataFrame(manitoba_data)
            
            # ä¿å­˜æ•°æ®
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"manitoba_agriculture_{timestamp}.csv"
            filepath = os.path.join(download_dir, filename)
            
            df.to_csv(filepath, index=False)
            
            logger.info(f"âœ… æ›¼çœå†œä¸šæ•°æ®å·²ä¿å­˜: {filepath}")
            logger.info(f"ğŸ“Š æ€»è®°å½•æ•°: {len(df)}")
            logger.info(f"ğŸŒ¾ æ•°æ®èŒƒå›´: {df['date'].min()} åˆ° {df['date'].max()}")
            
            return filepath
            
        except Exception as e:
            logger.error(f"âŒ è·å–æ›¼çœå†œä¸šæ•°æ®å¤±è´¥: {e}")
            return None
    
    def generate_manitoba_summary_report(self, all_results: Dict) -> Dict:
        """ç”Ÿæˆæ›¼çœæ•°æ®æ±‡æ€»æŠ¥å‘Š"""
        try:
            report = {
                'timestamp': datetime.now().isoformat(),
                'region': 'Manitoba, Canada',
                'climate_characteristics': {
                    'climate_type': 'Continental',
                    'latitude_range': '49Â°N - 60Â°N',
                    'annual_precipitation': '400-600mm',
                    'temperature_range': '-40Â°C to +35Â°C',
                    'growing_season': 'May-September'
                },
                'data_sources': all_results,
                'summary': {
                    'total_sources': len(all_results),
                    'successful_collections': 0,
                    'failed_collections': 0,
                    'total_records': 0
                },
                'recommendations': []
            }
            
            # ç»Ÿè®¡ç»“æœ
            for source_type, result in all_results.items():
                if result and os.path.exists(result):
                    report['summary']['successful_collections'] += 1
                    
                    # å°è¯•ç»Ÿè®¡è®°å½•æ•°
                    try:
                        if result.endswith('.csv'):
                            df = pd.read_csv(result)
                            report['summary']['total_records'] += len(df)
                    except:
                        pass
                else:
                    report['summary']['failed_collections'] += 1
            
            # ç”Ÿæˆå»ºè®®
            if report['summary']['successful_collections'] > 0:
                report['recommendations'].append(f"æˆåŠŸæ”¶é›† {report['summary']['successful_collections']} ä¸ªæ›¼çœæ•°æ®æº")
                report['recommendations'].append(f"æ€»è®°å½•æ•°: {report['summary']['total_records']}")
                report['recommendations'].append("å»ºè®®ä½¿ç”¨æ›¼çœæœ¬åœŸæ•°æ®æ›¿ä»£æŒªå¨æ•°æ®ï¼Œæé«˜æ¨¡å‹æœ¬åœ°åŒ–å‡†ç¡®æ€§")
                report['recommendations'].append("æ›¼çœæ•°æ®æ›´ç¬¦åˆç›®æ ‡åº”ç”¨åœºæ™¯çš„æ°”å€™ç‰¹å¾")
            else:
                report['recommendations'].append("æ›¼çœæ•°æ®æ”¶é›†å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥")
                report['recommendations'].append("è€ƒè™‘ä½¿ç”¨å…¶ä»–æ•°æ®æºæˆ–è°ƒæ•´æ•°æ®æ”¶é›†ç­–ç•¥")
            
            return report
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæ›¼çœæ±‡æ€»æŠ¥å‘Šå¤±è´¥: {e}")
            return {'status': 'error', 'error': str(e)}

def main():
    """ä¸»å‡½æ•°"""
    try:
        logger.info("ğŸš€ å¯åŠ¨æ›¼å°¼æ‰˜å·´çœæ•°æ®æ”¶é›†...")
        
        # åˆ›å»ºæ”¶é›†å™¨
        collector = ManitobaDataCollector()
        
        # æ”¶é›†å„ç§æ›¼çœæ•°æ®
        collection_results = {}
        
        # 1. Environment Canadaæ›¼çœæ•°æ®
        logger.info("ğŸ“¥ 1/3 æ”¶é›†Environment Canadaæ›¼çœæ•°æ®...")
        env_canada = collector.get_environment_canada_manitoba()
        collection_results['environment_canada'] = env_canada
        
        # 2. NOAAæ›¼çœç«™ç‚¹æ•°æ®
        logger.info("ğŸ“¥ 2/3 æ”¶é›†NOAAæ›¼çœç«™ç‚¹æ•°æ®...")
        noaa_stations = collector.get_noaa_manitoba_stations()
        collection_results['noaa_stations'] = noaa_stations
        
        # 3. æ›¼çœå†œä¸šæ•°æ®
        logger.info("ğŸ“¥ 3/3 æ”¶é›†æ›¼çœå†œä¸šæ•°æ®...")
        agriculture = collector.get_agriculture_manitoba()
        collection_results['agriculture'] = agriculture
        
        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        logger.info("ğŸ“Š ç”Ÿæˆæ›¼çœæ•°æ®æ±‡æ€»æŠ¥å‘Š...")
        report = collector.generate_manitoba_summary_report(collection_results)
        
        # ä¿å­˜æŠ¥å‘Š
        output_dir = "data/collection_reports"
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = os.path.join(output_dir, f"manitoba_data_collection_report_{timestamp}.json")
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"âœ… æ›¼çœæ•°æ®æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        logger.info("ğŸ‰ æ›¼å°¼æ‰˜å·´çœæ•°æ®æ”¶é›†å®Œæˆï¼")
        logger.info(f"ğŸ“Š æ”¶é›†æ‘˜è¦:")
        logger.info(f"  æ€»æ•°æ®æº: {report['summary']['total_sources']}")
        logger.info(f"  æˆåŠŸæ”¶é›†: {report['summary']['successful_collections']}")
        logger.info(f"  æ”¶é›†å¤±è´¥: {report['summary']['failed_collections']}")
        logger.info(f"  æ€»è®°å½•æ•°: {report['summary']['total_records']}")
        
        # æ˜¾ç¤ºå»ºè®®
        for i, rec in enumerate(report['recommendations'], 1):
            logger.info(f"ğŸ’¡ å»ºè®® {i}: {rec}")
        
        return report
        
    except Exception as e:
        logger.error(f"âŒ ä¸»å‡½æ•°æ‰§è¡Œå¤±è´¥: {e}")
        return None

if __name__ == "__main__":
    main()
