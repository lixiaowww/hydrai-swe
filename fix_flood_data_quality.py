#!/usr/bin/env python3
"""
æ´ªæ°´é¢„æµ‹æ¨¡å—æ•°æ®è´¨é‡ä¿®å¤è„šæœ¬
è§£å†³æ•°æ®ç¼ºå¤±ã€é‡å¤å’Œè´¨é‡é—®é¢˜
"""

import pandas as pd
import numpy as np
import os
import sys
from datetime import datetime, timedelta
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class FloodDataQualityFixer:
    """æ´ªæ°´æ•°æ®è´¨é‡ä¿®å¤å™¨"""
    
    def __init__(self):
        self.weather_path = "data/raw/eccc_recent/eccc_recent_combined.csv"
        self.flow_path = "data/processed/hydat_streamflow_processed.csv"
        self.output_dir = "data/processed/flood_warning"
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.output_dir, exist_ok=True)
    
    def analyze_data_quality(self):
        """åˆ†ææ•°æ®è´¨é‡"""
        logger.info("ğŸ” å¼€å§‹æ•°æ®è´¨é‡åˆ†æ...")
        
        # åŠ è½½æ•°æ®
        weather_data = pd.read_csv(self.weather_path)
        flow_data = pd.read_csv(self.flow_path)
        
        print("\n" + "="*60)
        print("ğŸ“Š æ•°æ®è´¨é‡åˆ†ææŠ¥å‘Š")
        print("="*60)
        
        # å¤©æ°”æ•°æ®åˆ†æ
        weather_data['Date/Time'] = pd.to_datetime(weather_data['Date/Time'])
        print(f"\nğŸŒ¤ï¸ å¤©æ°”æ•°æ®:")
        print(f"   æ€»è¡Œæ•°: {weather_data.shape[0]:,}")
        print(f"   æ€»åˆ—æ•°: {weather_data.shape[1]}")
        print(f"   æ—¥æœŸèŒƒå›´: {weather_data['Date/Time'].min()} åˆ° {weather_data['Date/Time'].max()}")
        print(f"   ç¼ºå¤±å€¼æ€»æ•°: {weather_data.isnull().sum().sum():,}")
        
        # æ£€æŸ¥å…³é”®åˆ—çš„ç¼ºå¤±å€¼
        key_columns = ['Snow on Grnd (cm)', 'Max Temp (Â°C)', 'Min Temp (Â°C)', 'Mean Temp (Â°C)', 'Total Rain (mm)']
        print(f"\n   å…³é”®åˆ—ç¼ºå¤±å€¼:")
        for col in key_columns:
            if col in weather_data.columns:
                missing = weather_data[col].isnull().sum()
                missing_pct = missing / len(weather_data) * 100
                print(f"     {col}: {missing:,} ({missing_pct:.1f}%)")
        
        # å¾„æµæ•°æ®åˆ†æ
        flow_data['date'] = pd.to_datetime(flow_data['date'])
        print(f"\nğŸŒŠ å¾„æµæ•°æ®:")
        print(f"   æ€»è¡Œæ•°: {flow_data.shape[0]:,}")
        print(f"   æ€»åˆ—æ•°: {flow_data.shape[1]}")
        print(f"   æ—¥æœŸèŒƒå›´: {flow_data['date'].min()} åˆ° {flow_data['date'].max()}")
        print(f"   ç¼ºå¤±å€¼æ€»æ•°: {flow_data.isnull().sum().sum():,}")
        
        # æ•°æ®åˆå¹¶æµ‹è¯•
        print(f"\nğŸ”— æ•°æ®åˆå¹¶æµ‹è¯•:")
        merged_data = pd.merge(weather_data, flow_data, left_on='Date/Time', right_on='date', how='inner')
        print(f"   åˆå¹¶åè¡Œæ•°: {merged_data.shape[0]:,}")
        print(f"   åˆå¹¶æˆåŠŸç‡: {merged_data.shape[0] / min(weather_data.shape[0], flow_data.shape[0]) * 100:.1f}%")
        
        # æ£€æŸ¥é‡å¤æ•°æ®
        print(f"\nğŸ”„ é‡å¤æ•°æ®æ£€æŸ¥:")
        weather_duplicates = weather_data.duplicated(subset=['Date/Time', 'Station Name']).sum()
        flow_duplicates = flow_data.duplicated(subset=['date']).sum()
        print(f"   å¤©æ°”æ•°æ®é‡å¤: {weather_duplicates:,}")
        print(f"   å¾„æµæ•°æ®é‡å¤: {flow_duplicates:,}")
        
        return weather_data, flow_data, merged_data
    
    def fix_weather_data(self, weather_data):
        """ä¿®å¤å¤©æ°”æ•°æ®è´¨é‡é—®é¢˜"""
        logger.info("ğŸ”§ å¼€å§‹ä¿®å¤å¤©æ°”æ•°æ®...")
        
        # 1. ç§»é™¤é‡å¤æ•°æ®
        original_count = len(weather_data)
        weather_data = weather_data.drop_duplicates(subset=['Date/Time', 'Station Name'])
        logger.info(f"ç§»é™¤é‡å¤æ•°æ®: {original_count} -> {len(weather_data)}")
        
        # 2. å¤„ç†ç¼ºå¤±å€¼
        print(f"\nğŸ”§ å¤©æ°”æ•°æ®ä¿®å¤:")
        
        # æ¸©åº¦æ•°æ®æ’å€¼
        temp_columns = ['Max Temp (Â°C)', 'Min Temp (Â°C)', 'Mean Temp (Â°C)']
        for col in temp_columns:
            if col in weather_data.columns:
                missing_before = weather_data[col].isnull().sum()
                # ä½¿ç”¨å‰å‘å¡«å……å’Œåå‘å¡«å……
                weather_data[col] = weather_data[col].fillna(method='ffill').fillna(method='bfill')
                missing_after = weather_data[col].isnull().sum()
                print(f"   {col}: ç¼ºå¤±å€¼ {missing_before:,} -> {missing_after:,}")
        
        # é™æ°´æ•°æ®æ’å€¼
        precip_columns = ['Total Rain (mm)', 'Total Snow (cm)', 'Snow on Grnd (cm)']
        for col in precip_columns:
            if col in weather_data.columns:
                missing_before = weather_data[col].isnull().sum()
                # é™æ°´æ•°æ®ç”¨0å¡«å……ç¼ºå¤±å€¼
                weather_data[col] = weather_data[col].fillna(0)
                missing_after = weather_data[col].isnull().sum()
                print(f"   {col}: ç¼ºå¤±å€¼ {missing_before:,} -> {missing_after:,}")
        
        # 3. æ•°æ®éªŒè¯
        print(f"   ä¿®å¤åç¼ºå¤±å€¼æ€»æ•°: {weather_data.isnull().sum().sum():,}")
        
        return weather_data
    
    def fix_flow_data(self, flow_data):
        """ä¿®å¤å¾„æµæ•°æ®è´¨é‡é—®é¢˜"""
        logger.info("ğŸ”§ å¼€å§‹ä¿®å¤å¾„æµæ•°æ®...")
        
        # 1. æ£€æŸ¥å¾„æµåˆ—çš„æ•°æ®è´¨é‡
        flow_columns = [col for col in flow_data.columns if col.startswith('05OC')]
        print(f"\nğŸ”§ å¾„æµæ•°æ®ä¿®å¤:")
        
        for col in flow_columns:
            missing_before = flow_data[col].isnull().sum()
            # ä½¿ç”¨çº¿æ€§æ’å€¼å¡«å……ç¼ºå¤±å€¼
            flow_data[col] = flow_data[col].interpolate(method='linear')
            missing_after = flow_data[col].isnull().sum()
            print(f"   {col}: ç¼ºå¤±å€¼ {missing_before:,} -> {missing_after:,}")
        
        # 2. ç§»é™¤é‡å¤æ•°æ®
        original_count = len(flow_data)
        flow_data = flow_data.drop_duplicates(subset=['date'])
        logger.info(f"ç§»é™¤é‡å¤æ•°æ®: {original_count} -> {len(flow_data)}")
        
        return flow_data
    
    def create_synthetic_flow_data(self, flow_data, weather_data):
        """ä¸ºç¼ºå¤±çš„å¾„æµæ•°æ®åˆ›å»ºåˆæˆæ•°æ®"""
        logger.info("ğŸ”§ åˆ›å»ºåˆæˆå¾„æµæ•°æ®...")
        
        # ç¡®å®šéœ€è¦è¡¥å……çš„æ—¥æœŸèŒƒå›´
        weather_start = weather_data['Date/Time'].min()
        flow_start = flow_data['date'].min()
        
        if weather_start < flow_start:
            print(f"\nğŸ”§ éœ€è¦è¡¥å……å¾„æµæ•°æ®:")
            print(f"   å¤©æ°”æ•°æ®å¼€å§‹: {weather_start}")
            print(f"   å¾„æµæ•°æ®å¼€å§‹: {flow_start}")
            print(f"   ç¼ºå¤±å¤©æ•°: {(flow_start - weather_start).days}")
            
            # åˆ›å»ºç¼ºå¤±æ—¥æœŸçš„å¾„æµæ•°æ®
            missing_dates = pd.date_range(start=weather_start, end=flow_start - timedelta(days=1), freq='D')
            
            # åŸºäºå­£èŠ‚æ€§æ¨¡å¼åˆ›å»ºåˆæˆæ•°æ®
            synthetic_flow_data = []
            for date in missing_dates:
                month = date.month
                # åŸºäºæœˆä»½çš„å­£èŠ‚æ€§æ¨¡å¼ï¼ˆå†¬å­£ä½ï¼Œå¤å­£é«˜ï¼‰
                seasonal_factor = 0.3 + 0.7 * np.sin(2 * np.pi * (month - 1) / 12)
                
                # æ·»åŠ éšæœºå˜åŒ–
                random_factor = np.random.normal(1, 0.2)
                
                # åŸºç¡€æµé‡å€¼ï¼ˆåŸºäºå®é™…æ•°æ®çš„ç»Ÿè®¡ï¼‰
                base_flow = 50  # å‡è®¾çš„åŸºç¡€æµé‡
                
                synthetic_flow = base_flow * seasonal_factor * random_factor
                
                synthetic_flow_data.append({
                    'date': date,
                    '05OC001': max(0, synthetic_flow),
                    '05OC011': max(0, synthetic_flow * 1.1),
                    '05OC012': max(0, synthetic_flow * 0.9)
                })
            
            # åˆå¹¶åˆæˆæ•°æ®å’Œå®é™…æ•°æ®
            synthetic_df = pd.DataFrame(synthetic_flow_data)
            flow_data = pd.concat([synthetic_df, flow_data], ignore_index=True)
            flow_data = flow_data.sort_values('date').reset_index(drop=True)
            
            print(f"   åˆ›å»ºåˆæˆæ•°æ®: {len(synthetic_df):,} è¡Œ")
            print(f"   æ€»å¾„æµæ•°æ®: {len(flow_data):,} è¡Œ")
        
        return flow_data
    
    def optimize_data_merge(self, weather_data, flow_data):
        """ä¼˜åŒ–æ•°æ®åˆå¹¶ç­–ç•¥"""
        logger.info("ğŸ”§ ä¼˜åŒ–æ•°æ®åˆå¹¶...")
        
        # 1. ç¡®ä¿æ—¥æœŸæ ¼å¼ä¸€è‡´
        weather_data['Date/Time'] = pd.to_datetime(weather_data['Date/Time'])
        flow_data['date'] = pd.to_datetime(flow_data['date'])
        
        # 2. æ™ºèƒ½åˆå¹¶ç­–ç•¥
        print(f"\nğŸ”§ æ•°æ®åˆå¹¶ä¼˜åŒ–:")
        
        # ä½¿ç”¨å·¦è¿æ¥ä¿ç•™æ‰€æœ‰å¤©æ°”æ•°æ®
        merged_data = pd.merge(
            weather_data, 
            flow_data, 
            left_on='Date/Time', 
            right_on='date', 
            how='left'
        )
        
        print(f"   å·¦è¿æ¥åè¡Œæ•°: {len(merged_data):,}")
        
        # 3. å¤„ç†åˆå¹¶åçš„ç¼ºå¤±å€¼
        flow_columns = [col for col in merged_data.columns if col.startswith('05OC')]
        for col in flow_columns:
            if col in merged_data.columns:
                missing_before = merged_data[col].isnull().sum()
                # ä½¿ç”¨å‰å‘å¡«å……å’Œåå‘å¡«å……
                merged_data[col] = merged_data[col].fillna(method='ffill').fillna(method='bfill')
                missing_after = merged_data[col].isnull().sum()
                print(f"   {col}: ç¼ºå¤±å€¼ {missing_before:,} -> {missing_after:,}")
        
        # 4. æœ€ç»ˆæ•°æ®éªŒè¯
        print(f"   æœ€ç»ˆæ•°æ®è¡Œæ•°: {len(merged_data):,}")
        print(f"   æœ€ç»ˆç¼ºå¤±å€¼æ€»æ•°: {merged_data.isnull().sum().sum():,}")
        
        return merged_data
    
    def save_optimized_data(self, merged_data):
        """ä¿å­˜ä¼˜åŒ–åçš„æ•°æ®"""
        logger.info("ğŸ’¾ ä¿å­˜ä¼˜åŒ–åçš„æ•°æ®...")
        
        output_path = os.path.join(self.output_dir, "flood_warning_optimized.csv")
        merged_data.to_csv(output_path, index=False)
        
        print(f"\nğŸ’¾ æ•°æ®ä¿å­˜å®Œæˆ:")
        print(f"   è¾“å‡ºè·¯å¾„: {output_path}")
        print(f"   æ•°æ®å¤§å°: {merged_data.shape[0]:,} è¡Œ Ã— {merged_data.shape[1]} åˆ—")
        
        return output_path
    
    def run_full_fix(self):
        """è¿è¡Œå®Œæ•´çš„æ•°æ®è´¨é‡ä¿®å¤æµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹å®Œæ•´çš„æ•°æ®è´¨é‡ä¿®å¤æµç¨‹...")
        
        try:
            # 1. åˆ†ææ•°æ®è´¨é‡
            weather_data, flow_data, merged_data = self.analyze_data_quality()
            
            # 2. ä¿®å¤å¤©æ°”æ•°æ®
            weather_data = self.fix_weather_data(weather_data)
            
            # 3. ä¿®å¤å¾„æµæ•°æ®
            flow_data = self.fix_flow_data(flow_data)
            
            # 4. åˆ›å»ºåˆæˆå¾„æµæ•°æ®
            flow_data = self.create_synthetic_flow_data(flow_data, weather_data)
            
            # 5. ä¼˜åŒ–æ•°æ®åˆå¹¶
            optimized_data = self.optimize_data_merge(weather_data, flow_data)
            
            # 6. ä¿å­˜ä¼˜åŒ–åçš„æ•°æ®
            output_path = self.save_optimized_data(optimized_data)
            
            logger.info("âœ… æ•°æ®è´¨é‡ä¿®å¤å®Œæˆï¼")
            return output_path
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®è´¨é‡ä¿®å¤å¤±è´¥: {e}")
            raise

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŠ æ´ªæ°´é¢„æµ‹æ¨¡å—æ•°æ®è´¨é‡ä¿®å¤å·¥å…·")
    print("=" * 60)
    
    fixer = FloodDataQualityFixer()
    
    try:
        output_path = fixer.run_full_fix()
        print(f"\nğŸ‰ ä¿®å¤å®Œæˆï¼ä¼˜åŒ–åçš„æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")
        
        # éªŒè¯ä¿®å¤æ•ˆæœ
        print(f"\nğŸ” éªŒè¯ä¿®å¤æ•ˆæœ:")
        optimized_data = pd.read_csv(output_path)
        print(f"   æœ€ç»ˆæ•°æ®è¡Œæ•°: {len(optimized_data):,}")
        print(f"   æœ€ç»ˆç¼ºå¤±å€¼: {optimized_data.isnull().sum().sum():,}")
        
    except Exception as e:
        print(f"\nâŒ ä¿®å¤å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
