#!/usr/bin/env python3
"""
ä¿®å¤æµ‹è¯•æ•°æ®ç‰¹å¾åç§°ï¼Œä½¿å…¶ä¸æ¨¡å‹æœŸæœ›çš„ç‰¹å¾åŒ¹é…
"""
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os

def fix_test_data_features():
    """ä¿®å¤æµ‹è¯•æ•°æ®ç‰¹å¾åç§°"""
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    test_data_file = "data/processed/flood_warning/flood_warning_test_data.csv"
    if not os.path.exists(test_data_file):
        print(f"âŒ æµ‹è¯•æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {test_data_file}")
        return False
    
    print("ğŸ“ åŠ è½½æµ‹è¯•æ•°æ®...")
    data = pd.read_csv(test_data_file)
    print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {data.shape}")
    
    # ä¿®å¤ç‰¹å¾åç§°ï¼Œä½¿å…¶ä¸æ¨¡å‹æœŸæœ›çš„åŒ¹é…
    print("ğŸ”§ ä¿®å¤ç‰¹å¾åç§°...")
    
    # é‡å‘½ååˆ—ä»¥åŒ¹é…æ¨¡å‹æœŸæœ›
    column_mapping = {
        '05OC001': '05OC001_x',
        '05OC011': '05OC011_y', 
        '05OC012': '05OC012_y'
    }
    
    data = data.rename(columns=column_mapping)
    
    # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„ç‰¹å¾éƒ½å­˜åœ¨
    required_features = [
        'Month', '05OC001_x', '05OC001_y', '05OC011_y', '05OC012_y',
        'DayOfYear', 'WeekOfYear', 'day_of_year_sin', 'day_of_year_cos',
        'month_sin', 'month_cos', 'temp_anomaly', 'flow_change',
        'flow_volatility', 'flow_peak', 'flow_corr_2_3', 'flow_corr_2_4',
        'flow_corr_2_5', 'flow_corr_3_5', 'flow_corr_4_5'
    ]
    
    # æ£€æŸ¥ç¼ºå¤±çš„ç‰¹å¾
    missing_features = [f for f in required_features if f not in data.columns]
    print(f"ğŸ” ç¼ºå¤±ç‰¹å¾: {missing_features}")
    
    # æ·»åŠ ç¼ºå¤±çš„ç‰¹å¾
    for feature in missing_features:
        if feature == '05OC001_x' and '05OC001' in data.columns:
            data['05OC001_x'] = data['05OC001']
        elif feature == '05OC011_y' and '05OC011' in data.columns:
            data['05OC011_y'] = data['05OC011']
        elif feature == '05OC012_y' and '05OC012' in data.columns:
            data['05OC012_y'] = data['05OC012']
        else:
            # ç”¨0å¡«å……ç¼ºå¤±ç‰¹å¾
            data[feature] = 0
            print(f"âš ï¸  ç”¨0å¡«å……ç¼ºå¤±ç‰¹å¾: {feature}")
    
    # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
    print("ğŸ”§ ä¿®å¤æ•°æ®ç±»å‹...")
    
    # å¤„ç†æ— ç©·å€¼å’ŒNaN
    numeric_columns = data.select_dtypes(include=[np.number]).columns
    for col in numeric_columns:
        # æ›¿æ¢æ— ç©·å€¼
        data[col] = data[col].replace([np.inf, -np.inf], np.nan)
        # ç”¨0å¡«å……NaN
        data[col] = data[col].fillna(0)
    
    # ç¡®ä¿æ‰€æœ‰ç‰¹å¾éƒ½æ˜¯æ•°å€¼å‹
    for feature in required_features:
        if feature in data.columns:
            data[feature] = pd.to_numeric(data[feature], errors='coerce').fillna(0)
    
    # éªŒè¯ç‰¹å¾
    print("âœ… éªŒè¯ç‰¹å¾...")
    available_features = [f for f in required_features if f in data.columns]
    print(f"ğŸ“Š å¯ç”¨ç‰¹å¾æ•°é‡: {len(available_features)}")
    print(f"ğŸ“Š æ•°æ®å½¢çŠ¶: {data.shape}")
    
    # ä¿å­˜ä¿®å¤åçš„æ•°æ®
    output_file = "data/processed/flood_warning/flood_warning_fixed_features.csv"
    data.to_csv(output_file, index=False)
    print(f"ğŸ’¾ ä¿®å¤åçš„æ•°æ®å·²ä¿å­˜: {output_file}")
    
    # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
    print("\nğŸ“‹ ä¿®å¤åçš„æ•°æ®é¢„è§ˆ:")
    print(data[required_features].head())
    
    return True

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹ä¿®å¤æµ‹è¯•æ•°æ®ç‰¹å¾...")
    fix_test_data_features()
