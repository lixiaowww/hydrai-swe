#!/usr/bin/env python3
"""
ERA5å†åˆ†ææ•°æ®æ‰©å±•ä¸‹è½½è„šæœ¬
è·å–æ›´å¤šæ°”è±¡å’Œé›ªç›¸å…³æ•°æ®ï¼Œæ‰©å±•æ•°æ®æ¥æº
"""

import os
import sys
import cdsapi
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json
import time
from typing import List, Dict, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

class ERA5ExtendedDownloader:
    """ERA5å†åˆ†ææ•°æ®æ‰©å±•ä¸‹è½½å™¨"""
    
    def __init__(self):
        self.data_dir = "data/raw/era5_extended"
        self.processed_dir = "data/processed/era5_extended"
        
        # åˆ›å»ºç›®å½•
        os.makedirs(self.data_dir, exist_ok=True)
        os.makedirs(self.processed_dir, exist_ok=True)
        
        # ç›®æ ‡åŒºåŸŸï¼ˆManitobaé™„è¿‘ï¼‰
        self.target_area = [60.0, -102.0, 49.0, -88.0]  # [åŒ—, è¥¿, å—, ä¸œ]
        
        # æ—¶é—´èŒƒå›´
        self.start_year = 2000
        self.end_year = 2024
        
        # åˆå§‹åŒ–CDS APIå®¢æˆ·ç«¯
        try:
            self.c = cdsapi.Client()
            print("âœ… ERA5 CDS APIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ ERA5 CDS APIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            print("âš ï¸ è¯·ç¡®ä¿å·²å®‰è£…cdsapi: pip install cdsapi")
            print("âš ï¸ è¯·ç¡®ä¿å·²é…ç½®CDS APIå¯†é’¥")
            self.c = None
    
    def download_snow_parameters(self, year: int) -> Optional[str]:
        """ä¸‹è½½é›ªç›¸å…³å‚æ•°"""
        if not self.c:
            print("âŒ CDS APIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return None
        
        try:
            print(f"ğŸ“¥ ä¸‹è½½ERA5é›ªå‚æ•°æ•°æ®: {year}")
            
            # é›ªç›¸å…³å‚æ•°
            variables = [
                'snow_density',           # é›ªå¯†åº¦
                'snow_depth',             # é›ªæ·±åº¦
                'snow_depth_water_equivalent',  # é›ªæ°´å½“é‡
                'snow_evaporation',       # é›ªè’¸å‘
                'snowfall',               # é™é›ªé‡
                'snowmelt',               # èé›ªé‡
            ]
            
            # æ„å»ºè¯·æ±‚å‚æ•°
            request_params = {
                'product_type': 'reanalysis',
                'variable': variables,
                'year': str(year),
                'month': [f"{i:02d}" for i in range(1, 13)],
                'day': [f"{i:02d}" for i in range(1, 32)],
                'time': [f"{i:02d}:00" for i in range(0, 24, 6)],  # 6å°æ—¶é—´éš”
                'area': self.target_area,
                'format': 'netcdf'
            }
            
            # ç”Ÿæˆæ–‡ä»¶å
            filename = f"era5_snow_{year}.nc"
            filepath = os.path.join(self.data_dir, filename)
            
            print(f"   å‚æ•°: {variables}")
            print(f"   åŒºåŸŸ: {self.target_area}")
            print(f"   ä¿å­˜åˆ°: {filepath}")
            
            # ä¸‹è½½æ•°æ®
            self.c.retrieve('reanalysis-era5-single-levels', request_params, filepath)
            
            print(f"âœ… ä¸‹è½½å®Œæˆ: {filename}")
            return filepath
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    def download_meteorological_parameters(self, year: int) -> Optional[str]:
        """ä¸‹è½½æ°”è±¡å‚æ•°"""
        if not self.c:
            print("âŒ CDS APIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return None
        
        try:
            print(f"ğŸ“¥ ä¸‹è½½ERA5æ°”è±¡å‚æ•°æ•°æ®: {year}")
            
            # æ°”è±¡ç›¸å…³å‚æ•°
            variables = [
                '2m_temperature',         # 2ç±³æ¸©åº¦
                '2m_relative_humidity',   # 2ç±³ç›¸å¯¹æ¹¿åº¦
                'total_precipitation',    # æ€»é™æ°´é‡
                'surface_pressure',       # è¡¨é¢æ°”å‹
                '10m_u_component_of_wind',  # 10ç±³é£é€ŸUåˆ†é‡
                '10m_v_component_of_wind',  # 10ç±³é£é€ŸVåˆ†é‡
                'surface_solar_radiation_downwards_hourly',  # è¡¨é¢å¤ªé˜³è¾å°„
                'surface_thermal_radiation_downwards_hourly',  # è¡¨é¢çƒ­è¾å°„
            ]
            
            # æ„å»ºè¯·æ±‚å‚æ•°
            request_params = {
                'product_type': 'reanalysis',
                'variable': variables,
                'year': str(year),
                'month': [f"{i:02d}" for i in range(1, 13)],
                'day': [f"{i:02d}" for i in range(1, 32)],
                'time': [f"{i:02d}:00" for i in range(0, 24, 6)],  # 6å°æ—¶é—´éš”
                'area': self.target_area,
                'format': 'netcdf'
            }
            
            # ç”Ÿæˆæ–‡ä»¶å
            filename = f"era5_meteo_{year}.nc"
            filepath = os.path.join(self.data_dir, filename)
            
            print(f"   å‚æ•°: {variables}")
            print(f"   åŒºåŸŸ: {self.target_area}")
            print(f"   ä¿å­˜åˆ°: {filepath}")
            
            # ä¸‹è½½æ•°æ®
            self.c.retrieve('reanalysis-era5-single-levels', request_params, filepath)
            
            print(f"âœ… ä¸‹è½½å®Œæˆ: {filename}")
            return filepath
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    def download_soil_parameters(self, year: int) -> Optional[str]:
        """ä¸‹è½½åœŸå£¤å‚æ•°"""
        if not self.c:
            print("âŒ CDS APIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return None
        
        try:
            print(f"ğŸ“¥ ä¸‹è½½ERA5åœŸå£¤å‚æ•°æ•°æ®: {year}")
            
            # åœŸå£¤ç›¸å…³å‚æ•°
            variables = [
                'volumetric_soil_water_layer_1',  # ç¬¬1å±‚åœŸå£¤ä½“ç§¯å«æ°´é‡
                'volumetric_soil_water_layer_2',  # ç¬¬2å±‚åœŸå£¤ä½“ç§¯å«æ°´é‡
                'volumetric_soil_water_layer_3',  # ç¬¬3å±‚åœŸå£¤ä½“ç§¯å«æ°´é‡
                'volumetric_soil_water_layer_4',  # ç¬¬4å±‚åœŸå£¤ä½“ç§¯å«æ°´é‡
                'soil_temperature_level_1',       # ç¬¬1å±‚åœŸå£¤æ¸©åº¦
                'soil_temperature_level_2',       # ç¬¬2å±‚åœŸå£¤æ¸©åº¦
                'soil_temperature_level_3',       # ç¬¬3å±‚åœŸå£¤æ¸©åº¦
                'soil_temperature_level_4',       # ç¬¬4å±‚åœŸå£¤æ¸©åº¦
            ]
            
            # æ„å»ºè¯·æ±‚å‚æ•°
            request_params = {
                'product_type': 'reanalysis',
                'variable': variables,
                'year': str(year),
                'month': [f"{i:02d}" for i in range(1, 13)],
                'day': [f"{i:02d}" for i in range(1, 32)],
                'time': [f"{i:02d}:00" for i in range(0, 24, 6)],  # 6å°æ—¶é—´éš”
                'area': self.target_area,
                'format': 'netcdf'
            }
            
            # ç”Ÿæˆæ–‡ä»¶å
            filename = f"era5_soil_{year}.nc"
            filepath = os.path.join(self.data_dir, filename)
            
            print(f"   å‚æ•°: {variables}")
            print(f"   åŒºåŸŸ: {self.target_area}")
            print(f"   ä¿å­˜åˆ°: {filepath}")
            
            # ä¸‹è½½æ•°æ®
            self.c.retrieve('reanalysis-era5-single-levels', request_params, filepath)
            
            print(f"âœ… ä¸‹è½½å®Œæˆ: {filename}")
            return filepath
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    def download_all_parameters(self, year: int) -> List[str]:
        """ä¸‹è½½æ‰€æœ‰å‚æ•°"""
        print(f"ğŸš€ å¼€å§‹ä¸‹è½½ERA5æ•°æ®: {year}")
        print("=" * 50)
        
        downloaded_files = []
        
        # ä¸‹è½½é›ªå‚æ•°
        snow_file = self.download_snow_parameters(year)
        if snow_file:
            downloaded_files.append(snow_file)
        
        # ä¸‹è½½æ°”è±¡å‚æ•°
        meteo_file = self.download_meteorological_parameters(year)
        if meteo_file:
            downloaded_files.append(meteo_file)
        
        # ä¸‹è½½åœŸå£¤å‚æ•°
        soil_file = self.download_soil_parameters(year)
        if soil_file:
            downloaded_files.append(soil_file)
        
        print(f"\nğŸ“Š {year}å¹´ä¸‹è½½å®Œæˆ: {len(downloaded_files)}/{3} ä¸ªæ–‡ä»¶")
        return downloaded_files
    
    def process_netcdf_file(self, filepath: str) -> Optional[pd.DataFrame]:
        """å¤„ç†NetCDFæ–‡ä»¶"""
        try:
            import netCDF4 as nc
            import xarray as xr
            
            print(f"ğŸ”„ å¤„ç†NetCDFæ–‡ä»¶: {filepath}")
            
            # ä½¿ç”¨xarrayè¯»å–æ•°æ®
            ds = xr.open_dataset(filepath)
            
            print(f"   å˜é‡: {list(ds.variables.keys())}")
            print(f"   ç»´åº¦: {list(ds.dims.keys())}")
            
            # è½¬æ¢ä¸ºDataFrame
            df = ds.to_dataframe()
            
            # é‡ç½®ç´¢å¼•
            df = df.reset_index()
            
            # å¤„ç†æ—¶é—´åˆ—
            if 'time' in df.columns:
                df['date'] = pd.to_datetime(df['time'])
                df = df.drop('time', axis=1)
            
            # å¤„ç†åæ ‡åˆ—
            if 'latitude' in df.columns and 'longitude' in df.columns:
                # é€‰æ‹©ä¸­å¿ƒç‚¹æ•°æ®ï¼ˆç®€åŒ–å¤„ç†ï¼‰
                center_lat = (self.target_area[0] + self.target_area[2]) / 2
                center_lon = (self.target_area[1] + self.target_area[3]) / 2
                
                # æ‰¾åˆ°æœ€æ¥è¿‘çš„åæ ‡ç‚¹
                df = df[
                    (df['latitude'].between(center_lat - 0.5, center_lat + 0.5)) &
                    (df['longitude'].between(center_lon - 0.5, center_lon + 0.5))
                ]
                
                # åˆ é™¤åæ ‡åˆ—
                df = df.drop(['latitude', 'longitude'], axis=1)
            
            print(f"   å¤„ç†åæ•°æ®å½¢çŠ¶: {df.shape}")
            return df
            
        except ImportError:
            print("âš ï¸ éœ€è¦å®‰è£…netCDF4å’Œxarray: pip install netCDF4 xarray")
            return None
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            return None
    
    def merge_era5_data(self) -> pd.DataFrame:
        """åˆå¹¶æ‰€æœ‰ERA5æ•°æ®"""
        print("ğŸ”„ åˆå¹¶ERA5æ•°æ®")
        
        all_data = []
        
        # å¤„ç†æ‰€æœ‰ä¸‹è½½çš„NetCDFæ–‡ä»¶
        netcdf_files = [f for f in os.listdir(self.data_dir) if f.endswith('.nc')]
        
        for netcdf_file in netcdf_files:
            filepath = os.path.join(self.data_dir, netcdf_file)
            print(f"\nğŸ“Š å¤„ç†æ–‡ä»¶: {netcdf_file}")
            
            df = self.process_netcdf_file(filepath)
            if df is not None and not df.empty:
                # æ·»åŠ æ•°æ®æºæ ‡è¯†
                df['data_source'] = 'ERA5'
                
                # æ ¹æ®æ–‡ä»¶åæ·»åŠ æ•°æ®ç±»å‹æ ‡è¯†
                if 'snow' in netcdf_file:
                    df['data_type'] = 'snow'
                elif 'meteo' in netcdf_file:
                    df['data_type'] = 'meteorological'
                elif 'soil' in netcdf_file:
                    df['data_type'] = 'soil'
                else:
                    df['data_type'] = 'unknown'
                
                all_data.append(df)
                print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(df)} æ¡è®°å½•")
            else:
                print(f"âš ï¸ æ•°æ®åŠ è½½å¤±è´¥")
        
        if not all_data:
            print("âŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ•°æ®")
            return pd.DataFrame()
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        merged_data = pd.concat(all_data, ignore_index=True)
        
        # å»é‡å’Œæ’åº
        if 'date' in merged_data.columns:
            merged_data = merged_data.drop_duplicates(subset=['date']).sort_values('date')
        
        print(f"âœ… ERA5æ•°æ®åˆå¹¶å®Œæˆ: {len(merged_data)} æ¡è®°å½•")
        
        # ä¿å­˜åˆå¹¶åçš„æ•°æ®
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"era5_extended_data_{timestamp}.csv"
        output_path = os.path.join(self.processed_dir, output_file)
        
        merged_data.to_csv(output_path, index=False)
        print(f"âœ… åˆå¹¶æ•°æ®å·²ä¿å­˜: {output_path}")
        
        return merged_data
    
    def generate_download_report(self, downloaded_files: List[str]) -> Dict[str, Any]:
        """ç”Ÿæˆä¸‹è½½æŠ¥å‘Š"""
        report = {
            'timestamp': datetime.now().isoformat(),
            'total_files': len(downloaded_files),
            'successful_downloads': len([f for f in downloaded_files if f]),
            'failed_downloads': len([f for f in downloaded_files if not f]),
            'file_details': [],
            'target_area': self.target_area,
            'time_range': f"{self.start_year}-{self.end_year}"
        }
        
        for filepath in downloaded_files:
            if filepath and os.path.exists(filepath):
                file_info = {
                    'filename': os.path.basename(filepath),
                    'size_mb': os.path.getsize(filepath) / 1024 / 1024,
                    'download_time': datetime.fromtimestamp(os.path.getctime(filepath)).isoformat()
                }
                report['file_details'].append(file_info)
        
        return report

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ERA5å†åˆ†ææ•°æ®æ‰©å±•ä¸‹è½½å™¨å¯åŠ¨")
    print("=" * 50)
    
    downloader = ERA5ExtendedDownloader()
    
    if not downloader.c:
        print("âŒ æ— æ³•ç»§ç»­ï¼ŒCDS APIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        return
    
    # ä¸‹è½½æ‰€æœ‰å¹´ä»½çš„æ•°æ®
    all_downloaded_files = []
    
    for year in range(downloader.start_year, downloader.end_year + 1):
        print(f"\nğŸ¯ å¼€å§‹ä¸‹è½½ {year} å¹´æ•°æ®")
        downloaded_files = downloader.download_all_parameters(year)
        all_downloaded_files.extend(downloaded_files)
        
        # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
        time.sleep(5)
    
    # ç”Ÿæˆä¸‹è½½æŠ¥å‘Š
    report = downloader.generate_download_report(all_downloaded_files)
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = os.path.join(downloader.data_dir, f"download_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
    with open(report_path, 'w') as f:
        json.dump(report, f, indent=2)
    
    print(f"\nğŸ“Š ä¸‹è½½æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    print(f"   æ€»æ–‡ä»¶æ•°: {report['total_files']}")
    print(f"   æˆåŠŸä¸‹è½½: {report['successful_downloads']}")
    print(f"   å¤±è´¥ä¸‹è½½: {report['failed_downloads']}")
    
    # åˆå¹¶æ•°æ®
    print(f"\nğŸ”„ å¼€å§‹åˆå¹¶ERA5æ•°æ®...")
    merged_data = downloader.merge_era5_data()
    
    if not merged_data.empty:
        print(f"âœ… ERA5æ‰©å±•æ•°æ®é›†åˆ›å»ºå®Œæˆï¼Œæ€»è®°å½•æ•°: {len(merged_data)}")
    else:
        print("âŒ ERA5æ•°æ®åˆå¹¶å¤±è´¥")

if __name__ == "__main__":
    main()

