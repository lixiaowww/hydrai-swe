#!/usr/bin/env python3
"""
æ•°æ®è´¨é‡ä¿®å¤å™¨
è§£å†³ç‰¹å¾è¿‡å¤šã€å¼‚å¸¸å€¼è¿‡å¤šã€é«˜ç›¸å…³ç‰¹å¾ç­‰é—®é¢˜
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import numpy as np
import pandas as pd
import logging
from datetime import datetime
import json
from typing import Dict, List, Tuple
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.preprocessing import StandardScaler
from scipy import stats

# å¯¼å…¥æ•°æ®è´¨é‡æ£€æµ‹å™¨
from src.data.data_quality_detector import DataQualityDetector

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class DataQualityFixer:
    """æ•°æ®è´¨é‡ä¿®å¤å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®è´¨é‡ä¿®å¤å™¨"""
        self.quality_detector = DataQualityDetector()
        self.fix_history = []
        
        logger.info("âœ… æ•°æ®è´¨é‡ä¿®å¤å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def fix_data_quality(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """ä¿®å¤æ•°æ®è´¨é‡é—®é¢˜"""
        try:
            logger.info("ğŸ”§ å¼€å§‹ä¿®å¤æ•°æ®è´¨é‡é—®é¢˜...")
            
            # æ­¥éª¤1: æ£€æµ‹æ•°æ®è´¨é‡é—®é¢˜
            logger.info("ğŸ” æ­¥éª¤1: æ£€æµ‹æ•°æ®è´¨é‡é—®é¢˜...")
            quality_result = self.quality_detector.detect_data_issues(X, y)
            
            if quality_result['status'] != 'success':
                logger.error("âŒ æ•°æ®è´¨é‡æ£€æµ‹å¤±è´¥")
                return {'status': 'error', 'error': 'æ•°æ®è´¨é‡æ£€æµ‹å¤±è´¥'}
            
            logger.info(f"ğŸ“Š æ£€æµ‹åˆ° {quality_result['total_issues']} ä¸ªé—®é¢˜")
            
            # æ­¥éª¤2: åº”ç”¨ä¿®å¤ç­–ç•¥
            logger.info("ğŸ”§ æ­¥éª¤2: åº”ç”¨ä¿®å¤ç­–ç•¥...")
            fixed_data = self._apply_fixes(X, y, quality_result)
            
            # æ­¥éª¤3: éªŒè¯ä¿®å¤æ•ˆæœ
            logger.info("ğŸ” æ­¥éª¤3: éªŒè¯ä¿®å¤æ•ˆæœ...")
            validation_result = self.quality_detector.detect_data_issues(fixed_data['X_fixed'], y)
            
            # ç”Ÿæˆä¿®å¤æŠ¥å‘Š
            fix_report = {
                'status': 'success',
                'timestamp': datetime.now().isoformat(),
                'original_quality_score': quality_result['quality_score'],
                'fixed_quality_score': validation_result['quality_score'],
                'improvement': validation_result['quality_score'] - quality_result['quality_score'],
                'fixes_applied': fixed_data['fixes_applied'],
                'original_shape': X.shape,
                'fixed_shape': fixed_data['X_fixed'].shape,
                'X_fixed': fixed_data['X_fixed'],
                'y_fixed': fixed_data['y_fixed'],
                'details': {
                    'original_issues': quality_result,
                    'fixed_issues': validation_result
                }
            }
            
            self.fix_history.append(fix_report)
            
            logger.info("âœ… æ•°æ®è´¨é‡ä¿®å¤å®Œæˆ")
            logger.info(f"ğŸ“Š è´¨é‡å¾—åˆ†æå‡: {quality_result['quality_score']:.3f} -> {validation_result['quality_score']:.3f}")
            
            return fix_report
            
        except Exception as e:
            logger.error(f"âŒ ä¿®å¤æ•°æ®è´¨é‡å¤±è´¥: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def _apply_fixes(self, X: np.ndarray, y: np.ndarray, quality_result: Dict) -> Dict:
        """åº”ç”¨ä¿®å¤ç­–ç•¥"""
        try:
            X_fixed = X.copy()
            y_fixed = y.copy()
            fixes_applied = []
            
            # ä¿®å¤1: å¤„ç†å¼‚å¸¸å€¼
            if quality_result.get('high_issues', 0) > 0:
                logger.info("ğŸ”§ ä¿®å¤1: å¤„ç†å¼‚å¸¸å€¼...")
                X_fixed, outlier_fixes = self._fix_outliers(X_fixed)
                fixes_applied.extend(outlier_fixes)
            
            # ä¿®å¤2: ç‰¹å¾é€‰æ‹©ï¼ˆå‡å°‘ç‰¹å¾æ•°é‡ï¼‰
            if any(issue['type'] == 'too_many_features' for issue in quality_result.get('issues', [])):
                logger.info("ğŸ”§ ä¿®å¤2: ç‰¹å¾é€‰æ‹©...")
                X_fixed, feature_fixes = self._select_features(X_fixed, y_fixed)
                fixes_applied.extend(feature_fixes)
            
            # ä¿®å¤3: ç§»é™¤é«˜ç›¸å…³ç‰¹å¾
            if any(issue['type'] == 'high_feature_correlation' for issue in quality_result.get('issues', [])):
                logger.info("ğŸ”§ ä¿®å¤3: ç§»é™¤é«˜ç›¸å…³ç‰¹å¾...")
                X_fixed, correlation_fixes = self._remove_correlated_features(X_fixed)
                fixes_applied.extend(correlation_fixes)
            
            # ä¿®å¤4: æ•°æ®æ ‡å‡†åŒ–
            logger.info("ğŸ”§ ä¿®å¤4: æ•°æ®æ ‡å‡†åŒ–...")
            X_fixed, scaling_fixes = self._standardize_features(X_fixed)
            fixes_applied.extend(scaling_fixes)
            
            return {
                'X_fixed': X_fixed,
                'y_fixed': y_fixed,
                'fixes_applied': fixes_applied
            }
            
        except Exception as e:
            logger.error(f"âŒ åº”ç”¨ä¿®å¤ç­–ç•¥å¤±è´¥: {e}")
            raise
    
    def _fix_outliers(self, X: np.ndarray) -> Tuple[np.ndarray, List[Dict]]:
        """ä¿®å¤å¼‚å¸¸å€¼"""
        try:
            fixes_applied = []
            X_fixed = X.copy()
            
            # ä½¿ç”¨IQRæ–¹æ³•å¤„ç†å¼‚å¸¸å€¼
            for col in range(X.shape[1]):
                feature_data = X[:, col]
                Q1 = np.percentile(feature_data, 25)
                Q3 = np.percentile(feature_data, 75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                # ç»Ÿè®¡å¼‚å¸¸å€¼
                outliers_mask = (feature_data < lower_bound) | (feature_data > upper_bound)
                outlier_count = np.sum(outliers_mask)
                
                if outlier_count > 0:
                    # å°†å¼‚å¸¸å€¼æ›¿æ¢ä¸ºè¾¹ç•Œå€¼
                    X_fixed[outliers_mask, col] = np.clip(
                        X_fixed[outliers_mask, col], 
                        lower_bound, 
                        upper_bound
                    )
                    
                    fixes_applied.append({
                        'type': 'outlier_fix',
                        'feature': col,
                        'outliers_fixed': outlier_count,
                        'method': 'IQR_clipping'
                    })
            
            logger.info(f"âœ… å¼‚å¸¸å€¼ä¿®å¤å®Œæˆï¼Œä¿®å¤äº† {len(fixes_applied)} ä¸ªç‰¹å¾")
            return X_fixed, fixes_applied
            
        except Exception as e:
            logger.error(f"âŒ ä¿®å¤å¼‚å¸¸å€¼å¤±è´¥: {e}")
            return X, []
    
    def _select_features(self, X: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray, List[Dict]]:
        """ç‰¹å¾é€‰æ‹©"""
        try:
            fixes_applied = []
            
            # è®¡ç®—åˆé€‚çš„ç‰¹å¾æ•°é‡ï¼ˆæ ·æœ¬æ•°çš„1/3ï¼‰
            max_features = max(5, len(X) // 3)
            
            if X.shape[1] > max_features:
                logger.info(f"ğŸ”§ ä» {X.shape[1]} ä¸ªç‰¹å¾ä¸­é€‰æ‹© {max_features} ä¸ªæœ€é‡è¦çš„ç‰¹å¾")
                
                # ä½¿ç”¨Fæ£€éªŒé€‰æ‹©ç‰¹å¾
                selector = SelectKBest(score_func=f_regression, k=max_features)
                X_selected = selector.fit_transform(X, y)
                
                # è·å–é€‰ä¸­çš„ç‰¹å¾ç´¢å¼•
                selected_features = selector.get_support(indices=True)
                
                fixes_applied.append({
                    'type': 'feature_selection',
                    'original_features': X.shape[1],
                    'selected_features': max_features,
                    'method': 'F_test',
                    'selected_indices': selected_features.tolist()
                })
                
                logger.info(f"âœ… ç‰¹å¾é€‰æ‹©å®Œæˆ: {X.shape[1]} -> {X_selected.shape[1]}")
                return X_selected, fixes_applied
            else:
                logger.info("âœ… ç‰¹å¾æ•°é‡åˆé€‚ï¼Œæ— éœ€é€‰æ‹©")
                return X, fixes_applied
                
        except Exception as e:
            logger.error(f"âŒ ç‰¹å¾é€‰æ‹©å¤±è´¥: {e}")
            return X, []
    
    def _remove_correlated_features(self, X: np.ndarray) -> Tuple[np.ndarray, List[Dict]]:
        """ç§»é™¤é«˜ç›¸å…³ç‰¹å¾"""
        try:
            fixes_applied = []
            
            if X.shape[1] <= 1:
                return X, fixes_applied
            
            # è®¡ç®—ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ
            corr_matrix = np.corrcoef(X.T)
            
            # æ‰¾åˆ°é«˜ç›¸å…³ç‰¹å¾å¯¹ï¼ˆç›¸å…³ç³»æ•° > 0.95ï¼‰
            high_corr_pairs = []
            for i in range(corr_matrix.shape[0]):
                for j in range(i + 1, corr_matrix.shape[1]):
                    if abs(corr_matrix[i, j]) > 0.95:
                        high_corr_pairs.append((i, j))
            
            if high_corr_pairs:
                logger.info(f"ğŸ”§ å‘ç° {len(high_corr_pairs)} å¯¹é«˜ç›¸å…³ç‰¹å¾")
                
                # ç§»é™¤é«˜ç›¸å…³ç‰¹å¾ï¼ˆä¿ç•™ç¬¬ä¸€ä¸ªï¼‰
                features_to_remove = set()
                for i, j in high_corr_pairs:
                    features_to_remove.add(j)  # ç§»é™¤ç¬¬äºŒä¸ªç‰¹å¾
                
                # ä¿ç•™è¦ä¿ç•™çš„ç‰¹å¾
                features_to_keep = [i for i in range(X.shape[1]) if i not in features_to_remove]
                X_uncorr = X[:, features_to_keep]
                
                fixes_applied.append({
                    'type': 'correlation_fix',
                    'high_corr_pairs': len(high_corr_pairs),
                    'features_removed': len(features_to_remove),
                    'features_kept': len(features_to_keep),
                    'method': 'high_correlation_removal'
                })
                
                logger.info(f"âœ… é«˜ç›¸å…³ç‰¹å¾ç§»é™¤å®Œæˆ: {X.shape[1]} -> {X_uncorr.shape[1]}")
                return X_uncorr, fixes_applied
            else:
                logger.info("âœ… æ²¡æœ‰å‘ç°é«˜ç›¸å…³ç‰¹å¾")
                return X, fixes_applied
                
        except Exception as e:
            logger.error(f"âŒ ç§»é™¤é«˜ç›¸å…³ç‰¹å¾å¤±è´¥: {e}")
            return X, []
    
    def _standardize_features(self, X: np.ndarray) -> Tuple[np.ndarray, List[Dict]]:
        """ç‰¹å¾æ ‡å‡†åŒ–"""
        try:
            fixes_applied = []
            
            # ä½¿ç”¨Z-scoreæ ‡å‡†åŒ–
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            
            fixes_applied.append({
                'type': 'standardization',
                'method': 'Z_score',
                'mean': scaler.mean_.tolist(),
                'scale': scaler.scale_.tolist()
            })
            
            logger.info("âœ… ç‰¹å¾æ ‡å‡†åŒ–å®Œæˆ")
            return X_scaled, fixes_applied
            
        except Exception as e:
            logger.error(f"âŒ ç‰¹å¾æ ‡å‡†åŒ–å¤±è´¥: {e}")
            return X, []
    
    def get_fix_summary(self) -> Dict:
        """è·å–ä¿®å¤æ‘˜è¦"""
        if not self.fix_history:
            return {"message": "æš‚æ— ä¿®å¤è®°å½•"}
        
        total_fixes = len(self.fix_history)
        successful_fixes = sum(1 for r in self.fix_history if r['status'] == 'success')
        
        # è®¡ç®—å¹³å‡æ”¹è¿›
        improvements = [r['improvement'] for r in self.fix_history if r['status'] == 'success']
        avg_improvement = np.mean(improvements) if improvements else 0
        
        return {
            "total_fixes": total_fixes,
            "successful_fixes": successful_fixes,
            "success_rate": f"{successful_fixes/total_fixes*100:.1f}%",
            "average_improvement": f"{avg_improvement:.3f}",
            "last_fix": self.fix_history[-1].get('timestamp', 'Unknown')
        }

def main():
    """ä¸»å‡½æ•°"""
    try:
        logger.info("ğŸš€ å¯åŠ¨æ•°æ®è´¨é‡ä¿®å¤...")
        
        # åŠ è½½ERA5æ•°æ®
        from src.models.agriculture.era5_soil_moisture_predictor import ERA5SoilMoisturePredictor
        
        predictor = ERA5SoilMoisturePredictor()
        data = predictor.load_data()
        
        # å±•å¹³æ•°æ® - æ­£ç¡®å¤„ç†åºåˆ—æ•°æ®
        X_train = data['X_train'].reshape(-1, data['X_train'].shape[-1])  # (11*7, 35) = (77, 35)
        y_train = np.repeat(data['y_train'], data['X_train'].shape[1])    # é‡å¤yå€¼ä»¥åŒ¹é…å±•å¹³åçš„X
        
        logger.info(f"ğŸ“Š åŸå§‹æ•°æ®å½¢çŠ¶: X={X_train.shape}, y={y_train.shape}")
        
        # åˆ›å»ºæ•°æ®è´¨é‡ä¿®å¤å™¨
        fixer = DataQualityFixer()
        
        # ä¿®å¤æ•°æ®è´¨é‡
        result = fixer.fix_data_quality(X_train, y_train)
        
        if result['status'] == 'success':
            logger.info("ğŸ‰ æ•°æ®è´¨é‡ä¿®å¤æˆåŠŸï¼")
            logger.info(f"ğŸ“Š è´¨é‡å¾—åˆ†æå‡: {result['improvement']:.3f}")
            logger.info(f"ğŸ”§ åº”ç”¨ä¿®å¤: {len(result['fixes_applied'])} ä¸ª")
            logger.info(f"ğŸ“ æ•°æ®å½¢çŠ¶: {result['original_shape']} -> {result['fixed_shape']}")
            
            # ä¿å­˜ä¿®å¤åçš„æ•°æ®
            X_fixed = result.get('X_fixed')
            y_fixed = result.get('y_fixed')
            
            if X_fixed is None or y_fixed is None:
                logger.error("âŒ ä¿®å¤åçš„æ•°æ®ä¸ºç©º")
                return result
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            output_dir = "data/processed/era5_fixed"
            os.makedirs(output_dir, exist_ok=True)
            
            np.save(os.path.join(output_dir, 'X_train_fixed.npy'), X_fixed)
            np.save(os.path.join(output_dir, 'y_train_fixed.npy'), y_fixed)
            
            logger.info(f"âœ… ä¿®å¤åçš„æ•°æ®å·²ä¿å­˜åˆ°: {output_dir}")
            
            # ä¿å­˜ä¿®å¤æŠ¥å‘Š
            report_file = f"data_quality_fix_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False, default=str)
            
            logger.info(f"âœ… ä¿®å¤æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            
        else:
            logger.error(f"âŒ æ•°æ®è´¨é‡ä¿®å¤å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ ä¸»å‡½æ•°æ‰§è¡Œå¤±è´¥: {e}")
        return {'status': 'error', 'error': str(e)}

if __name__ == "__main__":
    main()
