#!/usr/bin/env python3
"""
é‡æ–°è®­ç»ƒè¯šå®é¢„æµ‹å™¨
ä½¿ç”¨æ‰©å±•åçš„æ•°æ®é›†è®­ç»ƒè¯šå®é¢„æµ‹å™¨ï¼ŒéªŒè¯æ•°æ®æ‰©å±•çš„æ•ˆæœ
"""

import os
import sys
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

class HonestPredictorTrainer:
    """è¯šå®é¢„æµ‹å™¨è®­ç»ƒå™¨"""
    
    def __init__(self):
        self.data_dir = "data/processed/ready_for_training"
        self.models_dir = "models"
        self.results_dir = "training_results"
        
        # åˆ›å»ºç›®å½•
        os.makedirs(self.models_dir, exist_ok=True)
        os.makedirs(self.results_dir, exist_ok=True)
        
        # è®­ç»ƒå‚æ•°
        self.sequence_length = 30
        self.batch_size = 64
        self.epochs = 100
        self.learning_rate = 0.001
        self.patience = 10
        
        # è®¾å¤‡
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {self.device}")
    
    def load_processed_data(self) -> tuple:
        """åŠ è½½å¤„ç†åçš„æ•°æ®"""
        print("ğŸ“¥ åŠ è½½å¤„ç†åçš„æ•°æ®")
        
        try:
            # åŠ è½½è®­ç»ƒæ•°æ®
            train_path = os.path.join(self.data_dir, 'train_data_scaled.csv')
            test_path = os.path.join(self.data_dir, 'test_data_scaled.csv')
            
            train_data = pd.read_csv(train_path, index_col=0)
            test_data = pd.read_csv(test_path, index_col=0)
            
            print(f"âœ… è®­ç»ƒæ•°æ®: {train_data.shape}")
            print(f"âœ… æµ‹è¯•æ•°æ®: {test_data.shape}")
            
            return train_data, test_data
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
            return None, None
    
    def create_sequences(self, data: pd.DataFrame, target_col: str = 'snow_water_equivalent_mm') -> tuple:
        """åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®"""
        print(f"ğŸ”„ åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ® (åºåˆ—é•¿åº¦: {self.sequence_length})")
        
        sequences = []
        targets = []
        
        # é€‰æ‹©ç‰¹å¾åˆ—ï¼ˆæ’é™¤ç›®æ ‡åˆ—ï¼‰
        feature_cols = [col for col in data.columns if col != target_col]
        
        for i in range(self.sequence_length, len(data)):
            # åˆ›å»ºåºåˆ—
            seq = data[feature_cols].iloc[i-self.sequence_length:i].values
            target = data[target_col].iloc[i]
            
            sequences.append(seq)
            targets.append(target)
        
        sequences = np.array(sequences, dtype=np.float32)
        targets = np.array(targets, dtype=np.float32)
        
        print(f"   åºåˆ—å½¢çŠ¶: {sequences.shape}")
        print(f"   ç›®æ ‡å½¢çŠ¶: {targets.shape}")
        print(f"   ç‰¹å¾æ•°: {sequences.shape[2]}")
        
        return sequences, targets
    
    def create_data_loaders(self, train_sequences: np.ndarray, train_targets: np.ndarray,
                           test_sequences: np.ndarray, test_targets: np.ndarray) -> tuple:
        """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
        print("ğŸ”„ åˆ›å»ºæ•°æ®åŠ è½½å™¨")
        
        # è½¬æ¢ä¸ºPyTorchå¼ é‡
        train_sequences_tensor = torch.FloatTensor(train_sequences).to(self.device)
        train_targets_tensor = torch.FloatTensor(train_targets).to(self.device)
        test_sequences_tensor = torch.FloatTensor(test_sequences).to(self.device)
        test_targets_tensor = torch.FloatTensor(test_targets).to(self.device)
        
        # åˆ›å»ºæ•°æ®é›†
        train_dataset = TensorDataset(train_sequences_tensor, train_targets_tensor)
        test_dataset = TensorDataset(test_sequences_tensor, test_targets_tensor)
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)
        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)
        
        print(f"   è®­ç»ƒæ‰¹æ¬¡: {len(train_loader)}")
        print(f"   æµ‹è¯•æ‰¹æ¬¡: {len(test_loader)}")
        
        return train_loader, test_loader
    
    def create_model(self, input_size: int) -> nn.Module:
        """åˆ›å»ºæ¨¡å‹"""
        print(f"ğŸ—ï¸ åˆ›å»ºæ¨¡å‹ (è¾“å…¥ç‰¹å¾: {input_size})")
        
        model = nn.Sequential(
            # LSTMå±‚
            nn.LSTM(input_size, 128, num_layers=2, batch_first=True, dropout=0.2),
            # å…¨è¿æ¥å±‚
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(32, 1)
        )
        
        # è‡ªå®šä¹‰å‰å‘ä¼ æ’­
        class CustomLSTMModel(nn.Module):
            def __init__(self, lstm, fc_layers):
                super().__init__()
                self.lstm = lstm
                self.fc_layers = fc_layers
            
            def forward(self, x):
                lstm_out, _ = self.lstm(x)
                # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
                last_output = lstm_out[:, -1, :]
                # é€šè¿‡å…¨è¿æ¥å±‚
                for layer in self.fc_layers:
                    last_output = layer(last_output)
                return last_output
        
        lstm_layer = model[0]
        fc_layers = model[1:]
        
        custom_model = CustomLSTMModel(lstm_layer, fc_layers)
        custom_model.to(self.device)
        
        return custom_model
    
    def train_model(self, model: nn.Module, train_loader: DataLoader, 
                   test_loader: DataLoader) -> dict:
        """è®­ç»ƒæ¨¡å‹"""
        print("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹")
        
        # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        criterion = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=self.learning_rate)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)
        
        # è®­ç»ƒå†å²
        train_losses = []
        test_losses = []
        best_test_loss = float('inf')
        patience_counter = 0
        
        print(f"   è®­ç»ƒè½®æ•°: {self.epochs}")
        print(f"   å­¦ä¹ ç‡: {self.learning_rate}")
        print(f"   æ‰¹æ¬¡å¤§å°: {self.batch_size}")
        
        for epoch in range(self.epochs):
            # è®­ç»ƒé˜¶æ®µ
            model.train()
            train_loss = 0.0
            
            for sequences, targets in train_loader:
                optimizer.zero_grad()
                outputs = model(sequences)
                loss = criterion(outputs.squeeze(), targets)
                loss.backward()
                optimizer.step()
                train_loss += loss.item()
            
            train_loss /= len(train_loader)
            train_losses.append(train_loss)
            
            # æµ‹è¯•é˜¶æ®µ
            model.eval()
            test_loss = 0.0
            
            with torch.no_grad():
                for sequences, targets in test_loader:
                    outputs = model(sequences)
                    loss = criterion(outputs.squeeze(), targets)
                    test_loss += loss.item()
            
            test_loss /= len(test_loader)
            test_losses.append(test_loss)
            
            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step(test_loss)
            
            # æ—©åœæ£€æŸ¥
            if test_loss < best_test_loss:
                best_test_loss = test_loss
                patience_counter = 0
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                best_model_path = os.path.join(self.models_dir, 'best_honest_predictor.pth')
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'train_loss': train_loss,
                    'test_loss': test_loss,
                    'best_test_loss': best_test_loss
                }, best_model_path)
            else:
                patience_counter += 1
            
            # æ‰“å°è¿›åº¦
            if (epoch + 1) % 10 == 0:
                print(f"   Epoch {epoch+1:3d}/{self.epochs}: "
                      f"Train Loss: {train_loss:.6f}, "
                      f"Test Loss: {test_loss:.6f}, "
                      f"LR: {optimizer.param_groups[0]['lr']:.6f}")
            
            # æ—©åœ
            if patience_counter >= self.patience:
                print(f"   ğŸ›‘ æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬ {epoch+1} è½®åœæ­¢è®­ç»ƒ")
                break
        
        # è®­ç»ƒå®Œæˆ
        print(f"âœ… è®­ç»ƒå®Œæˆï¼æœ€ä½³æµ‹è¯•æŸå¤±: {best_test_loss:.6f}")
        
        # ä¿å­˜è®­ç»ƒå†å²
        training_history = {
            'train_losses': train_losses,
            'test_losses': test_losses,
            'best_epoch': epoch - patience_counter + 1,
            'best_test_loss': best_test_loss,
            'final_train_loss': train_losses[-1],
            'final_test_loss': test_losses[-1]
        }
        
        return training_history
    
    def evaluate_model(self, model: nn.Module, test_loader: DataLoader) -> dict:
        """è¯„ä¼°æ¨¡å‹"""
        print("ğŸ“Š è¯„ä¼°æ¨¡å‹æ€§èƒ½")
        
        model.eval()
        all_predictions = []
        all_targets = []
        
        with torch.no_grad():
            for sequences, targets in test_loader:
                outputs = model(sequences)
                predictions = outputs.squeeze().cpu().numpy()
                targets_np = targets.cpu().numpy()
                
                all_predictions.extend(predictions)
                all_targets.extend(targets_np)
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        all_predictions = np.array(all_predictions)
        all_targets = np.array(all_targets)
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        mse = mean_squared_error(all_targets, all_predictions)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(all_targets, all_predictions)
        r2 = r2_score(all_targets, all_predictions)
        
        # è®¡ç®—ç›¸å¯¹è¯¯å·®
        mape = np.mean(np.abs((all_targets - all_predictions) / (all_targets + 1e-8))) * 100
        
        metrics = {
            'mse': mse,
            'rmse': rmse,
            'mae': mae,
            'r2': r2,
            'mape': mape,
            'predictions': all_predictions.tolist(),
            'targets': all_targets.tolist()
        }
        
        print(f"   è¯„ä¼°æŒ‡æ ‡:")
        print(f"     MSE: {mse:.6f}")
        print(f"     RMSE: {rmse:.6f}")
        print(f"     MAE: {mae:.6f}")
        print(f"     RÂ²: {r2:.6f}")
        print(f"     MAPE: {mape:.2f}%")
        
        return metrics
    
    def plot_training_results(self, training_history: dict, evaluation_metrics: dict):
        """ç»˜åˆ¶è®­ç»ƒç»“æœ"""
        print("ğŸ“ˆ ç»˜åˆ¶è®­ç»ƒç»“æœ")
        
        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. è®­ç»ƒæŸå¤±æ›²çº¿
        axes[0, 0].plot(training_history['train_losses'], label='è®­ç»ƒæŸå¤±', color='blue')
        axes[0, 0].plot(training_history['test_losses'], label='æµ‹è¯•æŸå¤±', color='red')
        axes[0, 0].set_title('è®­ç»ƒå’Œæµ‹è¯•æŸå¤±')
        axes[0, 0].set_xlabel('è½®æ•°')
        axes[0, 0].set_ylabel('æŸå¤±')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. é¢„æµ‹vså®é™…å€¼æ•£ç‚¹å›¾
        predictions = np.array(evaluation_metrics['predictions'])
        targets = np.array(evaluation_metrics['targets'])
        
        axes[0, 1].scatter(targets, predictions, alpha=0.6, color='green')
        axes[0, 1].plot([targets.min(), targets.max()], [targets.min(), targets.max()], 'r--', lw=2)
        axes[0, 1].set_title('é¢„æµ‹å€¼ vs å®é™…å€¼')
        axes[0, 1].set_xlabel('å®é™…å€¼')
        axes[0, 1].set_ylabel('é¢„æµ‹å€¼')
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. æ®‹å·®å›¾
        residuals = predictions - targets
        axes[1, 0].scatter(predictions, residuals, alpha=0.6, color='orange')
        axes[1, 0].axhline(y=0, color='r', linestyle='--')
        axes[1, 0].set_title('æ®‹å·®å›¾')
        axes[1, 0].set_xlabel('é¢„æµ‹å€¼')
        axes[1, 0].set_ylabel('æ®‹å·®')
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. è¯¯å·®åˆ†å¸ƒç›´æ–¹å›¾
        axes[1, 1].hist(residuals, bins=50, alpha=0.7, color='purple', edgecolor='black')
        axes[1, 1].set_title('è¯¯å·®åˆ†å¸ƒ')
        axes[1, 1].set_xlabel('è¯¯å·®')
        axes[1, 1].set_ylabel('é¢‘æ¬¡')
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        plot_path = os.path.join(self.results_dir, 'training_results.png')
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        print(f"   è®­ç»ƒç»“æœå›¾è¡¨å·²ä¿å­˜: {plot_path}")
        
        plt.show()
    
    def save_results(self, training_history: dict, evaluation_metrics: dict):
        """ä¿å­˜è®­ç»ƒç»“æœ"""
        print("ğŸ’¾ ä¿å­˜è®­ç»ƒç»“æœ")
        
        # ä¿å­˜è®­ç»ƒå†å²
        history_path = os.path.join(self.results_dir, 'training_history.json')
        with open(history_path, 'w') as f:
            json.dump(training_history, f, indent=2, default=str)
        
        # ä¿å­˜è¯„ä¼°æŒ‡æ ‡
        metrics_path = os.path.join(self.results_dir, 'evaluation_metrics.json')
        with open(metrics_path, 'w') as f:
            json.dump(evaluation_metrics, f, indent=2, default=str)
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        report = {
            'timestamp': datetime.now().isoformat(),
            'model_info': {
                'sequence_length': self.sequence_length,
                'batch_size': self.batch_size,
                'epochs': self.epochs,
                'learning_rate': self.learning_rate,
                'device': str(self.device)
            },
            'training_summary': {
                'best_epoch': training_history['best_epoch'],
                'best_test_loss': training_history['best_test_loss'],
                'final_train_loss': training_history['final_train_loss'],
                'final_test_loss': training_history['final_test_loss']
            },
            'evaluation_summary': {
                'mse': evaluation_metrics['mse'],
                'rmse': evaluation_metrics['rmse'],
                'mae': evaluation_metrics['mae'],
                'r2': evaluation_metrics['r2'],
                'mape': evaluation_metrics['mape']
            }
        }
        
        report_path = os.path.join(self.results_dir, 'training_report.json')
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2, default=str)
        
        print(f"   è®­ç»ƒå†å²: {history_path}")
        print(f"   è¯„ä¼°æŒ‡æ ‡: {metrics_path}")
        print(f"   ç»¼åˆæŠ¥å‘Š: {report_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹é‡æ–°è®­ç»ƒè¯šå®é¢„æµ‹å™¨")
    print("=" * 50)
    
    trainer = HonestPredictorTrainer()
    
    # 1. åŠ è½½æ•°æ®
    train_data, test_data = trainer.load_processed_data()
    if train_data is None or test_data is None:
        print("âŒ æ— æ³•åŠ è½½æ•°æ®ï¼Œé€€å‡º")
        return False
    
    # 2. åˆ›å»ºåºåˆ—æ•°æ®
    train_sequences, train_targets = trainer.create_sequences(train_data)
    test_sequences, test_targets = trainer.create_sequences(test_data)
    
    # 3. åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader, test_loader = trainer.create_data_loaders(
        train_sequences, train_targets, test_sequences, test_targets
    )
    
    # 4. åˆ›å»ºæ¨¡å‹
    input_size = train_sequences.shape[2]
    model = trainer.create_model(input_size)
    
    # 5. è®­ç»ƒæ¨¡å‹
    training_history = trainer.train_model(model, train_loader, test_loader)
    
    # 6. è¯„ä¼°æ¨¡å‹
    evaluation_metrics = trainer.evaluate_model(model, test_loader)
    
    # 7. ç»˜åˆ¶ç»“æœ
    trainer.plot_training_results(training_history, evaluation_metrics)
    
    # 8. ä¿å­˜ç»“æœ
    trainer.save_results(training_history, evaluation_metrics)
    
    print(f"\nğŸ‰ è¯šå®é¢„æµ‹å™¨é‡æ–°è®­ç»ƒå®Œæˆï¼")
    print(f"   æœ€ä½³RÂ²åˆ†æ•°: {evaluation_metrics['r2']:.4f}")
    print(f"   æœ€ä½³æµ‹è¯•æŸå¤±: {training_history['best_test_loss']:.6f}")
    print(f"   è®­ç»ƒè½®æ•°: {training_history['best_epoch']}")
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
