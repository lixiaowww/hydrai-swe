# ğŸ“š HydrAI-SWE å®Œæ•´å­¦ä¹ æŒ‡å—

### **ğŸ¯ å­¦ä¹ ç›®æ ‡**
ä½œä¸ºåˆå­¦è€…ï¼Œä½ å°†é€šè¿‡è¿™ä¸ªæŒ‡å—ï¼š
1. ç†è§£æ°´æ–‡å’Œé›ªæ°´å½“é‡çš„åŸºæœ¬æ¦‚å¿µ
2. æŒæ¡Pythonç¼–ç¨‹å’Œæœºå™¨å­¦ä¹ åŸºç¡€
3. æ·±å…¥ç†è§£HydrAI-SWEé¡¹ç›®çš„æ ¸å¿ƒæ¨¡å—
4. å­¦ä¼šä½¿ç”¨å’Œæ‰©å±•ç³»ç»ŸåŠŸèƒ½

---

## ğŸ“– ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¡€æ¦‚å¿µå­¦ä¹ 

### **1.1 æ°´æ–‡åŸºç¡€çŸ¥è¯†**

#### **ä»€ä¹ˆæ˜¯æ°´æ–‡ï¼Ÿ**
æ°´æ–‡æ˜¯ç ”ç©¶åœ°çƒä¸Šæ°´å¾ªç¯çš„ç§‘å­¦ï¼ŒåŒ…æ‹¬ï¼š
- **é™æ°´**ï¼šé›¨ã€é›ªã€å†°é›¹ç­‰
- **è’¸å‘**ï¼šæ°´ä»åœ°è¡¨è’¸å‘åˆ°å¤§æ°”
- **å¾„æµ**ï¼šæ°´åœ¨åœ°è¡¨æµåŠ¨
- **åœ°ä¸‹æ°´**ï¼šå‚¨å­˜åœ¨åœ°ä¸‹çš„æ°´

#### **é›ªæ°´å½“é‡ (SWE - Snow Water Equivalent)**
```
SWE = é›ªæ·± Ã— é›ªå¯†åº¦
```
- **æ„ä¹‰**ï¼šç§¯é›ªèåŒ–åèƒ½äº§ç”Ÿå¤šå°‘æ°´
- **å•ä½**ï¼šæ¯«ç±³(mm)æˆ–è‹±å¯¸(in)
- **é‡è¦æ€§**ï¼šé¢„æµ‹æ˜¥å­£æ´ªæ°´ã€å†œä¸šçŒæº‰ã€æ°´èµ„æºç®¡ç†

#### **å­¦ä¹ èµ„æº**
- ğŸ“š **æ¨èä¹¦ç±**ï¼šã€Šæ°´æ–‡åœ°è´¨å­¦åŸºç¡€ã€‹
- ğŸŒ **åœ¨çº¿è¯¾ç¨‹**ï¼šCoursera "Introduction to Hydrology"
- ğŸ¥ **è§†é¢‘æ•™ç¨‹**ï¼šYouTube "Snow Water Equivalent Explained"

### **1.2 æœºå™¨å­¦ä¹ åŸºç¡€**

#### **ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ**
æœºå™¨å­¦ä¹ æ˜¯è®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼çš„æŠ€æœ¯ã€‚

#### **æ ¸å¿ƒæ¦‚å¿µ**
1. **ç›‘ç£å­¦ä¹ **ï¼šæœ‰æ ‡ç­¾æ•°æ®è®­ç»ƒæ¨¡å‹
2. **æ— ç›‘ç£å­¦ä¹ **ï¼šæ— æ ‡ç­¾æ•°æ®å‘ç°æ¨¡å¼
3. **æ—¶é—´åºåˆ—**ï¼šæŒ‰æ—¶é—´é¡ºåºæ’åˆ—çš„æ•°æ®
4. **ç‰¹å¾å·¥ç¨‹**ï¼šä»åŸå§‹æ•°æ®æå–æœ‰ç”¨ä¿¡æ¯

#### **å­¦ä¹ è·¯å¾„**
```
Week 1-2: PythonåŸºç¡€
Week 3-4: æ•°æ®å¤„ç† (Pandas, NumPy)
Week 5-6: æœºå™¨å­¦ä¹ åŸºç¡€ (Scikit-learn)
Week 7-8: æ·±åº¦å­¦ä¹  (TensorFlow/PyTorch)
```

---

## ğŸ ç¬¬äºŒéƒ¨åˆ†ï¼šPythonç¼–ç¨‹åŸºç¡€

### **2.1 Pythonç¯å¢ƒæ­å»º**

#### **å®‰è£…Python**
```bash
# æ£€æŸ¥Pythonç‰ˆæœ¬
python3 --version

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv hydrai_env
source hydrai_env/bin/activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

#### **æ ¸å¿ƒåº“ä»‹ç»**
```python
import pandas as pd      # æ•°æ®å¤„ç†
import numpy as np       # æ•°å€¼è®¡ç®—
import matplotlib.pyplot as plt  # ç»˜å›¾
import seaborn as sns    # ç»Ÿè®¡ç»˜å›¾
from sklearn.model_selection import train_test_split  # æ•°æ®åˆ†å‰²
```

### **2.2 æ•°æ®å¤„ç†åŸºç¡€**

#### **è¯»å–æ•°æ®**
```python
# è¯»å–CSVæ–‡ä»¶
data = pd.read_csv('swe_data.csv')

# æŸ¥çœ‹æ•°æ®åŸºæœ¬ä¿¡æ¯
print(data.info())
print(data.describe())
```

#### **æ•°æ®æ¸…æ´—**
```python
# å¤„ç†ç¼ºå¤±å€¼
data = data.dropna()  # åˆ é™¤ç¼ºå¤±å€¼
data = data.fillna(0)  # å¡«å……ç¼ºå¤±å€¼

# æ•°æ®ç±»å‹è½¬æ¢
data['date'] = pd.to_datetime(data['date'])
```

### **2.3 æ•°æ®å¯è§†åŒ–**

#### **åŸºç¡€å›¾è¡¨**
```python
import matplotlib.pyplot as plt

# æ—¶é—´åºåˆ—å›¾
plt.figure(figsize=(12, 6))
plt.plot(data['date'], data['swe_mm'])
plt.title('Snow Water Equivalent Over Time')
plt.xlabel('Date')
plt.ylabel('SWE (mm)')
plt.show()

# æ•£ç‚¹å›¾
plt.scatter(data['temperature'], data['swe_mm'])
plt.xlabel('Temperature (Â°C)')
plt.ylabel('SWE (mm)')
plt.show()
```

---

## ğŸ§  ç¬¬ä¸‰éƒ¨åˆ†ï¼šæœºå™¨å­¦ä¹ åŸºç¡€

### **3.1 æ—¶é—´åºåˆ—é¢„æµ‹**

#### **ä»€ä¹ˆæ˜¯æ—¶é—´åºåˆ—ï¼Ÿ**
æ—¶é—´åºåˆ—æ˜¯æŒ‰æ—¶é—´é¡ºåºæ’åˆ—çš„æ•°æ®ï¼Œå¦‚ï¼š
- æ¯æ—¥æ¸©åº¦
- æ¯æœˆé™æ°´é‡
- æ¯å¹´SWEå€¼

#### **æ—¶é—´åºåˆ—ç‰¹å¾**
```python
# åˆ›å»ºæ—¶é—´ç‰¹å¾
data['year'] = data['date'].dt.year
data['month'] = data['date'].dt.month
data['day_of_year'] = data['date'].dt.dayofyear

# æ»åç‰¹å¾
data['swe_lag1'] = data['swe_mm'].shift(1)  # å‰ä¸€å¤©çš„å€¼
data['swe_lag7'] = data['swe_mm'].shift(7)  # ä¸€å‘¨å‰çš„å€¼
```

### **3.2 æ¨¡å‹è®­ç»ƒåŸºç¡€**

#### **æ•°æ®åˆ†å‰²**
```python
from sklearn.model_selection import train_test_split

# åˆ†å‰²ç‰¹å¾å’Œç›®æ ‡
X = data[['temperature', 'precipitation', 'swe_lag1']]
y = data['swe_mm']

# åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
```

#### **æ¨¡å‹è®­ç»ƒ**
```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# è®­ç»ƒæ¨¡å‹
model = LinearRegression()
model.fit(X_train, y_train)

# é¢„æµ‹
y_pred = model.predict(X_test)

# è¯„ä¼°
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f'RÂ² Score: {r2:.4f}')
```

---

## ğŸ—ï¸ ç¬¬å››éƒ¨åˆ†ï¼šHydrAI-SWEé¡¹ç›®æ¶æ„

### **4.1 é¡¹ç›®ç»“æ„ç†è§£**

```
hydrai_swe/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/           # APIæ¥å£
â”‚   â”œâ”€â”€ models/        # æœºå™¨å­¦ä¹ æ¨¡å‹
â”‚   â””â”€â”€ data/          # æ•°æ®å¤„ç†
â”œâ”€â”€ templates/         # å‰ç«¯ç•Œé¢
â”œâ”€â”€ docs/             # æ–‡æ¡£
â””â”€â”€ requirements.txt  # ä¾èµ–åŒ…
```

### **4.2 æ ¸å¿ƒæ¨¡å—è§£æ**

#### **APIæ¨¡å— (src/api/)**
```python
# ä¸»è¦åŠŸèƒ½ï¼šæä¾›Web APIæ¥å£
# å…³é”®æ–‡ä»¶ï¼š
# - main.py: ä¸»åº”ç”¨å…¥å£
# - routers/: è·¯ç”±æ¨¡å—
#   - swe.py: SWEé¢„æµ‹API
#   - weather.py: å¤©æ°”æ•°æ®API
#   - agriculture.py: å†œä¸šåŠŸèƒ½API
```

#### **æ¨¡å‹æ¨¡å— (src/models/)**
```python
# ä¸»è¦åŠŸèƒ½ï¼šæœºå™¨å­¦ä¹ æ¨¡å‹å®ç°
# å…³é”®æ–‡ä»¶ï¼š
# - swe_analysis_system.py: SWEåˆ†æç³»ç»Ÿ
# - flood_risk_assessment.py: æ´ªæ°´é£é™©è¯„ä¼°
# - agriculture/: å†œä¸šç›¸å…³æ¨¡å‹
```

---

## ğŸ§  ç¬¬äº”éƒ¨åˆ†ï¼šæ·±å…¥ç†è§£æ ¸å¿ƒç®—æ³•

### **5.1 GRUæ¨¡å‹ (é¡¹ç›®æ ¸å¿ƒ)**

#### **ä»€ä¹ˆæ˜¯GRUï¼Ÿ**
GRU (Gated Recurrent Unit) æ˜¯ä¸€ç§å¾ªç¯ç¥ç»ç½‘ç»œï¼Œç‰¹åˆ«é€‚åˆæ—¶é—´åºåˆ—é¢„æµ‹ã€‚

#### **GRUå·¥ä½œåŸç†**
```python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GRU, Dense

# æ„å»ºGRUæ¨¡å‹
model = Sequential([
    GRU(64, return_sequences=True, input_shape=(30, 6)),  # 30å¤©ï¼Œ6ä¸ªç‰¹å¾
    GRU(32, return_sequences=False),
    Dense(1)  # è¾“å‡ºå±‚
])

# ç¼–è¯‘æ¨¡å‹
model.compile(
    optimizer='adam',
    loss='mse',
    metrics=['mae']
)
```

#### **ä¸ºä»€ä¹ˆé€‰æ‹©GRUï¼Ÿ**
1. **è®°å¿†èƒ½åŠ›**ï¼šèƒ½è®°ä½é•¿æœŸä¾èµ–å…³ç³»
2. **è®¡ç®—æ•ˆç‡**ï¼šæ¯”LSTMæ›´ç®€å•
3. **æ€§èƒ½ä¼˜ç§€**ï¼šåœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­è¡¨ç°è‰¯å¥½

### **5.2 é›†æˆå­¦ä¹  (Ensemble)**

#### **ä»€ä¹ˆæ˜¯é›†æˆå­¦ä¹ ï¼Ÿ**
é›†æˆå­¦ä¹ ç»“åˆå¤šä¸ªæ¨¡å‹æ¥æé«˜é¢„æµ‹å‡†ç¡®æ€§ã€‚

#### **é¡¹ç›®ä¸­çš„é›†æˆæ–¹æ³•**
```python
# ä¸‰ä¸ªGRUæ¨¡å‹çš„é›†æˆ
def ensemble_predict(models, X):
    predictions = []
    for model in models:
        pred = model.predict(X)
        predictions.append(pred)
    
    # ç®€å•å¹³å‡
    ensemble_pred = np.mean(predictions, axis=0)
    return ensemble_pred
```

### **5.3 ç‰¹å¾å·¥ç¨‹**

#### **æ—¶é—´ç‰¹å¾**
```python
# å­£èŠ‚æ€§ç‰¹å¾
data['sin_month'] = np.sin(2 * np.pi * data['month'] / 12)
data['cos_month'] = np.cos(2 * np.pi * data['month'] / 12)

# æ»åç‰¹å¾
for lag in [1, 3, 7, 14, 30]:
    data[f'swe_lag_{lag}'] = data['swe_mm'].shift(lag)

# ç§»åŠ¨å¹³å‡
data['swe_ma_7'] = data['swe_mm'].rolling(window=7).mean()
data['swe_ma_30'] = data['swe_mm'].rolling(window=30).mean()
```

#### **æ°”è±¡ç‰¹å¾**
```python
# æ¸©åº¦ç›¸å…³
data['temp_ma_7'] = data['temperature'].rolling(window=7).mean()
data['temp_std_7'] = data['temperature'].rolling(window=7).std()

# é™æ°´ç›¸å…³
data['precip_cumulative'] = data['precipitation'].cumsum()
data['precip_ma_30'] = data['precipitation'].rolling(window=30).mean()
```

---

## ğŸš€ ç¬¬å…­éƒ¨åˆ†ï¼šå®è·µæ“ä½œæŒ‡å—

### **6.1 å¯åŠ¨é¡¹ç›®**

#### **ç¯å¢ƒå‡†å¤‡**
```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/lixiaowww/hydrai-swe.git
cd hydrai-swe

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 4. å¯åŠ¨æœåŠ¡
uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --reload
```

#### **è®¿é—®ç•Œé¢**
- **ä¸»ç•Œé¢**: http://localhost:8000/ui
- **APIæ–‡æ¡£**: http://localhost:8000/docs
- **ç”¨æˆ·æŒ‡å—**: http://localhost:8000/guides

### **6.2 æ•°æ®æ¢ç´¢å®è·µ**

#### **æŸ¥çœ‹æ•°æ®**
```python
# åœ¨Pythonä¸­æ¢ç´¢æ•°æ®
import pandas as pd
import matplotlib.pyplot as plt

# è¯»å–æ•°æ®
data = pd.read_csv('data/swe_data.csv')

# åŸºæœ¬ç»Ÿè®¡
print("æ•°æ®å½¢çŠ¶:", data.shape)
print("æ•°æ®åˆ—:", data.columns.tolist())
print("ç¼ºå¤±å€¼:", data.isnull().sum())

# å¯è§†åŒ–
plt.figure(figsize=(15, 10))

# SWEæ—¶é—´åºåˆ—
plt.subplot(2, 2, 1)
plt.plot(data['date'], data['swe_mm'])
plt.title('SWE Time Series')
plt.xlabel('Date')
plt.ylabel('SWE (mm)')

# æ¸©åº¦åˆ†å¸ƒ
plt.subplot(2, 2, 2)
plt.hist(data['temperature'], bins=30)
plt.title('Temperature Distribution')
plt.xlabel('Temperature (Â°C)')

# SWE vs æ¸©åº¦
plt.subplot(2, 2, 3)
plt.scatter(data['temperature'], data['swe_mm'], alpha=0.5)
plt.title('SWE vs Temperature')
plt.xlabel('Temperature (Â°C)')
plt.ylabel('SWE (mm)')

# æœˆåº¦SWEå¹³å‡å€¼
plt.subplot(2, 2, 4)
monthly_swe = data.groupby('month')['swe_mm'].mean()
plt.bar(monthly_swe.index, monthly_swe.values)
plt.title('Monthly Average SWE')
plt.xlabel('Month')
plt.ylabel('Average SWE (mm)')

plt.tight_layout()
plt.show()
```

### **6.3 æ¨¡å‹è®­ç»ƒå®è·µ**

#### **è®­ç»ƒç®€å•æ¨¡å‹**
```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# å‡†å¤‡æ•°æ®
features = ['temperature', 'precipitation', 'swe_lag1', 'swe_lag7']
X = data[features].dropna()
y = data.loc[X.index, 'swe_mm']

# åˆ†å‰²æ•°æ®
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# è®­ç»ƒæ¨¡å‹
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# é¢„æµ‹å’Œè¯„ä¼°
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'RÂ² Score: {r2:.4f}')
print(f'RMSE: {np.sqrt(mse):.4f}')

# ç‰¹å¾é‡è¦æ€§
feature_importance = pd.DataFrame({
    'feature': features,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

print("\nç‰¹å¾é‡è¦æ€§:")
print(feature_importance)
```

---

## ğŸ” ç¬¬ä¸ƒéƒ¨åˆ†ï¼šé¡¹ç›®æ ¸å¿ƒåŠŸèƒ½è¯¦è§£

### **7.1 SWEé¢„æµ‹ç³»ç»Ÿ**

#### **ç³»ç»Ÿæ¶æ„**
```
æ•°æ®è¾“å…¥ â†’ ç‰¹å¾å·¥ç¨‹ â†’ æ¨¡å‹è®­ç»ƒ â†’ é¢„æµ‹è¾“å‡º
    â†“           â†“          â†“         â†“
  æ°”è±¡æ•°æ®   æ—¶é—´ç‰¹å¾    GRUæ¨¡å‹    SWEé¢„æµ‹
  å†å²SWE   æ»åç‰¹å¾    é›†æˆå­¦ä¹    ç½®ä¿¡åŒºé—´
```

#### **å…³é”®ä»£ç ç†è§£**
```python
# æ¥è‡ª src/models/swe_analysis_system.py
class SWEAnalysisSystem:
    def __init__(self):
        self.models = []  # å­˜å‚¨å¤šä¸ªGRUæ¨¡å‹
        self.scaler = StandardScaler()  # æ•°æ®æ ‡å‡†åŒ–
    
    def prepare_features(self, data):
        """ç‰¹å¾å·¥ç¨‹"""
        # æ—¶é—´ç‰¹å¾
        data['sin_month'] = np.sin(2 * np.pi * data['month'] / 12)
        data['cos_month'] = np.cos(2 * np.pi * data['month'] / 12)
        
        # æ»åç‰¹å¾
        for lag in [1, 3, 7, 14, 30]:
            data[f'swe_lag_{lag}'] = data['swe_mm'].shift(lag)
        
        return data
    
    def train_ensemble(self, X, y):
        """è®­ç»ƒé›†æˆæ¨¡å‹"""
        # è®­ç»ƒå¤šä¸ªGRUæ¨¡å‹
        for i in range(3):
            model = self.create_gru_model()
            model.fit(X, y, epochs=100, validation_split=0.2)
            self.models.append(model)
    
    def predict(self, X):
        """é›†æˆé¢„æµ‹"""
        predictions = []
        for model in self.models:
            pred = model.predict(X)
            predictions.append(pred)
        
        # è¿”å›å¹³å‡é¢„æµ‹å’Œç½®ä¿¡åŒºé—´
        mean_pred = np.mean(predictions, axis=0)
        std_pred = np.std(predictions, axis=0)
        
        return mean_pred, std_pred
```

### **7.2 æ´ªæ°´é¢„è­¦ç³»ç»Ÿ**

#### **é¢„è­¦é€»è¾‘**
```python
# æ¥è‡ª src/models/flood_risk_assessment.py
class FloodRiskAssessment:
    def assess_risk(self, swe_data, weather_data):
        """æ´ªæ°´é£é™©è¯„ä¼°"""
        risk_factors = []
        
        # 1. SWEç´¯ç§¯é‡
        if swe_data['current_swe'] > swe_data['historical_90th']:
            risk_factors.append('high_swe')
        
        # 2. æ¸©åº¦ä¸Šå‡
        if weather_data['temperature_trend'] > 5:  # 5Â°C/å¤©
            risk_factors.append('rapid_warming')
        
        # 3. é™æ°´é¢„æµ‹
        if weather_data['forecasted_precip'] > 20:  # 20mm
            risk_factors.append('heavy_precipitation')
        
        # ç»¼åˆé£é™©è¯„ä¼°
        risk_level = self.calculate_risk_level(risk_factors)
        return risk_level
    
    def calculate_risk_level(self, factors):
        """è®¡ç®—é£é™©ç­‰çº§"""
        if len(factors) >= 3:
            return 'HIGH'
        elif len(factors) >= 2:
            return 'MODERATE'
        elif len(factors) >= 1:
            return 'LOW'
        else:
            return 'MINIMAL'
```

### **7.3 å†œä¸šæ™ºèƒ½ç³»ç»Ÿ**

#### **åœŸå£¤æ°´åˆ†é¢„æµ‹**
```python
# æ¥è‡ª src/models/agriculture/soil_moisture_predictor.py
class SoilMoisturePredictor:
    def __init__(self):
        self.model = None
        self.features = ['temperature', 'precipitation', 'humidity', 'swe']
    
    def train_lstm_model(self, data):
        """è®­ç»ƒLSTMæ¨¡å‹"""
        # å‡†å¤‡åºåˆ—æ•°æ®
        sequences = self.create_sequences(data, sequence_length=30)
        
        # æ„å»ºLSTMæ¨¡å‹
        model = Sequential([
            LSTM(50, return_sequences=True, input_shape=(30, len(self.features))),
            LSTM(50, return_sequences=False),
            Dense(25),
            Dense(1)
        ])
        
        model.compile(optimizer='adam', loss='mse', metrics=['mae'])
        model.fit(sequences, epochs=100, validation_split=0.2)
        
        self.model = model
    
    def predict_soil_moisture(self, weather_data):
        """é¢„æµ‹åœŸå£¤æ°´åˆ†"""
        if self.model is None:
            return "Model not trained"
        
        # é¢„å¤„ç†æ•°æ®
        processed_data = self.preprocess_data(weather_data)
        
        # é¢„æµ‹
        prediction = self.model.predict(processed_data)
        return prediction[0][0]
```

---

## ğŸ› ï¸ ç¬¬å…«éƒ¨åˆ†ï¼šæ‰©å±•å¼€å‘æŒ‡å—

### **8.1 æ·»åŠ æ–°åŠŸèƒ½**

#### **åˆ›å»ºæ–°çš„APIç«¯ç‚¹**
```python
# åœ¨ src/api/routers/ ä¸­åˆ›å»ºæ–°æ–‡ä»¶
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel

router = APIRouter()

class PredictionRequest(BaseModel):
    temperature: float
    precipitation: float
    date: str

@router.post("/predict-custom")
async def custom_prediction(request: PredictionRequest):
    """è‡ªå®šä¹‰é¢„æµ‹ç«¯ç‚¹"""
    try:
        # è°ƒç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹
        result = your_model.predict(request.dict())
        return {"prediction": result, "status": "success"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

#### **æ·»åŠ æ–°çš„æœºå™¨å­¦ä¹ æ¨¡å‹**
```python
# åœ¨ src/models/ ä¸­åˆ›å»ºæ–°æ–‡ä»¶
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

class CustomModel:
    def __init__(self):
        self.model = None
    
    def build_model(self, input_shape):
        """æ„å»ºè‡ªå®šä¹‰æ¨¡å‹"""
        model = Sequential([
            LSTM(64, return_sequences=True, input_shape=input_shape),
            LSTM(32, return_sequences=False),
            Dense(16, activation='relu'),
            Dense(1)
        ])
        
        model.compile(
            optimizer='adam',
            loss='mse',
            metrics=['mae']
        )
        
        self.model = model
        return model
    
    def train(self, X, y, epochs=100):
        """è®­ç»ƒæ¨¡å‹"""
        history = self.model.fit(
            X, y,
            epochs=epochs,
            validation_split=0.2,
            verbose=1
        )
        return history
```

### **8.2 æ•°æ®å¯è§†åŒ–æ‰©å±•**

#### **åˆ›å»ºè‡ªå®šä¹‰å›¾è¡¨**
```python
import plotly.graph_objects as go
import plotly.express as px

def create_interactive_swe_chart(data):
    """åˆ›å»ºäº¤äº’å¼SWEå›¾è¡¨"""
    fig = go.Figure()
    
    # æ·»åŠ SWEæ•°æ®
    fig.add_trace(go.Scatter(
        x=data['date'],
        y=data['swe_mm'],
        mode='lines+markers',
        name='SWE',
        line=dict(color='blue', width=2)
    ))
    
    # æ·»åŠ æ¸©åº¦æ•°æ®ï¼ˆåŒè½´ï¼‰
    fig.add_trace(go.Scatter(
        x=data['date'],
        y=data['temperature'],
        mode='lines',
        name='Temperature',
        yaxis='y2',
        line=dict(color='red', width=1)
    ))
    
    # è®¾ç½®å¸ƒå±€
    fig.update_layout(
        title='SWE and Temperature Over Time',
        xaxis_title='Date',
        yaxis=dict(title='SWE (mm)', side='left'),
        yaxis2=dict(title='Temperature (Â°C)', side='right', overlaying='y'),
        hovermode='x unified'
    )
    
    return fig
```

---

## ğŸ“š ç¬¬ä¹éƒ¨åˆ†ï¼šå­¦ä¹ èµ„æºæ¨è

### **9.1 åœ¨çº¿è¯¾ç¨‹**

#### **Pythonç¼–ç¨‹**
- **Coursera**: "Python for Everybody" (University of Michigan)
- **edX**: "Introduction to Computer Science and Programming" (MIT)
- **Udemy**: "Complete Python Bootcamp"

#### **æœºå™¨å­¦ä¹ **
- **Coursera**: "Machine Learning" (Stanford University)
- **edX**: "Introduction to Machine Learning" (MIT)
- **Fast.ai**: "Practical Deep Learning for Coders"

#### **æ°´æ–‡ç§‘å­¦**
- **Coursera**: "Introduction to Hydrology"
- **edX**: "Water in the Western United States"
- **YouTube**: "Hydrology and Water Resources"

### **9.2 æ¨èä¹¦ç±**

#### **Pythonç¼–ç¨‹**
- ã€ŠPythonç¼–ç¨‹ï¼šä»å…¥é—¨åˆ°å®è·µã€‹
- ã€Šæµç•…çš„Pythonã€‹
- ã€ŠPythonæ•°æ®ç§‘å­¦æ‰‹å†Œã€‹

#### **æœºå™¨å­¦ä¹ **
- ã€Šæœºå™¨å­¦ä¹ å®æˆ˜ã€‹
- ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹
- ã€Šæ·±åº¦å­¦ä¹ ã€‹(Ian Goodfellow)

#### **æ°´æ–‡ç§‘å­¦**
- ã€Šæ°´æ–‡åœ°è´¨å­¦åŸºç¡€ã€‹
- ã€Šæ°´èµ„æºå·¥ç¨‹ã€‹
- ã€Šæ°”å€™å˜åŒ–ä¸æ°´æ–‡å¾ªç¯ã€‹

### **9.3 å®è·µé¡¹ç›®**

#### **åˆçº§é¡¹ç›®**
1. **æ•°æ®å¯è§†åŒ–é¡¹ç›®**
   - ä½¿ç”¨Matplotlibç»˜åˆ¶SWEæ—¶é—´åºåˆ—
   - åˆ›å»ºæ¸©åº¦-SWEæ•£ç‚¹å›¾
   - åˆ¶ä½œæœˆåº¦SWEç»Ÿè®¡å›¾

2. **ç®€å•é¢„æµ‹æ¨¡å‹**
   - ä½¿ç”¨çº¿æ€§å›å½’é¢„æµ‹SWE
   - å®ç°ç§»åŠ¨å¹³å‡é¢„æµ‹
   - åˆ›å»ºå­£èŠ‚æ€§åˆ†è§£

#### **ä¸­çº§é¡¹ç›®**
1. **æ—¶é—´åºåˆ—åˆ†æ**
   - å®ç°ARIMAæ¨¡å‹
   - åˆ›å»ºLSTMé¢„æµ‹æ¨¡å‹
   - è¿›è¡Œç‰¹å¾å·¥ç¨‹

2. **Webåº”ç”¨å¼€å‘**
   - ä½¿ç”¨Flaskåˆ›å»ºç®€å•API
   - å¼€å‘æ•°æ®å¯è§†åŒ–ç•Œé¢
   - å®ç°ç”¨æˆ·äº¤äº’åŠŸèƒ½

#### **é«˜çº§é¡¹ç›®**
1. **å®Œæ•´é¢„æµ‹ç³»ç»Ÿ**
   - å®ç°å¤šæ¨¡å‹é›†æˆ
   - åˆ›å»ºå®æ—¶é¢„æµ‹API
   - å¼€å‘é¢„è­¦ç³»ç»Ÿ

2. **ç³»ç»Ÿä¼˜åŒ–**
   - æ¨¡å‹æ€§èƒ½ä¼˜åŒ–
   - æ•°æ®å¤„ç†ç®¡é“ä¼˜åŒ–
   - ç”¨æˆ·ç•Œé¢æ”¹è¿›

---

## ğŸ¯ ç¬¬åéƒ¨åˆ†ï¼šå­¦ä¹ è®¡åˆ’å»ºè®®

### **10.1 12å‘¨å­¦ä¹ è®¡åˆ’**

#### **ç¬¬1-2å‘¨ï¼šåŸºç¡€å‡†å¤‡**
- **ç›®æ ‡**ï¼šæŒæ¡PythonåŸºç¡€è¯­æ³•
- **ä»»åŠ¡**ï¼š
  - å®ŒæˆPythonåŸºç¡€æ•™ç¨‹
  - å®‰è£…å¼€å‘ç¯å¢ƒ
  - è¿è¡Œç¬¬ä¸€ä¸ªHydrAI-SWEç¨‹åº

#### **ç¬¬3-4å‘¨ï¼šæ•°æ®å¤„ç†**
- **ç›®æ ‡**ï¼šæŒæ¡Pandaså’ŒNumPy
- **ä»»åŠ¡**ï¼š
  - å­¦ä¹ æ•°æ®è¯»å–å’Œæ¸…æ´—
  - æŒæ¡æ•°æ®å¯è§†åŒ–
  - åˆ†æé¡¹ç›®ä¸­çš„æ•°æ®é›†

#### **ç¬¬5-6å‘¨ï¼šæœºå™¨å­¦ä¹ åŸºç¡€**
- **ç›®æ ‡**ï¼šç†è§£æœºå™¨å­¦ä¹ æ¦‚å¿µ
- **ä»»åŠ¡**ï¼š
  - å­¦ä¹ ç›‘ç£å­¦ä¹ ç®—æ³•
  - å®ç°ç®€å•é¢„æµ‹æ¨¡å‹
  - ç†è§£æ¨¡å‹è¯„ä¼°æŒ‡æ ‡

#### **ç¬¬7-8å‘¨ï¼šæ·±åº¦å­¦ä¹ **
- **ç›®æ ‡**ï¼šæŒæ¡ç¥ç»ç½‘ç»œåŸºç¡€
- **ä»»åŠ¡**ï¼š
  - å­¦ä¹ TensorFlow/Keras
  - å®ç°LSTMæ¨¡å‹
  - ç†è§£æ—¶é—´åºåˆ—é¢„æµ‹

#### **ç¬¬9-10å‘¨ï¼šé¡¹ç›®å®è·µ**
- **ç›®æ ‡**ï¼šæ·±å…¥ç†è§£é¡¹ç›®æ¶æ„
- **ä»»åŠ¡**ï¼š
  - åˆ†æé¡¹ç›®ä»£ç ç»“æ„
  - è¿è¡Œå’Œæµ‹è¯•å„ä¸ªæ¨¡å—
  - ç†è§£APIæ¥å£è®¾è®¡

#### **ç¬¬11-12å‘¨ï¼šæ‰©å±•å¼€å‘**
- **ç›®æ ‡**ï¼šèƒ½å¤Ÿæ‰©å±•é¡¹ç›®åŠŸèƒ½
- **ä»»åŠ¡**ï¼š
  - æ·»åŠ æ–°çš„é¢„æµ‹æ¨¡å‹
  - å¼€å‘æ–°çš„APIç«¯ç‚¹
  - æ”¹è¿›ç”¨æˆ·ç•Œé¢

### **10.2 æ¯æ—¥å­¦ä¹ å®‰æ’**

#### **å·¥ä½œæ—¥ (1-2å°æ—¶)**
- **ç†è®ºå­¦ä¹ **ï¼š30åˆ†é’Ÿ
- **ä»£ç å®è·µ**ï¼š60-90åˆ†é’Ÿ
- **é¡¹ç›®åˆ†æ**ï¼š30åˆ†é’Ÿ

#### **å‘¨æœ« (3-4å°æ—¶)**
- **æ·±åº¦å®è·µ**ï¼š2-3å°æ—¶
- **é¡¹ç›®å¼€å‘**ï¼š1-2å°æ—¶
- **æ€»ç»“å¤ä¹ **ï¼š30åˆ†é’Ÿ

### **10.3 å­¦ä¹ æ£€æŸ¥ç‚¹**

#### **ç¬¬4å‘¨æ£€æŸ¥ç‚¹**
- [ ] èƒ½å¤Ÿç‹¬ç«‹ç¼–å†™Pythonç¨‹åº
- [ ] æŒæ¡åŸºæœ¬çš„æ•°æ®å¤„ç†æ“ä½œ
- [ ] èƒ½å¤Ÿè¿è¡ŒHydrAI-SWEé¡¹ç›®

#### **ç¬¬8å‘¨æ£€æŸ¥ç‚¹**
- [ ] ç†è§£æœºå™¨å­¦ä¹ åŸºæœ¬æ¦‚å¿µ
- [ ] èƒ½å¤Ÿè®­ç»ƒç®€å•çš„é¢„æµ‹æ¨¡å‹
- [ ] æŒæ¡æ—¶é—´åºåˆ—åˆ†ææ–¹æ³•

#### **ç¬¬12å‘¨æ£€æŸ¥ç‚¹**
- [ ] æ·±å…¥ç†è§£é¡¹ç›®æ¶æ„
- [ ] èƒ½å¤Ÿæ‰©å±•é¡¹ç›®åŠŸèƒ½
- [ ] å…·å¤‡ç‹¬ç«‹å¼€å‘èƒ½åŠ›

---

## ğŸ‰ ç»“è¯­

é€šè¿‡è¿™ä¸ªå®Œæ•´çš„å­¦ä¹ æŒ‡å—ï¼Œä½ å°†ï¼š

1. **æŒæ¡åŸºç¡€çŸ¥è¯†**ï¼šä»æ°´æ–‡ç§‘å­¦åˆ°æœºå™¨å­¦ä¹ 
2. **ç†è§£é¡¹ç›®æ¶æ„**ï¼šæ·±å…¥HydrAI-SWEçš„æ¯ä¸ªæ¨¡å—
3. **å…·å¤‡å®è·µèƒ½åŠ›**ï¼šèƒ½å¤Ÿè¿è¡Œã€ä¿®æ”¹å’Œæ‰©å±•é¡¹ç›®
4. **å»ºç«‹å­¦ä¹ ä¹ æƒ¯**ï¼šæŒç»­å­¦ä¹ å’Œæ”¹è¿›

è®°ä½ï¼Œå­¦ä¹ æ˜¯ä¸€ä¸ªæ¸è¿›çš„è¿‡ç¨‹ã€‚ä¸è¦æ€¥äºæ±‚æˆï¼Œè¦æ³¨é‡ç†è§£æ¦‚å¿µå’ŒåŠ¨æ‰‹å®è·µã€‚é‡åˆ°é—®é¢˜æ—¶ï¼Œå¤šæŸ¥é˜…æ–‡æ¡£ï¼Œå¤šä¸ç¤¾åŒºäº¤æµã€‚

**ç¥ä½ å­¦ä¹ æ„‰å¿«ï¼Œæ—©æ—¥æˆä¸ºæ°´æ–‡AIä¸“å®¶ï¼** ğŸš€

---

**ğŸ“ å­¦ä¹ æ”¯æŒ**
- **GitHub Issues**: é¡¹ç›®é—®é¢˜è®¨è®º
- **Stack Overflow**: æŠ€æœ¯é—®é¢˜è§£ç­”
- **Reddit**: r/MachineLearning, r/Python
- **Discord**: æœºå™¨å­¦ä¹ ç¤¾åŒº

**ğŸ”„ æŒç»­æ›´æ–°**
è¿™ä¸ªå­¦ä¹ æŒ‡å—ä¼šéšç€é¡¹ç›®å‘å±•æŒç»­æ›´æ–°ï¼Œç¡®ä¿å†…å®¹çš„å‰æ²¿æ€§å’Œå®ç”¨æ€§ã€‚

